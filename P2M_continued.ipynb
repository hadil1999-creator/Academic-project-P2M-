{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2M continued.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hadil1999-creator/P2M-/blob/main/P2M_continued.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read the two scenarios"
      ],
      "metadata": {
        "id": "8KHFsDFtVQKC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tenKdQ7bC8-E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1= pd.read_csv(r\"/content/scenario1.csv\")\n",
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lYA8ROuEEBWa",
        "outputId": "4016a694-e006-41c4-e0f3-a3afb1989d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       scope_item_id  assessment_id  N2O      CO2  CH4  Other    total\n",
              "0                1.0              1  3.0    624.0  1.0    0.0    628.0\n",
              "1                1.0              3  0.0    787.0  0.0   12.0    799.0\n",
              "2                1.0              4  0.0  19686.0  0.0    0.0  19686.0\n",
              "3                1.0              7  1.0  17487.0  2.0    0.0  17490.0\n",
              "4                1.0              8  0.0    918.0  0.0    0.0    918.0\n",
              "...              ...            ...  ...      ...  ...    ...      ...\n",
              "11858            6.0           7576  NaN      NaN  NaN    NaN   1375.0\n",
              "11859            6.0           7577  NaN      NaN  NaN    NaN  34931.0\n",
              "11860            6.0           7578  NaN      NaN  NaN    NaN   1454.0\n",
              "11861            6.0           7588  NaN      NaN  NaN    NaN    110.0\n",
              "11862            6.0           7594  NaN      NaN  NaN    NaN    120.0\n",
              "\n",
              "[11863 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10c3777f-fe0b-42ac-b5de-0ccc5a630988\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scope_item_id</th>\n",
              "      <th>assessment_id</th>\n",
              "      <th>N2O</th>\n",
              "      <th>CO2</th>\n",
              "      <th>CH4</th>\n",
              "      <th>Other</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>624.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>628.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>787.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>799.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19686.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19686.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17487.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17490.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>918.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>918.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11858</th>\n",
              "      <td>6.0</td>\n",
              "      <td>7576</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1375.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11859</th>\n",
              "      <td>6.0</td>\n",
              "      <td>7577</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34931.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11860</th>\n",
              "      <td>6.0</td>\n",
              "      <td>7578</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1454.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11861</th>\n",
              "      <td>6.0</td>\n",
              "      <td>7588</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>110.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11862</th>\n",
              "      <td>6.0</td>\n",
              "      <td>7594</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11863 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10c3777f-fe0b-42ac-b5de-0ccc5a630988')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10c3777f-fe0b-42ac-b5de-0ccc5a630988 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10c3777f-fe0b-42ac-b5de-0ccc5a630988');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2= pd.read_csv(r\"/content/scenario2.csv\")\n",
        "df2"
      ],
      "metadata": {
        "id": "u2F9TcfEEVdO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f6d00100-a246-4583-97d4-4bde590078fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  organization_type   staff  population  reporting_year  \\\n",
              "0        1                  1  6848.0         NaN          2011.0   \n",
              "1        3                  2   261.0         NaN          2011.0   \n",
              "2        4                  3  3000.0     94000.0          2010.0   \n",
              "3        7                  2   557.0         NaN          2011.0   \n",
              "4        8                  1  2711.0         NaN          2012.0   \n",
              "...    ...                ...     ...         ...             ...   \n",
              "2360  7576                  1   700.0         NaN          2019.0   \n",
              "2361  7577                  1  9134.0         NaN          2020.0   \n",
              "2362  7578                  1   560.0         NaN          2019.0   \n",
              "2363  7588                  1   612.0         NaN          2020.0   \n",
              "2364  7594                  1  1306.0         NaN          2019.0   \n",
              "\n",
              "      total_scope_1  total_scope_2  total_scope_3  \n",
              "0            6017.0         2170.0        59931.0  \n",
              "1             824.0          382.0            0.0  \n",
              "2           19811.0            0.0        48674.0  \n",
              "3           17802.0        23319.0            0.0  \n",
              "4            4132.0         2432.0            0.0  \n",
              "...             ...            ...            ...  \n",
              "2360        12647.0         1375.0            0.0  \n",
              "2361        15851.0        35389.0       280232.0  \n",
              "2362        24596.0         1454.0            0.0  \n",
              "2363          439.0          110.0        57004.0  \n",
              "2364         1141.0          120.0        28563.0  \n",
              "\n",
              "[2365 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc7d73ba-676c-4b9b-8d5c-5be2c0102f2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>organization_type</th>\n",
              "      <th>staff</th>\n",
              "      <th>population</th>\n",
              "      <th>reporting_year</th>\n",
              "      <th>total_scope_1</th>\n",
              "      <th>total_scope_2</th>\n",
              "      <th>total_scope_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6848.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>6017.0</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>59931.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>261.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>824.0</td>\n",
              "      <td>382.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>94000.0</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>19811.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48674.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>557.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>17802.0</td>\n",
              "      <td>23319.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2711.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>4132.0</td>\n",
              "      <td>2432.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2360</th>\n",
              "      <td>7576</td>\n",
              "      <td>1</td>\n",
              "      <td>700.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>12647.0</td>\n",
              "      <td>1375.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2361</th>\n",
              "      <td>7577</td>\n",
              "      <td>1</td>\n",
              "      <td>9134.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>15851.0</td>\n",
              "      <td>35389.0</td>\n",
              "      <td>280232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2362</th>\n",
              "      <td>7578</td>\n",
              "      <td>1</td>\n",
              "      <td>560.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>24596.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2363</th>\n",
              "      <td>7588</td>\n",
              "      <td>1</td>\n",
              "      <td>612.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>439.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>57004.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2364</th>\n",
              "      <td>7594</td>\n",
              "      <td>1</td>\n",
              "      <td>1306.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1141.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>28563.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2365 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc7d73ba-676c-4b9b-8d5c-5be2c0102f2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc7d73ba-676c-4b9b-8d5c-5be2c0102f2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc7d73ba-676c-4b9b-8d5c-5be2c0102f2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"population\"]=df2[\"population\"].fillna(df2[\"population\"].mean())\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "go-pNDdEzyG1",
        "outputId": "3095d7c0-5e1d-499f-fde1-5b574a706e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  organization_type   staff     population  reporting_year  \\\n",
              "0        1                  1  6848.0  475014.179167          2011.0   \n",
              "1        3                  2   261.0  475014.179167          2011.0   \n",
              "2        4                  3  3000.0   94000.000000          2010.0   \n",
              "3        7                  2   557.0  475014.179167          2011.0   \n",
              "4        8                  1  2711.0  475014.179167          2012.0   \n",
              "...    ...                ...     ...            ...             ...   \n",
              "2360  7576                  1   700.0  475014.179167          2019.0   \n",
              "2361  7577                  1  9134.0  475014.179167          2020.0   \n",
              "2362  7578                  1   560.0  475014.179167          2019.0   \n",
              "2363  7588                  1   612.0  475014.179167          2020.0   \n",
              "2364  7594                  1  1306.0  475014.179167          2019.0   \n",
              "\n",
              "      total_scope_1  total_scope_2  total_scope_3  \n",
              "0            6017.0         2170.0        59931.0  \n",
              "1             824.0          382.0            0.0  \n",
              "2           19811.0            0.0        48674.0  \n",
              "3           17802.0        23319.0            0.0  \n",
              "4            4132.0         2432.0            0.0  \n",
              "...             ...            ...            ...  \n",
              "2360        12647.0         1375.0            0.0  \n",
              "2361        15851.0        35389.0       280232.0  \n",
              "2362        24596.0         1454.0            0.0  \n",
              "2363          439.0          110.0        57004.0  \n",
              "2364         1141.0          120.0        28563.0  \n",
              "\n",
              "[2365 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90593ba7-bd35-4b27-a935-de61cb965a21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>organization_type</th>\n",
              "      <th>staff</th>\n",
              "      <th>population</th>\n",
              "      <th>reporting_year</th>\n",
              "      <th>total_scope_1</th>\n",
              "      <th>total_scope_2</th>\n",
              "      <th>total_scope_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6848.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>6017.0</td>\n",
              "      <td>2170.0</td>\n",
              "      <td>59931.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>261.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>824.0</td>\n",
              "      <td>382.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>94000.000000</td>\n",
              "      <td>2010.0</td>\n",
              "      <td>19811.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48674.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>557.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2011.0</td>\n",
              "      <td>17802.0</td>\n",
              "      <td>23319.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2711.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2012.0</td>\n",
              "      <td>4132.0</td>\n",
              "      <td>2432.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2360</th>\n",
              "      <td>7576</td>\n",
              "      <td>1</td>\n",
              "      <td>700.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>12647.0</td>\n",
              "      <td>1375.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2361</th>\n",
              "      <td>7577</td>\n",
              "      <td>1</td>\n",
              "      <td>9134.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>15851.0</td>\n",
              "      <td>35389.0</td>\n",
              "      <td>280232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2362</th>\n",
              "      <td>7578</td>\n",
              "      <td>1</td>\n",
              "      <td>560.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>24596.0</td>\n",
              "      <td>1454.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2363</th>\n",
              "      <td>7588</td>\n",
              "      <td>1</td>\n",
              "      <td>612.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>439.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>57004.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2364</th>\n",
              "      <td>7594</td>\n",
              "      <td>1</td>\n",
              "      <td>1306.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1141.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>28563.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2365 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90593ba7-bd35-4b27-a935-de61cb965a21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90593ba7-bd35-4b27-a935-de61cb965a21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90593ba7-bd35-4b27-a935-de61cb965a21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2=df2.dropna(axis=0)"
      ],
      "metadata": {
        "id": "JcW2jtPiR2Ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.isna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LN8f1HsWSlmK",
        "outputId": "a81936c2-b96d-44e1-a8ea-79a72cf3e3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  organization_type  staff  population  reporting_year  \\\n",
              "0     False              False  False       False           False   \n",
              "1     False              False  False       False           False   \n",
              "2     False              False  False       False           False   \n",
              "3     False              False  False       False           False   \n",
              "4     False              False  False       False           False   \n",
              "...     ...                ...    ...         ...             ...   \n",
              "2360  False              False  False       False           False   \n",
              "2361  False              False  False       False           False   \n",
              "2362  False              False  False       False           False   \n",
              "2363  False              False  False       False           False   \n",
              "2364  False              False  False       False           False   \n",
              "\n",
              "      total_scope_1  total_scope_2  total_scope_3  \n",
              "0             False          False          False  \n",
              "1             False          False          False  \n",
              "2             False          False          False  \n",
              "3             False          False          False  \n",
              "4             False          False          False  \n",
              "...             ...            ...            ...  \n",
              "2360          False          False          False  \n",
              "2361          False          False          False  \n",
              "2362          False          False          False  \n",
              "2363          False          False          False  \n",
              "2364          False          False          False  \n",
              "\n",
              "[2275 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a11986c-1da2-43a9-910a-a046713cf9b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>organization_type</th>\n",
              "      <th>staff</th>\n",
              "      <th>population</th>\n",
              "      <th>reporting_year</th>\n",
              "      <th>total_scope_1</th>\n",
              "      <th>total_scope_2</th>\n",
              "      <th>total_scope_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2360</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2361</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2362</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2363</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2364</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2275 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a11986c-1da2-43a9-910a-a046713cf9b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a11986c-1da2-43a9-910a-a046713cf9b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a11986c-1da2-43a9-910a-a046713cf9b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ],
      "metadata": {
        "id": "unpFHM1F46W1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results=['total_scope_1','total_scope_2','total_scope_3']\n",
        "Y=df2[results]\n",
        "features=[\"organization_type\",\t\"staff\"\t,\"population\"\t,\"reporting_year\"]\n",
        "X=df2[features]\n",
        "train_X, val_X, train_Y, val_Y = train_test_split(X, Y,test_size= 0.33, random_state = 0)\n",
        "train_X\n"
      ],
      "metadata": {
        "id": "KaFgV79e5J2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "996c6414-8092-4d8b-b29c-4231704f36d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      organization_type   staff     population  reporting_year\n",
              "974                   1  1670.0  475014.179167          2016.0\n",
              "786                   2  1755.0  475014.179167          2015.0\n",
              "2362                  1   560.0  475014.179167          2019.0\n",
              "1980                  1   600.0  475014.179167          2019.0\n",
              "427                   1   860.0  475014.179167          2015.0\n",
              "...                 ...     ...            ...             ...\n",
              "1111                  2  2930.0  475014.179167          2016.0\n",
              "1816                  1   505.0  475014.179167          2019.0\n",
              "839                   1  2307.0  475014.179167          2019.0\n",
              "913                   1   540.0  475014.179167          2016.0\n",
              "1737                  1   609.0  475014.179167          2019.0\n",
              "\n",
              "[1524 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-936e0577-2167-4c98-9fc1-1a0da12e4673\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>organization_type</th>\n",
              "      <th>staff</th>\n",
              "      <th>population</th>\n",
              "      <th>reporting_year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>974</th>\n",
              "      <td>1</td>\n",
              "      <td>1670.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>2</td>\n",
              "      <td>1755.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2362</th>\n",
              "      <td>1</td>\n",
              "      <td>560.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>1</td>\n",
              "      <td>600.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>1</td>\n",
              "      <td>860.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2015.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1111</th>\n",
              "      <td>2</td>\n",
              "      <td>2930.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1816</th>\n",
              "      <td>1</td>\n",
              "      <td>505.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>1</td>\n",
              "      <td>2307.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>1</td>\n",
              "      <td>540.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2016.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>1</td>\n",
              "      <td>609.0</td>\n",
              "      <td>475014.179167</td>\n",
              "      <td>2019.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1524 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-936e0577-2167-4c98-9fc1-1a0da12e4673')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-936e0577-2167-4c98-9fc1-1a0da12e4673 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-936e0577-2167-4c98-9fc1-1a0da12e4673');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPy"
      ],
      "metadata": {
        "id": "gAHvkKnhSQUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce6826a-5796-4853-ed31-328987868b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPy\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 32.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 296 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 307 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 317 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 327 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 337 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 348 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 358 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 368 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 378 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 389 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 399 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 409 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 419 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 430 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 440 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 450 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 460 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 471 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 481 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 491 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 501 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 512 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 522 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 532 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 542 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 552 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 563 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 573 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 583 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 593 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 604 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 614 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 624 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 634 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 645 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 655 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 665 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 675 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 686 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 696 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 706 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 716 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 727 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 737 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 747 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 757 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 768 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 778 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 788 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 798 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 808 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 819 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 829 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 839 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 849 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 860 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 870 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 880 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 890 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 901 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 911 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 921 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 931 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 942 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 952 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 959 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from GPy) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from GPy) (1.15.0)\n",
            "Collecting paramz>=0.9.0\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 785 kB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from GPy) (0.29.28)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from GPy) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->GPy) (4.4.2)\n",
            "Building wheels for collected packages: GPy, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.10.0-cp37-cp37m-linux_x86_64.whl size=2565093 sha256=41d262d48e74f53bd49b6b43df7b0f0b5ee465777711f48a3a5211d9d92a4944\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/18/28/dd1ce0192a81b71a3b086fd952511d088b21e8359ea496860a\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102566 sha256=88fa82fd9f68317a3523e5e6678e0bf81bd3704b6c0a5e129b50b5ed23513e9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\n",
            "Successfully built GPy paramz\n",
            "Installing collected packages: paramz, GPy\n",
            "Successfully installed GPy-1.10.0 paramz-0.9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GPyOpt"
      ],
      "metadata": {
        "id": "7kPgy0MTSf2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a0886c-802d-4598-8821-39df3a63ba51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPyOpt\n",
            "  Downloading GPyOpt-1.2.6.tar.gz (56 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▊                          | 10 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 56 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from GPyOpt) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.7/dist-packages (from GPyOpt) (1.4.1)\n",
            "Requirement already satisfied: GPy>=1.8 in /usr/local/lib/python3.7/dist-packages (from GPyOpt) (1.10.0)\n",
            "Requirement already satisfied: paramz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from GPy>=1.8->GPyOpt) (0.9.5)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from GPy>=1.8->GPyOpt) (0.29.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from GPy>=1.8->GPyOpt) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt) (4.4.2)\n",
            "Building wheels for collected packages: GPyOpt\n",
            "  Building wheel for GPyOpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPyOpt: filename=GPyOpt-1.2.6-py3-none-any.whl size=83609 sha256=7370eca6306ea51121614c82d2188586ce81c04887abbbd5cdfb75480b9145d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/fa/d1/f9652b5af79f769a0ab74dbead7c7aea9a93c6bc74543fd3ec\n",
            "Successfully built GPyOpt\n",
            "Installing collected packages: GPyOpt\n",
            "Successfully installed GPyOpt-1.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import GPy, GPyOpt\n",
        "import numpy as np\n",
        "import pandas as pds\n",
        "import random\n",
        "from keras.layers import Activation, Dropout, BatchNormalization, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import mnist\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "first_input=4\n",
        "last_output=3\n",
        "l1_out=16\n",
        "l2_out=8\n",
        "l3_out=16\n",
        "l4_out=128\n",
        "\n",
        "        \n",
        "        "
      ],
      "metadata": {
        "id": "U_Dl0t-LNraj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optimizers"
      ],
      "metadata": {
        "id": "ND35ATNPSz7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "73ade325-a7f2-4e10-e1e5-0024a7e84482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optimizers\n",
            "  Downloading Optimizers-v2.1.tar.gz (1.6 kB)\n",
            "Collecting requests>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->optimizers) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->optimizers) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->optimizers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->optimizers) (1.24.3)\n",
            "Building wheels for collected packages: optimizers\n",
            "  Building wheel for optimizers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimizers: filename=Optimizers-2.1-py3-none-any.whl size=2284 sha256=4c27d489125347453a55689400758191af781060c2b4497a3e50b34c0f51c8ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/a5/4d/f679a391b5fca0b18c5e2fcd66ebff8900d97d6d95713915b9\n",
            "Successfully built optimizers\n",
            "Installing collected packages: requests, optimizers\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed optimizers-2.1 requests-2.27.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "u0dsLqLkTUYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80404940-1947-4d86-daf8-96be1edffaa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(l1_out, input_dim=first_input ,kernel_initializer='he_uniform', activation='elu'))\n",
        "model.add(Dense(l2_out, activation='sigmoid'))\n",
        "model.add(Dense(l3_out, activation='sigmoid'))\n",
        "model.add(Dense(l4_out, activation='sigmoid'))\n",
        "model.add(Dense(last_output, activation=\"linear\"))"
      ],
      "metadata": {
        "id": "XBxBimrQ51Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DtLejONfBQ1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6FCvOnzOhir",
        "outputId": "edd430cb-2d21-4eec-a133-7f8c5cce12c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                80        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               2176      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,923\n",
            "Trainable params: 2,923\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=30\n",
        "epochs=150\n",
        "validation_split= 0.33\n",
        "model.fit(train_X, train_Y,verbose=2, epochs=epochs, batch_size=batch_size, validation_split=validation_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhIrtSV0E1VQ",
        "outputId": "1c6ca9da-8e76-4deb-9a6f-abcdd6f18ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "35/35 - 4s - loss: 95397.2109 - accuracy: 0.6033 - val_loss: 23193.5645 - val_accuracy: 0.6223 - 4s/epoch - 105ms/step\n",
            "Epoch 2/150\n",
            "35/35 - 0s - loss: 95395.1484 - accuracy: 0.6033 - val_loss: 23191.3398 - val_accuracy: 0.6223 - 168ms/epoch - 5ms/step\n",
            "Epoch 3/150\n",
            "35/35 - 0s - loss: 95392.6250 - accuracy: 0.6033 - val_loss: 23188.5938 - val_accuracy: 0.6223 - 131ms/epoch - 4ms/step\n",
            "Epoch 4/150\n",
            "35/35 - 0s - loss: 95389.6328 - accuracy: 0.6033 - val_loss: 23185.4277 - val_accuracy: 0.6223 - 162ms/epoch - 5ms/step\n",
            "Epoch 5/150\n",
            "35/35 - 0s - loss: 95386.3281 - accuracy: 0.6033 - val_loss: 23182.1133 - val_accuracy: 0.6223 - 136ms/epoch - 4ms/step\n",
            "Epoch 6/150\n",
            "35/35 - 0s - loss: 95383.0078 - accuracy: 0.6033 - val_loss: 23178.7988 - val_accuracy: 0.6223 - 133ms/epoch - 4ms/step\n",
            "Epoch 7/150\n",
            "35/35 - 0s - loss: 95379.7031 - accuracy: 0.6033 - val_loss: 23175.5469 - val_accuracy: 0.6223 - 160ms/epoch - 5ms/step\n",
            "Epoch 8/150\n",
            "35/35 - 0s - loss: 95376.4297 - accuracy: 0.6033 - val_loss: 23172.3066 - val_accuracy: 0.6223 - 159ms/epoch - 5ms/step\n",
            "Epoch 9/150\n",
            "35/35 - 0s - loss: 95373.1484 - accuracy: 0.6033 - val_loss: 23169.0488 - val_accuracy: 0.6223 - 162ms/epoch - 5ms/step\n",
            "Epoch 10/150\n",
            "35/35 - 0s - loss: 95369.8984 - accuracy: 0.6033 - val_loss: 23165.8574 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 11/150\n",
            "35/35 - 0s - loss: 95366.7734 - accuracy: 0.6033 - val_loss: 23162.7988 - val_accuracy: 0.6223 - 158ms/epoch - 5ms/step\n",
            "Epoch 12/150\n",
            "35/35 - 0s - loss: 95363.7109 - accuracy: 0.6033 - val_loss: 23159.7695 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 13/150\n",
            "35/35 - 0s - loss: 95360.7188 - accuracy: 0.6033 - val_loss: 23156.8398 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 14/150\n",
            "35/35 - 0s - loss: 95357.7812 - accuracy: 0.6033 - val_loss: 23154.0371 - val_accuracy: 0.6223 - 121ms/epoch - 3ms/step\n",
            "Epoch 15/150\n",
            "35/35 - 0s - loss: 95354.9531 - accuracy: 0.6033 - val_loss: 23151.2949 - val_accuracy: 0.6223 - 128ms/epoch - 4ms/step\n",
            "Epoch 16/150\n",
            "35/35 - 0s - loss: 95352.2188 - accuracy: 0.6033 - val_loss: 23148.6387 - val_accuracy: 0.6223 - 154ms/epoch - 4ms/step\n",
            "Epoch 17/150\n",
            "35/35 - 0s - loss: 95349.5391 - accuracy: 0.6033 - val_loss: 23146.0273 - val_accuracy: 0.6223 - 131ms/epoch - 4ms/step\n",
            "Epoch 18/150\n",
            "35/35 - 0s - loss: 95346.9375 - accuracy: 0.6033 - val_loss: 23143.4961 - val_accuracy: 0.6223 - 157ms/epoch - 4ms/step\n",
            "Epoch 19/150\n",
            "35/35 - 0s - loss: 95344.4609 - accuracy: 0.6033 - val_loss: 23141.0371 - val_accuracy: 0.6223 - 140ms/epoch - 4ms/step\n",
            "Epoch 20/150\n",
            "35/35 - 0s - loss: 95341.9844 - accuracy: 0.6033 - val_loss: 23138.5703 - val_accuracy: 0.6223 - 125ms/epoch - 4ms/step\n",
            "Epoch 21/150\n",
            "35/35 - 0s - loss: 95339.5625 - accuracy: 0.6033 - val_loss: 23136.1328 - val_accuracy: 0.6223 - 168ms/epoch - 5ms/step\n",
            "Epoch 22/150\n",
            "35/35 - 0s - loss: 95337.1641 - accuracy: 0.6033 - val_loss: 23133.7773 - val_accuracy: 0.6223 - 132ms/epoch - 4ms/step\n",
            "Epoch 23/150\n",
            "35/35 - 0s - loss: 95334.8984 - accuracy: 0.6033 - val_loss: 23131.4688 - val_accuracy: 0.6223 - 168ms/epoch - 5ms/step\n",
            "Epoch 24/150\n",
            "35/35 - 0s - loss: 95332.6562 - accuracy: 0.6033 - val_loss: 23129.1895 - val_accuracy: 0.6223 - 133ms/epoch - 4ms/step\n",
            "Epoch 25/150\n",
            "35/35 - 0s - loss: 95330.4141 - accuracy: 0.6033 - val_loss: 23126.9180 - val_accuracy: 0.6223 - 157ms/epoch - 4ms/step\n",
            "Epoch 26/150\n",
            "35/35 - 0s - loss: 95328.2109 - accuracy: 0.6033 - val_loss: 23124.6328 - val_accuracy: 0.6223 - 169ms/epoch - 5ms/step\n",
            "Epoch 27/150\n",
            "35/35 - 0s - loss: 95325.9766 - accuracy: 0.6033 - val_loss: 23122.4258 - val_accuracy: 0.6223 - 157ms/epoch - 4ms/step\n",
            "Epoch 28/150\n",
            "35/35 - 0s - loss: 95323.9375 - accuracy: 0.6033 - val_loss: 23120.3770 - val_accuracy: 0.6223 - 162ms/epoch - 5ms/step\n",
            "Epoch 29/150\n",
            "35/35 - 0s - loss: 95321.9766 - accuracy: 0.6033 - val_loss: 23118.3301 - val_accuracy: 0.6223 - 136ms/epoch - 4ms/step\n",
            "Epoch 30/150\n",
            "35/35 - 0s - loss: 95319.9297 - accuracy: 0.6033 - val_loss: 23116.2852 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 31/150\n",
            "35/35 - 0s - loss: 95317.9141 - accuracy: 0.6033 - val_loss: 23114.1465 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 32/150\n",
            "35/35 - 0s - loss: 95315.8984 - accuracy: 0.6033 - val_loss: 23112.0469 - val_accuracy: 0.6223 - 138ms/epoch - 4ms/step\n",
            "Epoch 33/150\n",
            "35/35 - 0s - loss: 95313.9375 - accuracy: 0.6033 - val_loss: 23109.9316 - val_accuracy: 0.6223 - 157ms/epoch - 4ms/step\n",
            "Epoch 34/150\n",
            "35/35 - 0s - loss: 95311.9609 - accuracy: 0.6033 - val_loss: 23107.8770 - val_accuracy: 0.6223 - 128ms/epoch - 4ms/step\n",
            "Epoch 35/150\n",
            "35/35 - 0s - loss: 95310.0078 - accuracy: 0.6033 - val_loss: 23105.8594 - val_accuracy: 0.6223 - 160ms/epoch - 5ms/step\n",
            "Epoch 36/150\n",
            "35/35 - 0s - loss: 95308.1016 - accuracy: 0.6033 - val_loss: 23103.8066 - val_accuracy: 0.6223 - 161ms/epoch - 5ms/step\n",
            "Epoch 37/150\n",
            "35/35 - 0s - loss: 95306.1797 - accuracy: 0.6033 - val_loss: 23101.8320 - val_accuracy: 0.6223 - 157ms/epoch - 4ms/step\n",
            "Epoch 38/150\n",
            "35/35 - 0s - loss: 95304.3047 - accuracy: 0.6033 - val_loss: 23099.8301 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 39/150\n",
            "35/35 - 0s - loss: 95302.4609 - accuracy: 0.6033 - val_loss: 23097.8535 - val_accuracy: 0.6223 - 139ms/epoch - 4ms/step\n",
            "Epoch 40/150\n",
            "35/35 - 0s - loss: 95300.6328 - accuracy: 0.6033 - val_loss: 23095.9277 - val_accuracy: 0.6223 - 162ms/epoch - 5ms/step\n",
            "Epoch 41/150\n",
            "35/35 - 0s - loss: 95298.8750 - accuracy: 0.6033 - val_loss: 23094.0059 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 42/150\n",
            "35/35 - 0s - loss: 95297.0859 - accuracy: 0.6033 - val_loss: 23092.1230 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 43/150\n",
            "35/35 - 0s - loss: 95295.3281 - accuracy: 0.6033 - val_loss: 23090.2812 - val_accuracy: 0.6223 - 163ms/epoch - 5ms/step\n",
            "Epoch 44/150\n",
            "35/35 - 0s - loss: 95293.6641 - accuracy: 0.6033 - val_loss: 23088.5254 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 45/150\n",
            "35/35 - 0s - loss: 95292.0469 - accuracy: 0.6033 - val_loss: 23086.7480 - val_accuracy: 0.6223 - 155ms/epoch - 4ms/step\n",
            "Epoch 46/150\n",
            "35/35 - 0s - loss: 95290.4141 - accuracy: 0.6033 - val_loss: 23084.9941 - val_accuracy: 0.6223 - 140ms/epoch - 4ms/step\n",
            "Epoch 47/150\n",
            "35/35 - 0s - loss: 95288.8203 - accuracy: 0.6033 - val_loss: 23083.2305 - val_accuracy: 0.6223 - 158ms/epoch - 5ms/step\n",
            "Epoch 48/150\n",
            "35/35 - 0s - loss: 95287.1797 - accuracy: 0.6033 - val_loss: 23081.5234 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 49/150\n",
            "35/35 - 0s - loss: 95285.6016 - accuracy: 0.6033 - val_loss: 23079.8164 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 50/150\n",
            "35/35 - 0s - loss: 95284.0859 - accuracy: 0.6033 - val_loss: 23078.1504 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 51/150\n",
            "35/35 - 0s - loss: 95282.5469 - accuracy: 0.6033 - val_loss: 23076.4609 - val_accuracy: 0.6223 - 128ms/epoch - 4ms/step\n",
            "Epoch 52/150\n",
            "35/35 - 0s - loss: 95280.9922 - accuracy: 0.6033 - val_loss: 23074.7832 - val_accuracy: 0.6223 - 127ms/epoch - 4ms/step\n",
            "Epoch 53/150\n",
            "35/35 - 0s - loss: 95279.4531 - accuracy: 0.6033 - val_loss: 23073.1367 - val_accuracy: 0.6223 - 130ms/epoch - 4ms/step\n",
            "Epoch 54/150\n",
            "35/35 - 0s - loss: 95277.9297 - accuracy: 0.6033 - val_loss: 23071.4941 - val_accuracy: 0.6223 - 173ms/epoch - 5ms/step\n",
            "Epoch 55/150\n",
            "35/35 - 0s - loss: 95276.5391 - accuracy: 0.6033 - val_loss: 23069.9707 - val_accuracy: 0.6223 - 155ms/epoch - 4ms/step\n",
            "Epoch 56/150\n",
            "35/35 - 0s - loss: 95275.1172 - accuracy: 0.6033 - val_loss: 23068.4141 - val_accuracy: 0.6223 - 125ms/epoch - 4ms/step\n",
            "Epoch 57/150\n",
            "35/35 - 0s - loss: 95273.6328 - accuracy: 0.6033 - val_loss: 23066.8145 - val_accuracy: 0.6223 - 162ms/epoch - 5ms/step\n",
            "Epoch 58/150\n",
            "35/35 - 0s - loss: 95272.2109 - accuracy: 0.6033 - val_loss: 23065.2832 - val_accuracy: 0.6223 - 130ms/epoch - 4ms/step\n",
            "Epoch 59/150\n",
            "35/35 - 0s - loss: 95270.8047 - accuracy: 0.6033 - val_loss: 23063.6934 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 60/150\n",
            "35/35 - 0s - loss: 95269.3750 - accuracy: 0.6033 - val_loss: 23062.1738 - val_accuracy: 0.6223 - 138ms/epoch - 4ms/step\n",
            "Epoch 61/150\n",
            "35/35 - 0s - loss: 95267.9688 - accuracy: 0.6033 - val_loss: 23060.6367 - val_accuracy: 0.6223 - 163ms/epoch - 5ms/step\n",
            "Epoch 62/150\n",
            "35/35 - 0s - loss: 95266.5938 - accuracy: 0.6033 - val_loss: 23059.1172 - val_accuracy: 0.6223 - 142ms/epoch - 4ms/step\n",
            "Epoch 63/150\n",
            "35/35 - 0s - loss: 95265.2734 - accuracy: 0.6033 - val_loss: 23057.6875 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 64/150\n",
            "35/35 - 0s - loss: 95263.9766 - accuracy: 0.6033 - val_loss: 23056.2656 - val_accuracy: 0.6223 - 154ms/epoch - 4ms/step\n",
            "Epoch 65/150\n",
            "35/35 - 0s - loss: 95262.6562 - accuracy: 0.6033 - val_loss: 23054.8301 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 66/150\n",
            "35/35 - 0s - loss: 95261.3125 - accuracy: 0.6033 - val_loss: 23053.3691 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 67/150\n",
            "35/35 - 0s - loss: 95260.0156 - accuracy: 0.6033 - val_loss: 23051.9277 - val_accuracy: 0.6223 - 164ms/epoch - 5ms/step\n",
            "Epoch 68/150\n",
            "35/35 - 0s - loss: 95258.7109 - accuracy: 0.6033 - val_loss: 23050.4648 - val_accuracy: 0.6223 - 122ms/epoch - 3ms/step\n",
            "Epoch 69/150\n",
            "35/35 - 0s - loss: 95257.4297 - accuracy: 0.6033 - val_loss: 23049.0332 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 70/150\n",
            "35/35 - 0s - loss: 95256.2031 - accuracy: 0.6033 - val_loss: 23047.6934 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 71/150\n",
            "35/35 - 0s - loss: 95254.9688 - accuracy: 0.6033 - val_loss: 23046.3027 - val_accuracy: 0.6223 - 125ms/epoch - 4ms/step\n",
            "Epoch 72/150\n",
            "35/35 - 0s - loss: 95253.7188 - accuracy: 0.6033 - val_loss: 23044.9531 - val_accuracy: 0.6223 - 122ms/epoch - 3ms/step\n",
            "Epoch 73/150\n",
            "35/35 - 0s - loss: 95252.4922 - accuracy: 0.6033 - val_loss: 23043.5762 - val_accuracy: 0.6223 - 128ms/epoch - 4ms/step\n",
            "Epoch 74/150\n",
            "35/35 - 0s - loss: 95251.2734 - accuracy: 0.6033 - val_loss: 23042.2129 - val_accuracy: 0.6223 - 130ms/epoch - 4ms/step\n",
            "Epoch 75/150\n",
            "35/35 - 0s - loss: 95250.0469 - accuracy: 0.6033 - val_loss: 23040.8633 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 76/150\n",
            "35/35 - 0s - loss: 95248.8203 - accuracy: 0.6033 - val_loss: 23039.5059 - val_accuracy: 0.6223 - 120ms/epoch - 3ms/step\n",
            "Epoch 77/150\n",
            "35/35 - 0s - loss: 95247.6328 - accuracy: 0.6033 - val_loss: 23038.1836 - val_accuracy: 0.6223 - 159ms/epoch - 5ms/step\n",
            "Epoch 78/150\n",
            "35/35 - 0s - loss: 95246.4609 - accuracy: 0.6033 - val_loss: 23036.8613 - val_accuracy: 0.6223 - 121ms/epoch - 3ms/step\n",
            "Epoch 79/150\n",
            "35/35 - 0s - loss: 95245.2891 - accuracy: 0.6033 - val_loss: 23035.5508 - val_accuracy: 0.6223 - 158ms/epoch - 5ms/step\n",
            "Epoch 80/150\n",
            "35/35 - 0s - loss: 95244.1562 - accuracy: 0.6033 - val_loss: 23034.2871 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 81/150\n",
            "35/35 - 0s - loss: 95242.9922 - accuracy: 0.6033 - val_loss: 23032.9980 - val_accuracy: 0.6223 - 158ms/epoch - 5ms/step\n",
            "Epoch 82/150\n",
            "35/35 - 0s - loss: 95241.9531 - accuracy: 0.6033 - val_loss: 23031.8242 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 83/150\n",
            "35/35 - 0s - loss: 95240.8359 - accuracy: 0.6033 - val_loss: 23030.5508 - val_accuracy: 0.6223 - 158ms/epoch - 5ms/step\n",
            "Epoch 84/150\n",
            "35/35 - 0s - loss: 95239.8125 - accuracy: 0.6033 - val_loss: 23029.3965 - val_accuracy: 0.6223 - 120ms/epoch - 3ms/step\n",
            "Epoch 85/150\n",
            "35/35 - 0s - loss: 95238.7578 - accuracy: 0.6033 - val_loss: 23028.1406 - val_accuracy: 0.6223 - 162ms/epoch - 5ms/step\n",
            "Epoch 86/150\n",
            "35/35 - 0s - loss: 95237.7188 - accuracy: 0.6033 - val_loss: 23026.9395 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 87/150\n",
            "35/35 - 0s - loss: 95236.6719 - accuracy: 0.6033 - val_loss: 23025.7363 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 88/150\n",
            "35/35 - 0s - loss: 95235.5781 - accuracy: 0.6033 - val_loss: 23024.4941 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 89/150\n",
            "35/35 - 0s - loss: 95234.5703 - accuracy: 0.6033 - val_loss: 23023.3828 - val_accuracy: 0.6223 - 134ms/epoch - 4ms/step\n",
            "Epoch 90/150\n",
            "35/35 - 0s - loss: 95233.5703 - accuracy: 0.6033 - val_loss: 23022.1699 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 91/150\n",
            "35/35 - 0s - loss: 95232.5938 - accuracy: 0.6033 - val_loss: 23021.0488 - val_accuracy: 0.6223 - 166ms/epoch - 5ms/step\n",
            "Epoch 92/150\n",
            "35/35 - 0s - loss: 95231.5625 - accuracy: 0.6033 - val_loss: 23019.8594 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 93/150\n",
            "35/35 - 0s - loss: 95230.5234 - accuracy: 0.6033 - val_loss: 23018.6426 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 94/150\n",
            "35/35 - 0s - loss: 95229.4609 - accuracy: 0.6033 - val_loss: 23017.4570 - val_accuracy: 0.6223 - 159ms/epoch - 5ms/step\n",
            "Epoch 95/150\n",
            "35/35 - 0s - loss: 95228.4531 - accuracy: 0.6033 - val_loss: 23016.2695 - val_accuracy: 0.6223 - 143ms/epoch - 4ms/step\n",
            "Epoch 96/150\n",
            "35/35 - 0s - loss: 95227.4297 - accuracy: 0.6033 - val_loss: 23015.1582 - val_accuracy: 0.6223 - 170ms/epoch - 5ms/step\n",
            "Epoch 97/150\n",
            "35/35 - 0s - loss: 95226.5078 - accuracy: 0.6033 - val_loss: 23014.1035 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 98/150\n",
            "35/35 - 0s - loss: 95225.6094 - accuracy: 0.6033 - val_loss: 23013.0605 - val_accuracy: 0.6223 - 163ms/epoch - 5ms/step\n",
            "Epoch 99/150\n",
            "35/35 - 0s - loss: 95224.6484 - accuracy: 0.6033 - val_loss: 23011.9414 - val_accuracy: 0.6223 - 157ms/epoch - 4ms/step\n",
            "Epoch 100/150\n",
            "35/35 - 0s - loss: 95223.6562 - accuracy: 0.6033 - val_loss: 23010.7812 - val_accuracy: 0.6223 - 155ms/epoch - 4ms/step\n",
            "Epoch 101/150\n",
            "35/35 - 0s - loss: 95222.6484 - accuracy: 0.6033 - val_loss: 23009.6465 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 102/150\n",
            "35/35 - 0s - loss: 95221.6953 - accuracy: 0.6033 - val_loss: 23008.5566 - val_accuracy: 0.6223 - 122ms/epoch - 3ms/step\n",
            "Epoch 103/150\n",
            "35/35 - 0s - loss: 95220.7344 - accuracy: 0.6033 - val_loss: 23007.4082 - val_accuracy: 0.6223 - 163ms/epoch - 5ms/step\n",
            "Epoch 104/150\n",
            "35/35 - 0s - loss: 95219.7344 - accuracy: 0.6033 - val_loss: 23006.2793 - val_accuracy: 0.6223 - 157ms/epoch - 4ms/step\n",
            "Epoch 105/150\n",
            "35/35 - 0s - loss: 95218.7578 - accuracy: 0.6033 - val_loss: 23005.1426 - val_accuracy: 0.6223 - 154ms/epoch - 4ms/step\n",
            "Epoch 106/150\n",
            "35/35 - 0s - loss: 95217.7812 - accuracy: 0.6033 - val_loss: 23004.0469 - val_accuracy: 0.6223 - 161ms/epoch - 5ms/step\n",
            "Epoch 107/150\n",
            "35/35 - 0s - loss: 95216.8047 - accuracy: 0.6033 - val_loss: 23002.9258 - val_accuracy: 0.6223 - 160ms/epoch - 5ms/step\n",
            "Epoch 108/150\n",
            "35/35 - 0s - loss: 95215.8438 - accuracy: 0.6033 - val_loss: 23001.8262 - val_accuracy: 0.6223 - 122ms/epoch - 3ms/step\n",
            "Epoch 109/150\n",
            "35/35 - 0s - loss: 95214.8828 - accuracy: 0.6033 - val_loss: 23000.7188 - val_accuracy: 0.6223 - 131ms/epoch - 4ms/step\n",
            "Epoch 110/150\n",
            "35/35 - 0s - loss: 95213.9688 - accuracy: 0.6033 - val_loss: 22999.6738 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 111/150\n",
            "35/35 - 0s - loss: 95213.0234 - accuracy: 0.6033 - val_loss: 22998.5820 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 112/150\n",
            "35/35 - 0s - loss: 95212.1250 - accuracy: 0.6033 - val_loss: 22997.5176 - val_accuracy: 0.6223 - 118ms/epoch - 3ms/step\n",
            "Epoch 113/150\n",
            "35/35 - 0s - loss: 95211.1875 - accuracy: 0.6033 - val_loss: 22996.4805 - val_accuracy: 0.6223 - 122ms/epoch - 3ms/step\n",
            "Epoch 114/150\n",
            "35/35 - 0s - loss: 95210.3672 - accuracy: 0.6033 - val_loss: 22995.5020 - val_accuracy: 0.6223 - 125ms/epoch - 4ms/step\n",
            "Epoch 115/150\n",
            "35/35 - 0s - loss: 95209.4609 - accuracy: 0.6033 - val_loss: 22994.4609 - val_accuracy: 0.6223 - 125ms/epoch - 4ms/step\n",
            "Epoch 116/150\n",
            "35/35 - 0s - loss: 95208.6172 - accuracy: 0.6033 - val_loss: 22993.5273 - val_accuracy: 0.6223 - 160ms/epoch - 5ms/step\n",
            "Epoch 117/150\n",
            "35/35 - 0s - loss: 95207.7969 - accuracy: 0.6033 - val_loss: 22992.4883 - val_accuracy: 0.6223 - 137ms/epoch - 4ms/step\n",
            "Epoch 118/150\n",
            "35/35 - 0s - loss: 95206.9531 - accuracy: 0.6033 - val_loss: 22991.4902 - val_accuracy: 0.6223 - 156ms/epoch - 4ms/step\n",
            "Epoch 119/150\n",
            "35/35 - 0s - loss: 95206.1797 - accuracy: 0.6033 - val_loss: 22990.5820 - val_accuracy: 0.6223 - 120ms/epoch - 3ms/step\n",
            "Epoch 120/150\n",
            "35/35 - 0s - loss: 95205.3984 - accuracy: 0.6033 - val_loss: 22989.6641 - val_accuracy: 0.6223 - 121ms/epoch - 3ms/step\n",
            "Epoch 121/150\n",
            "35/35 - 0s - loss: 95204.6016 - accuracy: 0.6033 - val_loss: 22988.6992 - val_accuracy: 0.6223 - 161ms/epoch - 5ms/step\n",
            "Epoch 122/150\n",
            "35/35 - 0s - loss: 95203.7969 - accuracy: 0.6033 - val_loss: 22987.7383 - val_accuracy: 0.6223 - 125ms/epoch - 4ms/step\n",
            "Epoch 123/150\n",
            "35/35 - 0s - loss: 95203.0000 - accuracy: 0.6033 - val_loss: 22986.7754 - val_accuracy: 0.6223 - 156ms/epoch - 4ms/step\n",
            "Epoch 124/150\n",
            "35/35 - 0s - loss: 95202.1719 - accuracy: 0.6033 - val_loss: 22985.8047 - val_accuracy: 0.6223 - 131ms/epoch - 4ms/step\n",
            "Epoch 125/150\n",
            "35/35 - 0s - loss: 95201.3281 - accuracy: 0.6033 - val_loss: 22984.8086 - val_accuracy: 0.6223 - 155ms/epoch - 4ms/step\n",
            "Epoch 126/150\n",
            "35/35 - 0s - loss: 95200.4688 - accuracy: 0.6033 - val_loss: 22983.8086 - val_accuracy: 0.6223 - 164ms/epoch - 5ms/step\n",
            "Epoch 127/150\n",
            "35/35 - 0s - loss: 95199.6250 - accuracy: 0.6033 - val_loss: 22982.7969 - val_accuracy: 0.6223 - 118ms/epoch - 3ms/step\n",
            "Epoch 128/150\n",
            "35/35 - 0s - loss: 95198.8047 - accuracy: 0.6033 - val_loss: 22981.8164 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 129/150\n",
            "35/35 - 0s - loss: 95197.9531 - accuracy: 0.6033 - val_loss: 22980.8633 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 130/150\n",
            "35/35 - 0s - loss: 95197.1719 - accuracy: 0.6033 - val_loss: 22979.8711 - val_accuracy: 0.6223 - 130ms/epoch - 4ms/step\n",
            "Epoch 131/150\n",
            "35/35 - 0s - loss: 95196.3516 - accuracy: 0.6033 - val_loss: 22978.9336 - val_accuracy: 0.6223 - 129ms/epoch - 4ms/step\n",
            "Epoch 132/150\n",
            "35/35 - 0s - loss: 95195.5312 - accuracy: 0.6033 - val_loss: 22977.9805 - val_accuracy: 0.6223 - 158ms/epoch - 5ms/step\n",
            "Epoch 133/150\n",
            "35/35 - 0s - loss: 95194.7578 - accuracy: 0.6033 - val_loss: 22977.0566 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 134/150\n",
            "35/35 - 0s - loss: 95193.9531 - accuracy: 0.6033 - val_loss: 22976.1055 - val_accuracy: 0.6223 - 152ms/epoch - 4ms/step\n",
            "Epoch 135/150\n",
            "35/35 - 0s - loss: 95193.1562 - accuracy: 0.6033 - val_loss: 22975.1699 - val_accuracy: 0.6223 - 123ms/epoch - 4ms/step\n",
            "Epoch 136/150\n",
            "35/35 - 0s - loss: 95192.3672 - accuracy: 0.6033 - val_loss: 22974.2383 - val_accuracy: 0.6223 - 155ms/epoch - 4ms/step\n",
            "Epoch 137/150\n",
            "35/35 - 0s - loss: 95191.6250 - accuracy: 0.6033 - val_loss: 22973.3457 - val_accuracy: 0.6223 - 131ms/epoch - 4ms/step\n",
            "Epoch 138/150\n",
            "35/35 - 0s - loss: 95190.8516 - accuracy: 0.6033 - val_loss: 22972.4648 - val_accuracy: 0.6223 - 122ms/epoch - 3ms/step\n",
            "Epoch 139/150\n",
            "35/35 - 0s - loss: 95190.0859 - accuracy: 0.6033 - val_loss: 22971.5645 - val_accuracy: 0.6223 - 158ms/epoch - 5ms/step\n",
            "Epoch 140/150\n",
            "35/35 - 0s - loss: 95189.3359 - accuracy: 0.6033 - val_loss: 22970.6934 - val_accuracy: 0.6223 - 155ms/epoch - 4ms/step\n",
            "Epoch 141/150\n",
            "35/35 - 0s - loss: 95188.5859 - accuracy: 0.6033 - val_loss: 22969.8164 - val_accuracy: 0.6223 - 127ms/epoch - 4ms/step\n",
            "Epoch 142/150\n",
            "35/35 - 0s - loss: 95187.8047 - accuracy: 0.6033 - val_loss: 22968.9434 - val_accuracy: 0.6223 - 126ms/epoch - 4ms/step\n",
            "Epoch 143/150\n",
            "35/35 - 0s - loss: 95187.0391 - accuracy: 0.6033 - val_loss: 22968.0645 - val_accuracy: 0.6223 - 154ms/epoch - 4ms/step\n",
            "Epoch 144/150\n",
            "35/35 - 0s - loss: 95186.2891 - accuracy: 0.6033 - val_loss: 22967.1562 - val_accuracy: 0.6223 - 119ms/epoch - 3ms/step\n",
            "Epoch 145/150\n",
            "35/35 - 0s - loss: 95185.5000 - accuracy: 0.6033 - val_loss: 22966.2812 - val_accuracy: 0.6223 - 154ms/epoch - 4ms/step\n",
            "Epoch 146/150\n",
            "35/35 - 0s - loss: 95184.7422 - accuracy: 0.6033 - val_loss: 22965.4023 - val_accuracy: 0.6223 - 121ms/epoch - 3ms/step\n",
            "Epoch 147/150\n",
            "35/35 - 0s - loss: 95183.9766 - accuracy: 0.6033 - val_loss: 22964.5410 - val_accuracy: 0.6223 - 154ms/epoch - 4ms/step\n",
            "Epoch 148/150\n",
            "35/35 - 0s - loss: 95183.2969 - accuracy: 0.6033 - val_loss: 22963.7598 - val_accuracy: 0.6223 - 124ms/epoch - 4ms/step\n",
            "Epoch 149/150\n",
            "35/35 - 0s - loss: 95182.5469 - accuracy: 0.6033 - val_loss: 22962.8848 - val_accuracy: 0.6223 - 161ms/epoch - 5ms/step\n",
            "Epoch 150/150\n",
            "35/35 - 0s - loss: 95181.8125 - accuracy: 0.6033 - val_loss: 22962.0078 - val_accuracy: 0.6223 - 122ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e70653710>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_Y= model.predict(val_X)"
      ],
      "metadata": {
        "id": "FizXgIuoGXs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_Y[:10,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSs_DWWyQY8Q",
        "outputId": "51c7dd08-4b8a-4247-879b-28c8534b8cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([635.32135, 635.32135, 635.32135, 635.32135, 635.32135, 635.32135,\n",
              "       635.32135, 635.32135, 635.32135, 635.32135], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = pd.DataFrame({'Actual': val_Y.iloc[:,0] , 'Predicted': pred_Y[:,0]})  \n",
        "result1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vmmncKiwnOy-",
        "outputId": "52550063-6aea-44a0-cdf4-7d3b8000d4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Actual  Predicted\n",
              "695    1289.0  635.32135\n",
              "1513    772.0  635.32135\n",
              "1896   8176.0  635.32135\n",
              "519    2617.0  635.32135\n",
              "651   19463.0  635.32135\n",
              "...       ...        ...\n",
              "728     391.0  635.32135\n",
              "793    9557.0  635.32135\n",
              "898    1844.0  635.32135\n",
              "634    8403.0  635.32135\n",
              "232    1940.0  635.32135\n",
              "\n",
              "[751 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cad3ac4-622a-4990-ac80-89df7d839c77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>1289.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>772.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>8176.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>2617.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>19463.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>391.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>9557.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>1844.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>8403.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>1940.0</td>\n",
              "      <td>635.32135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>751 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cad3ac4-622a-4990-ac80-89df7d839c77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cad3ac4-622a-4990-ac80-89df7d839c77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cad3ac4-622a-4990-ac80-89df7d839c77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result2 = pd.DataFrame({'Actual': val_Y.iloc[:,1] , 'Predicted': pred_Y[:,1]})  \n",
        "result2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "KUGQJSpvncE_",
        "outputId": "3988af88-b5c0-4037-e3c7-490587e6ccd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Actual   Predicted\n",
              "695     631.0  410.785065\n",
              "1513    141.0  410.785065\n",
              "1896    234.0  410.785065\n",
              "519     581.0  410.785065\n",
              "651    2383.0  410.785065\n",
              "...       ...         ...\n",
              "728     242.0  410.785065\n",
              "793     821.0  410.785065\n",
              "898     418.0  410.785065\n",
              "634   13974.0  410.785065\n",
              "232     158.0  410.785065\n",
              "\n",
              "[751 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1952ea1-0773-4ec7-86f7-6c8f2b92adb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>631.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1513</th>\n",
              "      <td>141.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1896</th>\n",
              "      <td>234.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>581.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>651</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>242.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>793</th>\n",
              "      <td>821.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>418.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>13974.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>158.0</td>\n",
              "      <td>410.785065</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>751 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1952ea1-0773-4ec7-86f7-6c8f2b92adb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1952ea1-0773-4ec7-86f7-6c8f2b92adb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1952ea1-0773-4ec7-86f7-6c8f2b92adb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"y1 MSE:%.4f\" % mean_absolute_error(val_Y.iloc[:,0], pred_Y[:,0]))\n",
        "print(\"y2 MSE:%.4f\" % mean_absolute_error(val_Y.iloc[:,1], pred_Y[:,1]))\n",
        "print(\"y3 MSE:%.4f\" % mean_absolute_error(val_Y.iloc[:,2], pred_Y[:,2]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqlBwRDJG3iP",
        "outputId": "e7827e4c-ef18-49be-86b5-71230e0e53d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y1 MSE:57303.6772\n",
            "y2 MSE:4930.0812\n",
            "y3 MSE:87653.6392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_ax = range(len(val_X))\n",
        "plt.scatter(x_ax, val_Y.iloc[:,0],  s=6, c='y', label=\"y1-test\")\n",
        "plt.plot(x_ax, pred_Y[:,0], label=\"y1-pred\")\n",
        "plt.ylim(0,100000)\n",
        "plt.xlim(0,60)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "lROmTLYqT4xR",
        "outputId": "f7b7fa4d-e1c4-4cc1-ebd9-a2289455f3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian Optimization\n",
        "#Définissez le choix et la plage de chaque paramètre.\n",
        "#Remarque: le paramètre est type: continuous、type:Doit être écrit dans un ordre discret.\n",
        "#Sinon, une erreur se produira dans le processus suivant.\n",
        "bounds = [{'name': 'validation_split', 'type': 'continuous',  'domain': (0.0, 0.3)},\n",
        "          {'name': 'l1_out',           'type': 'discrete',    'domain': (8, 16, 32, 64, 128)},\n",
        "          {'name': 'l2_out',           'type': 'discrete',    'domain': (8, 16, 32, 64, 128)},\n",
        "          {'name': 'batch_size',       'type': 'discrete',    'domain': (20, 30, 40, 50, 60)},\n",
        "          {'name': 'epochs',           'type': 'discrete',    'domain': (100, 150, 200, 250)},\n",
        "          {'name': 'l3_out',           'type': 'discrete',    'domain': (8, 16, 32, 64, 128)},\n",
        "          {'name': 'l4_out',           'type': 'discrete',    'domain': (8, 16, 32, 64, 128)}]\n",
        "\n",
        "#Définissez une fonction pour l'optimisation bayésienne (boîte noire décrite ci-dessus).\n",
        "#x est l'entrée et la sortie est renvoyée.\n",
        "def f(x):\n",
        "    print(x)\n",
        "    l1_out = int(x[:,1]),\n",
        "    l2_out = int(x[:,2]),\n",
        "    l3_out = int(x[:,5]),\n",
        "    l4_out = int(x[:,6]),\n",
        "    batch_size = int(x[:,3]), \n",
        "    epochs = int(x[:,4]), \n",
        "    validation_split = float(x[:,0])\n",
        "    print('l1',str(l1_out[0]))\n",
        "    print ('epochs',str(epochs[0]))\n",
        "    print(batch_size[0])\n",
        "    print(validation_split)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(l1_out[0], input_dim=first_input ,kernel_initializer='he_uniform', activation='elu'))\n",
        "    model.add(Dense(l2_out[0], activation='elu'))\n",
        "    model.add(Dense(l3_out[0], activation='elu'))\n",
        "    model.add(Dense(l4_out[0], activation='elu'))\n",
        "    model.add(Dense(last_output))\n",
        "\n",
        "    model.compile(loss='mae', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_X, train_Y,verbose=2, epochs=epochs[0], batch_size=batch_size[0], validation_split=validation_split)\n",
        "    evaluation = model.evaluate(val_X, val_Y, batch_size=batch_size[0], verbose=0)\n",
        "    return evaluation[0]\n",
        "\n",
        "#Effectuez une recherche préliminaire.\n",
        "opt_mnist = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds)\n",
        "\n",
        "#Recherchez les meilleurs paramètres.\n",
        "opt_mnist.run_optimization(max_iter=20)\n",
        "print(\"optimized parameters: {0}\".format(opt_mnist.x_opt))\n",
        "print(\"optimized loss: {0}\".format(opt_mnist.fx_opt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf7_npQWclvh",
        "outputId": "a9eae768-84e2-4781-870a-821287e209f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "23/23 - 0s - loss: 78701.4141 - accuracy: 0.5793 - val_loss: 19553.9180 - val_accuracy: 0.6321 - 100ms/epoch - 4ms/step\n",
            "Epoch 138/250\n",
            "23/23 - 0s - loss: 78667.5703 - accuracy: 0.5725 - val_loss: 19445.4336 - val_accuracy: 0.6477 - 78ms/epoch - 3ms/step\n",
            "Epoch 139/250\n",
            "23/23 - 0s - loss: 78605.1172 - accuracy: 0.5988 - val_loss: 19432.4922 - val_accuracy: 0.6010 - 87ms/epoch - 4ms/step\n",
            "Epoch 140/250\n",
            "23/23 - 0s - loss: 78690.0234 - accuracy: 0.5702 - val_loss: 19662.3496 - val_accuracy: 0.6477 - 80ms/epoch - 3ms/step\n",
            "Epoch 141/250\n",
            "23/23 - 0s - loss: 78852.1250 - accuracy: 0.4628 - val_loss: 19390.9473 - val_accuracy: 0.6425 - 78ms/epoch - 3ms/step\n",
            "Epoch 142/250\n",
            "23/23 - 0s - loss: 78676.2188 - accuracy: 0.5702 - val_loss: 19520.7910 - val_accuracy: 0.5959 - 81ms/epoch - 4ms/step\n",
            "Epoch 143/250\n",
            "23/23 - 0s - loss: 78691.5078 - accuracy: 0.5763 - val_loss: 19447.4668 - val_accuracy: 0.6425 - 77ms/epoch - 3ms/step\n",
            "Epoch 144/250\n",
            "23/23 - 0s - loss: 78681.2578 - accuracy: 0.5620 - val_loss: 19460.3867 - val_accuracy: 0.6321 - 95ms/epoch - 4ms/step\n",
            "Epoch 145/250\n",
            "23/23 - 0s - loss: 78681.9453 - accuracy: 0.5778 - val_loss: 19382.5098 - val_accuracy: 0.6269 - 91ms/epoch - 4ms/step\n",
            "Epoch 146/250\n",
            "23/23 - 0s - loss: 78657.9375 - accuracy: 0.5748 - val_loss: 19466.6973 - val_accuracy: 0.6010 - 83ms/epoch - 4ms/step\n",
            "Epoch 147/250\n",
            "23/23 - 0s - loss: 78620.0547 - accuracy: 0.5755 - val_loss: 19413.1875 - val_accuracy: 0.6269 - 85ms/epoch - 4ms/step\n",
            "Epoch 148/250\n",
            "23/23 - 0s - loss: 78600.0938 - accuracy: 0.5800 - val_loss: 19351.0117 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 149/250\n",
            "23/23 - 0s - loss: 78583.8594 - accuracy: 0.5154 - val_loss: 19414.7285 - val_accuracy: 0.6062 - 103ms/epoch - 4ms/step\n",
            "Epoch 150/250\n",
            "23/23 - 0s - loss: 78739.8672 - accuracy: 0.5282 - val_loss: 19688.9863 - val_accuracy: 0.6010 - 80ms/epoch - 3ms/step\n",
            "Epoch 151/250\n",
            "23/23 - 0s - loss: 78746.7500 - accuracy: 0.5357 - val_loss: 19671.9102 - val_accuracy: 0.6218 - 98ms/epoch - 4ms/step\n",
            "Epoch 152/250\n",
            "23/23 - 0s - loss: 78627.0078 - accuracy: 0.5642 - val_loss: 19475.1875 - val_accuracy: 0.6425 - 77ms/epoch - 3ms/step\n",
            "Epoch 153/250\n",
            "23/23 - 0s - loss: 78627.4219 - accuracy: 0.5710 - val_loss: 19499.0293 - val_accuracy: 0.5959 - 77ms/epoch - 3ms/step\n",
            "Epoch 154/250\n",
            "23/23 - 0s - loss: 78617.1562 - accuracy: 0.5785 - val_loss: 19342.7090 - val_accuracy: 0.6528 - 98ms/epoch - 4ms/step\n",
            "Epoch 155/250\n",
            "23/23 - 0s - loss: 78576.0391 - accuracy: 0.5552 - val_loss: 19371.5000 - val_accuracy: 0.6269 - 79ms/epoch - 3ms/step\n",
            "Epoch 156/250\n",
            "23/23 - 0s - loss: 78614.1172 - accuracy: 0.5763 - val_loss: 19352.9395 - val_accuracy: 0.6528 - 74ms/epoch - 3ms/step\n",
            "Epoch 157/250\n",
            "23/23 - 0s - loss: 78465.3984 - accuracy: 0.5913 - val_loss: 19246.5820 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 158/250\n",
            "23/23 - 0s - loss: 78506.5859 - accuracy: 0.5687 - val_loss: 19339.5020 - val_accuracy: 0.6528 - 87ms/epoch - 4ms/step\n",
            "Epoch 159/250\n",
            "23/23 - 0s - loss: 78430.4844 - accuracy: 0.6033 - val_loss: 19531.2227 - val_accuracy: 0.6528 - 79ms/epoch - 3ms/step\n",
            "Epoch 160/250\n",
            "23/23 - 0s - loss: 78657.2578 - accuracy: 0.4778 - val_loss: 19319.2148 - val_accuracy: 0.6477 - 91ms/epoch - 4ms/step\n",
            "Epoch 161/250\n",
            "23/23 - 0s - loss: 78536.1328 - accuracy: 0.5763 - val_loss: 19332.8438 - val_accuracy: 0.6321 - 106ms/epoch - 5ms/step\n",
            "Epoch 162/250\n",
            "23/23 - 0s - loss: 78498.5859 - accuracy: 0.5920 - val_loss: 19241.3535 - val_accuracy: 0.6528 - 98ms/epoch - 4ms/step\n",
            "Epoch 163/250\n",
            "23/23 - 0s - loss: 78435.7266 - accuracy: 0.6011 - val_loss: 19787.4141 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 164/250\n",
            "23/23 - 0s - loss: 78460.5000 - accuracy: 0.6041 - val_loss: 19298.5742 - val_accuracy: 0.6528 - 96ms/epoch - 4ms/step\n",
            "Epoch 165/250\n",
            "23/23 - 0s - loss: 78480.3281 - accuracy: 0.6018 - val_loss: 19396.5957 - val_accuracy: 0.5699 - 76ms/epoch - 3ms/step\n",
            "Epoch 166/250\n",
            "23/23 - 0s - loss: 78592.2500 - accuracy: 0.5041 - val_loss: 19397.2129 - val_accuracy: 0.6218 - 83ms/epoch - 4ms/step\n",
            "Epoch 167/250\n",
            "23/23 - 0s - loss: 78556.6484 - accuracy: 0.5748 - val_loss: 19330.8457 - val_accuracy: 0.6218 - 76ms/epoch - 3ms/step\n",
            "Epoch 168/250\n",
            "23/23 - 0s - loss: 78506.2578 - accuracy: 0.5718 - val_loss: 19345.7852 - val_accuracy: 0.6269 - 75ms/epoch - 3ms/step\n",
            "Epoch 169/250\n",
            "23/23 - 0s - loss: 78581.1719 - accuracy: 0.5612 - val_loss: 19355.7949 - val_accuracy: 0.6269 - 76ms/epoch - 3ms/step\n",
            "Epoch 170/250\n",
            "23/23 - 0s - loss: 78585.1953 - accuracy: 0.5552 - val_loss: 19222.0254 - val_accuracy: 0.6528 - 82ms/epoch - 4ms/step\n",
            "Epoch 171/250\n",
            "23/23 - 0s - loss: 78462.5391 - accuracy: 0.5672 - val_loss: 19437.9258 - val_accuracy: 0.6528 - 92ms/epoch - 4ms/step\n",
            "Epoch 172/250\n",
            "23/23 - 0s - loss: 78485.8516 - accuracy: 0.6026 - val_loss: 19257.1914 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 173/250\n",
            "23/23 - 0s - loss: 78452.9609 - accuracy: 0.6011 - val_loss: 19349.0703 - val_accuracy: 0.6528 - 81ms/epoch - 4ms/step\n",
            "Epoch 174/250\n",
            "23/23 - 0s - loss: 78391.3203 - accuracy: 0.6033 - val_loss: 19333.5781 - val_accuracy: 0.6528 - 92ms/epoch - 4ms/step\n",
            "Epoch 175/250\n",
            "23/23 - 0s - loss: 78456.6719 - accuracy: 0.5838 - val_loss: 19291.6426 - val_accuracy: 0.6321 - 75ms/epoch - 3ms/step\n",
            "Epoch 176/250\n",
            "23/23 - 0s - loss: 78374.8672 - accuracy: 0.5988 - val_loss: 19245.5293 - val_accuracy: 0.6528 - 82ms/epoch - 4ms/step\n",
            "Epoch 177/250\n",
            "23/23 - 0s - loss: 78375.7500 - accuracy: 0.6026 - val_loss: 19333.8438 - val_accuracy: 0.6528 - 82ms/epoch - 4ms/step\n",
            "Epoch 178/250\n",
            "23/23 - 0s - loss: 78397.4297 - accuracy: 0.6026 - val_loss: 19357.4629 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 179/250\n",
            "23/23 - 0s - loss: 78449.0000 - accuracy: 0.5800 - val_loss: 19422.9980 - val_accuracy: 0.6528 - 77ms/epoch - 3ms/step\n",
            "Epoch 180/250\n",
            "23/23 - 0s - loss: 78432.4609 - accuracy: 0.5755 - val_loss: 19375.7402 - val_accuracy: 0.6580 - 76ms/epoch - 3ms/step\n",
            "Epoch 181/250\n",
            "23/23 - 0s - loss: 78425.8594 - accuracy: 0.5898 - val_loss: 19464.0957 - val_accuracy: 0.6373 - 81ms/epoch - 4ms/step\n",
            "Epoch 182/250\n",
            "23/23 - 0s - loss: 78458.0781 - accuracy: 0.5853 - val_loss: 19456.5898 - val_accuracy: 0.6580 - 96ms/epoch - 4ms/step\n",
            "Epoch 183/250\n",
            "23/23 - 0s - loss: 78465.7656 - accuracy: 0.5785 - val_loss: 19291.4219 - val_accuracy: 0.6373 - 91ms/epoch - 4ms/step\n",
            "Epoch 184/250\n",
            "23/23 - 0s - loss: 78375.8281 - accuracy: 0.6041 - val_loss: 19240.6035 - val_accuracy: 0.6528 - 96ms/epoch - 4ms/step\n",
            "Epoch 185/250\n",
            "23/23 - 0s - loss: 78422.4766 - accuracy: 0.5958 - val_loss: 19397.4766 - val_accuracy: 0.6528 - 84ms/epoch - 4ms/step\n",
            "Epoch 186/250\n",
            "23/23 - 0s - loss: 78424.0234 - accuracy: 0.5920 - val_loss: 19433.5762 - val_accuracy: 0.6528 - 81ms/epoch - 4ms/step\n",
            "Epoch 187/250\n",
            "23/23 - 0s - loss: 78464.8203 - accuracy: 0.5823 - val_loss: 19327.1016 - val_accuracy: 0.6062 - 76ms/epoch - 3ms/step\n",
            "Epoch 188/250\n",
            "23/23 - 0s - loss: 78442.5469 - accuracy: 0.5943 - val_loss: 19275.2188 - val_accuracy: 0.6528 - 75ms/epoch - 3ms/step\n",
            "Epoch 189/250\n",
            "23/23 - 0s - loss: 78444.0547 - accuracy: 0.5687 - val_loss: 19376.1094 - val_accuracy: 0.6425 - 80ms/epoch - 3ms/step\n",
            "Epoch 190/250\n",
            "23/23 - 0s - loss: 78416.0938 - accuracy: 0.5672 - val_loss: 19260.7129 - val_accuracy: 0.6528 - 90ms/epoch - 4ms/step\n",
            "Epoch 191/250\n",
            "23/23 - 0s - loss: 78589.7656 - accuracy: 0.4500 - val_loss: 19549.4121 - val_accuracy: 0.6425 - 84ms/epoch - 4ms/step\n",
            "Epoch 192/250\n",
            "23/23 - 0s - loss: 78486.2656 - accuracy: 0.5755 - val_loss: 19327.9062 - val_accuracy: 0.6477 - 78ms/epoch - 3ms/step\n",
            "Epoch 193/250\n",
            "23/23 - 0s - loss: 78450.7812 - accuracy: 0.5748 - val_loss: 19356.6523 - val_accuracy: 0.6425 - 80ms/epoch - 3ms/step\n",
            "Epoch 194/250\n",
            "23/23 - 0s - loss: 78419.2188 - accuracy: 0.5913 - val_loss: 19309.6934 - val_accuracy: 0.6321 - 88ms/epoch - 4ms/step\n",
            "Epoch 195/250\n",
            "23/23 - 0s - loss: 78445.8359 - accuracy: 0.5853 - val_loss: 19599.4551 - val_accuracy: 0.5596 - 87ms/epoch - 4ms/step\n",
            "Epoch 196/250\n",
            "23/23 - 0s - loss: 78512.5938 - accuracy: 0.5860 - val_loss: 19513.8438 - val_accuracy: 0.5648 - 92ms/epoch - 4ms/step\n",
            "Epoch 197/250\n",
            "23/23 - 0s - loss: 78437.9531 - accuracy: 0.5778 - val_loss: 19620.0625 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 198/250\n",
            "23/23 - 0s - loss: 78511.0703 - accuracy: 0.6011 - val_loss: 19332.5293 - val_accuracy: 0.6373 - 96ms/epoch - 4ms/step\n",
            "Epoch 199/250\n",
            "23/23 - 0s - loss: 78394.6016 - accuracy: 0.6033 - val_loss: 19265.9668 - val_accuracy: 0.6528 - 76ms/epoch - 3ms/step\n",
            "Epoch 200/250\n",
            "23/23 - 0s - loss: 78398.2188 - accuracy: 0.5965 - val_loss: 19232.2402 - val_accuracy: 0.6528 - 76ms/epoch - 3ms/step\n",
            "Epoch 201/250\n",
            "23/23 - 0s - loss: 78349.0703 - accuracy: 0.6018 - val_loss: 19226.1367 - val_accuracy: 0.6528 - 74ms/epoch - 3ms/step\n",
            "Epoch 202/250\n",
            "23/23 - 0s - loss: 78397.4453 - accuracy: 0.6026 - val_loss: 19287.2637 - val_accuracy: 0.6528 - 74ms/epoch - 3ms/step\n",
            "Epoch 203/250\n",
            "23/23 - 0s - loss: 78391.2578 - accuracy: 0.6011 - val_loss: 19227.2090 - val_accuracy: 0.6528 - 79ms/epoch - 3ms/step\n",
            "Epoch 204/250\n",
            "23/23 - 0s - loss: 78368.2969 - accuracy: 0.5995 - val_loss: 19325.8594 - val_accuracy: 0.6321 - 79ms/epoch - 3ms/step\n",
            "Epoch 205/250\n",
            "23/23 - 0s - loss: 78409.8125 - accuracy: 0.6018 - val_loss: 19224.7441 - val_accuracy: 0.6528 - 77ms/epoch - 3ms/step\n",
            "Epoch 206/250\n",
            "23/23 - 0s - loss: 78345.1484 - accuracy: 0.6033 - val_loss: 19237.5781 - val_accuracy: 0.6528 - 76ms/epoch - 3ms/step\n",
            "Epoch 207/250\n",
            "23/23 - 0s - loss: 78358.6484 - accuracy: 0.6033 - val_loss: 19215.2285 - val_accuracy: 0.6528 - 104ms/epoch - 5ms/step\n",
            "Epoch 208/250\n",
            "23/23 - 0s - loss: 78356.2266 - accuracy: 0.5988 - val_loss: 19288.4648 - val_accuracy: 0.6477 - 96ms/epoch - 4ms/step\n",
            "Epoch 209/250\n",
            "23/23 - 0s - loss: 78369.2969 - accuracy: 0.6018 - val_loss: 19224.7832 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 210/250\n",
            "23/23 - 0s - loss: 78334.6953 - accuracy: 0.6026 - val_loss: 19327.5957 - val_accuracy: 0.6373 - 95ms/epoch - 4ms/step\n",
            "Epoch 211/250\n",
            "23/23 - 0s - loss: 78408.0156 - accuracy: 0.5890 - val_loss: 19303.1289 - val_accuracy: 0.6528 - 77ms/epoch - 3ms/step\n",
            "Epoch 212/250\n",
            "23/23 - 0s - loss: 78382.9922 - accuracy: 0.5965 - val_loss: 19297.9961 - val_accuracy: 0.6528 - 82ms/epoch - 4ms/step\n",
            "Epoch 213/250\n",
            "23/23 - 0s - loss: 78371.9766 - accuracy: 0.6033 - val_loss: 19223.4395 - val_accuracy: 0.6528 - 76ms/epoch - 3ms/step\n",
            "Epoch 214/250\n",
            "23/23 - 0s - loss: 78368.6797 - accuracy: 0.6033 - val_loss: 19616.5137 - val_accuracy: 0.6528 - 85ms/epoch - 4ms/step\n",
            "Epoch 215/250\n",
            "23/23 - 0s - loss: 78466.1250 - accuracy: 0.5808 - val_loss: 19419.2012 - val_accuracy: 0.6528 - 81ms/epoch - 4ms/step\n",
            "Epoch 216/250\n",
            "23/23 - 0s - loss: 78440.7188 - accuracy: 0.5958 - val_loss: 19395.1895 - val_accuracy: 0.6373 - 86ms/epoch - 4ms/step\n",
            "Epoch 217/250\n",
            "23/23 - 0s - loss: 78386.8281 - accuracy: 0.6026 - val_loss: 19248.9004 - val_accuracy: 0.6528 - 85ms/epoch - 4ms/step\n",
            "Epoch 218/250\n",
            "23/23 - 0s - loss: 78348.3984 - accuracy: 0.6033 - val_loss: 19220.8594 - val_accuracy: 0.6528 - 89ms/epoch - 4ms/step\n",
            "Epoch 219/250\n",
            "23/23 - 0s - loss: 78337.1875 - accuracy: 0.6033 - val_loss: 19303.3301 - val_accuracy: 0.6528 - 79ms/epoch - 3ms/step\n",
            "Epoch 220/250\n",
            "23/23 - 0s - loss: 78350.6953 - accuracy: 0.6033 - val_loss: 19221.3984 - val_accuracy: 0.6528 - 77ms/epoch - 3ms/step\n",
            "Epoch 221/250\n",
            "23/23 - 0s - loss: 78356.5938 - accuracy: 0.5988 - val_loss: 19292.4609 - val_accuracy: 0.6528 - 76ms/epoch - 3ms/step\n",
            "Epoch 222/250\n",
            "23/23 - 0s - loss: 78415.2578 - accuracy: 0.6011 - val_loss: 19317.0449 - val_accuracy: 0.6528 - 79ms/epoch - 3ms/step\n",
            "Epoch 223/250\n",
            "23/23 - 0s - loss: 78402.6875 - accuracy: 0.6033 - val_loss: 19289.0176 - val_accuracy: 0.6528 - 75ms/epoch - 3ms/step\n",
            "Epoch 224/250\n",
            "23/23 - 0s - loss: 78361.5547 - accuracy: 0.6033 - val_loss: 19280.5938 - val_accuracy: 0.6528 - 82ms/epoch - 4ms/step\n",
            "Epoch 225/250\n",
            "23/23 - 0s - loss: 78392.0469 - accuracy: 0.6033 - val_loss: 19222.1191 - val_accuracy: 0.6528 - 97ms/epoch - 4ms/step\n",
            "Epoch 226/250\n",
            "23/23 - 0s - loss: 78394.9297 - accuracy: 0.6033 - val_loss: 19377.5410 - val_accuracy: 0.6528 - 74ms/epoch - 3ms/step\n",
            "Epoch 227/250\n",
            "23/23 - 0s - loss: 78353.7422 - accuracy: 0.6033 - val_loss: 19220.5664 - val_accuracy: 0.6528 - 79ms/epoch - 3ms/step\n",
            "Epoch 228/250\n",
            "23/23 - 0s - loss: 78336.0391 - accuracy: 0.6033 - val_loss: 19524.3164 - val_accuracy: 0.6528 - 80ms/epoch - 3ms/step\n",
            "Epoch 229/250\n",
            "23/23 - 0s - loss: 78365.6875 - accuracy: 0.6033 - val_loss: 19223.3828 - val_accuracy: 0.6528 - 97ms/epoch - 4ms/step\n",
            "Epoch 230/250\n",
            "23/23 - 0s - loss: 78361.1094 - accuracy: 0.6033 - val_loss: 19274.1641 - val_accuracy: 0.6528 - 88ms/epoch - 4ms/step\n",
            "Epoch 231/250\n",
            "23/23 - 0s - loss: 78347.7344 - accuracy: 0.6033 - val_loss: 20082.5566 - val_accuracy: 0.6528 - 77ms/epoch - 3ms/step\n",
            "Epoch 232/250\n",
            "23/23 - 0s - loss: 78978.7734 - accuracy: 0.4305 - val_loss: 19767.8945 - val_accuracy: 0.0777 - 85ms/epoch - 4ms/step\n",
            "Epoch 233/250\n",
            "23/23 - 0s - loss: 78844.2812 - accuracy: 0.1187 - val_loss: 19787.5781 - val_accuracy: 0.0674 - 80ms/epoch - 3ms/step\n",
            "Epoch 234/250\n",
            "23/23 - 0s - loss: 78696.4844 - accuracy: 0.1052 - val_loss: 19584.3867 - val_accuracy: 0.0622 - 77ms/epoch - 3ms/step\n",
            "Epoch 235/250\n",
            "23/23 - 0s - loss: 78543.9062 - accuracy: 0.2900 - val_loss: 19420.6719 - val_accuracy: 0.6166 - 77ms/epoch - 3ms/step\n",
            "Epoch 236/250\n",
            "23/23 - 0s - loss: 78437.2031 - accuracy: 0.5695 - val_loss: 19360.6191 - val_accuracy: 0.6477 - 82ms/epoch - 4ms/step\n",
            "Epoch 237/250\n",
            "23/23 - 0s - loss: 78393.8125 - accuracy: 0.6033 - val_loss: 19327.3730 - val_accuracy: 0.6528 - 75ms/epoch - 3ms/step\n",
            "Epoch 238/250\n",
            "23/23 - 0s - loss: 78364.9375 - accuracy: 0.6033 - val_loss: 19314.9062 - val_accuracy: 0.6528 - 73ms/epoch - 3ms/step\n",
            "Epoch 239/250\n",
            "23/23 - 0s - loss: 78387.3516 - accuracy: 0.6033 - val_loss: 19276.4648 - val_accuracy: 0.6528 - 83ms/epoch - 4ms/step\n",
            "Epoch 240/250\n",
            "23/23 - 0s - loss: 78370.1719 - accuracy: 0.6033 - val_loss: 19283.2832 - val_accuracy: 0.6528 - 94ms/epoch - 4ms/step\n",
            "Epoch 241/250\n",
            "23/23 - 0s - loss: 78390.5156 - accuracy: 0.6033 - val_loss: 19312.1875 - val_accuracy: 0.6528 - 85ms/epoch - 4ms/step\n",
            "Epoch 242/250\n",
            "23/23 - 0s - loss: 78366.4922 - accuracy: 0.6033 - val_loss: 19260.2070 - val_accuracy: 0.6528 - 81ms/epoch - 4ms/step\n",
            "Epoch 243/250\n",
            "23/23 - 0s - loss: 78351.9297 - accuracy: 0.6033 - val_loss: 19247.8711 - val_accuracy: 0.6528 - 81ms/epoch - 4ms/step\n",
            "Epoch 244/250\n",
            "23/23 - 0s - loss: 78347.0000 - accuracy: 0.6033 - val_loss: 19267.3438 - val_accuracy: 0.6528 - 94ms/epoch - 4ms/step\n",
            "Epoch 245/250\n",
            "23/23 - 0s - loss: 78321.1562 - accuracy: 0.6033 - val_loss: 19236.0801 - val_accuracy: 0.6528 - 78ms/epoch - 3ms/step\n",
            "Epoch 246/250\n",
            "23/23 - 0s - loss: 78370.6484 - accuracy: 0.6033 - val_loss: 19268.8242 - val_accuracy: 0.6528 - 81ms/epoch - 4ms/step\n",
            "Epoch 247/250\n",
            "23/23 - 0s - loss: 78400.6953 - accuracy: 0.6033 - val_loss: 19234.8555 - val_accuracy: 0.6528 - 77ms/epoch - 3ms/step\n",
            "Epoch 248/250\n",
            "23/23 - 0s - loss: 78414.9688 - accuracy: 0.6033 - val_loss: 19262.7051 - val_accuracy: 0.6528 - 89ms/epoch - 4ms/step\n",
            "Epoch 249/250\n",
            "23/23 - 0s - loss: 78348.4766 - accuracy: 0.6033 - val_loss: 19435.5293 - val_accuracy: 0.6528 - 89ms/epoch - 4ms/step\n",
            "Epoch 250/250\n",
            "23/23 - 0s - loss: 78414.8359 - accuracy: 0.6033 - val_loss: 19299.1602 - val_accuracy: 0.6528 - 80ms/epoch - 3ms/step\n",
            "[[  0.17182457  32.          16.          60.         150.\n",
            "   64.           8.        ]]\n",
            "l1 32\n",
            "epochs 150\n",
            "60\n",
            "0.17182457312066599\n",
            "Epoch 1/150\n",
            "22/22 - 1s - loss: 90699.3906 - accuracy: 0.2052 - val_loss: 17759.2246 - val_accuracy: 0.2824 - 618ms/epoch - 28ms/step\n",
            "Epoch 2/150\n",
            "22/22 - 0s - loss: 82696.4141 - accuracy: 0.2987 - val_loss: 17698.5176 - val_accuracy: 0.2824 - 79ms/epoch - 4ms/step\n",
            "Epoch 3/150\n",
            "22/22 - 0s - loss: 82730.4609 - accuracy: 0.2987 - val_loss: 17759.1348 - val_accuracy: 0.2824 - 76ms/epoch - 3ms/step\n",
            "Epoch 4/150\n",
            "22/22 - 0s - loss: 82738.1406 - accuracy: 0.2987 - val_loss: 17759.0742 - val_accuracy: 0.2824 - 79ms/epoch - 4ms/step\n",
            "Epoch 5/150\n",
            "22/22 - 0s - loss: 82738.0703 - accuracy: 0.2987 - val_loss: 17759.0117 - val_accuracy: 0.2824 - 73ms/epoch - 3ms/step\n",
            "Epoch 6/150\n",
            "22/22 - 0s - loss: 82738.0156 - accuracy: 0.2987 - val_loss: 17758.9531 - val_accuracy: 0.0687 - 76ms/epoch - 3ms/step\n",
            "Epoch 7/150\n",
            "22/22 - 0s - loss: 82737.9453 - accuracy: 0.0990 - val_loss: 17758.8926 - val_accuracy: 0.0687 - 95ms/epoch - 4ms/step\n",
            "Epoch 8/150\n",
            "22/22 - 0s - loss: 82737.8984 - accuracy: 0.0990 - val_loss: 17758.8340 - val_accuracy: 0.0687 - 91ms/epoch - 4ms/step\n",
            "Epoch 9/150\n",
            "22/22 - 0s - loss: 82737.8438 - accuracy: 0.0990 - val_loss: 17758.7734 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 10/150\n",
            "22/22 - 0s - loss: 82737.7656 - accuracy: 0.0990 - val_loss: 17758.7168 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 11/150\n",
            "22/22 - 0s - loss: 82737.7188 - accuracy: 0.0990 - val_loss: 17758.6562 - val_accuracy: 0.0687 - 82ms/epoch - 4ms/step\n",
            "Epoch 12/150\n",
            "22/22 - 0s - loss: 82737.6562 - accuracy: 0.0990 - val_loss: 17758.5977 - val_accuracy: 0.0687 - 85ms/epoch - 4ms/step\n",
            "Epoch 13/150\n",
            "22/22 - 0s - loss: 82737.5938 - accuracy: 0.0990 - val_loss: 17758.5410 - val_accuracy: 0.0687 - 75ms/epoch - 3ms/step\n",
            "Epoch 14/150\n",
            "22/22 - 0s - loss: 82737.5312 - accuracy: 0.0990 - val_loss: 17758.4824 - val_accuracy: 0.0687 - 100ms/epoch - 5ms/step\n",
            "Epoch 15/150\n",
            "22/22 - 0s - loss: 82737.4609 - accuracy: 0.0990 - val_loss: 17758.4238 - val_accuracy: 0.0687 - 75ms/epoch - 3ms/step\n",
            "Epoch 16/150\n",
            "22/22 - 0s - loss: 82737.4062 - accuracy: 0.0990 - val_loss: 17758.3691 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 17/150\n",
            "22/22 - 0s - loss: 82737.3594 - accuracy: 0.0990 - val_loss: 17758.3086 - val_accuracy: 0.0687 - 94ms/epoch - 4ms/step\n",
            "Epoch 18/150\n",
            "22/22 - 0s - loss: 82737.2891 - accuracy: 0.0990 - val_loss: 17758.2520 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 19/150\n",
            "22/22 - 0s - loss: 82737.2344 - accuracy: 0.0990 - val_loss: 17758.1953 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 20/150\n",
            "22/22 - 0s - loss: 82737.1797 - accuracy: 0.0990 - val_loss: 17758.1348 - val_accuracy: 0.0687 - 85ms/epoch - 4ms/step\n",
            "Epoch 21/150\n",
            "22/22 - 0s - loss: 82737.1250 - accuracy: 0.0990 - val_loss: 17758.0801 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 22/150\n",
            "22/22 - 0s - loss: 82737.0547 - accuracy: 0.0990 - val_loss: 17758.0215 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 23/150\n",
            "22/22 - 0s - loss: 82737.0078 - accuracy: 0.0990 - val_loss: 17757.9629 - val_accuracy: 0.0687 - 94ms/epoch - 4ms/step\n",
            "Epoch 24/150\n",
            "22/22 - 0s - loss: 82736.9531 - accuracy: 0.0990 - val_loss: 17757.9043 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 25/150\n",
            "22/22 - 0s - loss: 82736.8828 - accuracy: 0.0990 - val_loss: 17757.8477 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 26/150\n",
            "22/22 - 0s - loss: 82736.8203 - accuracy: 0.0990 - val_loss: 17757.7910 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 27/150\n",
            "22/22 - 0s - loss: 82736.7656 - accuracy: 0.0990 - val_loss: 17757.7324 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 28/150\n",
            "22/22 - 0s - loss: 82736.7031 - accuracy: 0.0990 - val_loss: 17757.6758 - val_accuracy: 0.0687 - 76ms/epoch - 3ms/step\n",
            "Epoch 29/150\n",
            "22/22 - 0s - loss: 82736.6562 - accuracy: 0.0990 - val_loss: 17757.6191 - val_accuracy: 0.0687 - 82ms/epoch - 4ms/step\n",
            "Epoch 30/150\n",
            "22/22 - 0s - loss: 82736.5859 - accuracy: 0.0990 - val_loss: 17757.5605 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 31/150\n",
            "22/22 - 0s - loss: 82736.5312 - accuracy: 0.0990 - val_loss: 17757.5059 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 32/150\n",
            "22/22 - 0s - loss: 82736.4688 - accuracy: 0.0990 - val_loss: 17757.4492 - val_accuracy: 0.0687 - 83ms/epoch - 4ms/step\n",
            "Epoch 33/150\n",
            "22/22 - 0s - loss: 82736.4219 - accuracy: 0.0990 - val_loss: 17757.3887 - val_accuracy: 0.0687 - 90ms/epoch - 4ms/step\n",
            "Epoch 34/150\n",
            "22/22 - 0s - loss: 82736.3516 - accuracy: 0.0990 - val_loss: 17757.3340 - val_accuracy: 0.0687 - 84ms/epoch - 4ms/step\n",
            "Epoch 35/150\n",
            "22/22 - 0s - loss: 82736.2969 - accuracy: 0.0990 - val_loss: 17757.2773 - val_accuracy: 0.0687 - 90ms/epoch - 4ms/step\n",
            "Epoch 36/150\n",
            "22/22 - 0s - loss: 82736.2500 - accuracy: 0.0990 - val_loss: 17757.2168 - val_accuracy: 0.0687 - 76ms/epoch - 3ms/step\n",
            "Epoch 37/150\n",
            "22/22 - 0s - loss: 82736.1797 - accuracy: 0.0990 - val_loss: 17757.1602 - val_accuracy: 0.0687 - 77ms/epoch - 3ms/step\n",
            "Epoch 38/150\n",
            "22/22 - 0s - loss: 82736.1250 - accuracy: 0.0990 - val_loss: 17757.1055 - val_accuracy: 0.0687 - 84ms/epoch - 4ms/step\n",
            "Epoch 39/150\n",
            "22/22 - 0s - loss: 82736.0781 - accuracy: 0.0990 - val_loss: 17757.0469 - val_accuracy: 0.0687 - 90ms/epoch - 4ms/step\n",
            "Epoch 40/150\n",
            "22/22 - 0s - loss: 82736.0078 - accuracy: 0.0990 - val_loss: 17756.9902 - val_accuracy: 0.0687 - 75ms/epoch - 3ms/step\n",
            "Epoch 41/150\n",
            "22/22 - 0s - loss: 82735.9453 - accuracy: 0.0990 - val_loss: 17756.9336 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 42/150\n",
            "22/22 - 0s - loss: 82735.8906 - accuracy: 0.0990 - val_loss: 17756.8770 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 43/150\n",
            "22/22 - 0s - loss: 82735.8438 - accuracy: 0.0990 - val_loss: 17756.8203 - val_accuracy: 0.0687 - 95ms/epoch - 4ms/step\n",
            "Epoch 44/150\n",
            "22/22 - 0s - loss: 82735.7812 - accuracy: 0.0990 - val_loss: 17756.7637 - val_accuracy: 0.0687 - 90ms/epoch - 4ms/step\n",
            "Epoch 45/150\n",
            "22/22 - 0s - loss: 82735.7109 - accuracy: 0.0990 - val_loss: 17756.7070 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 46/150\n",
            "22/22 - 0s - loss: 82735.6641 - accuracy: 0.0990 - val_loss: 17756.6504 - val_accuracy: 0.0687 - 91ms/epoch - 4ms/step\n",
            "Epoch 47/150\n",
            "22/22 - 0s - loss: 82735.6094 - accuracy: 0.0990 - val_loss: 17756.5918 - val_accuracy: 0.0687 - 85ms/epoch - 4ms/step\n",
            "Epoch 48/150\n",
            "22/22 - 0s - loss: 82735.5469 - accuracy: 0.0990 - val_loss: 17756.5371 - val_accuracy: 0.0687 - 91ms/epoch - 4ms/step\n",
            "Epoch 49/150\n",
            "22/22 - 0s - loss: 82735.4922 - accuracy: 0.0990 - val_loss: 17756.4805 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 50/150\n",
            "22/22 - 0s - loss: 82735.4297 - accuracy: 0.0990 - val_loss: 17756.4238 - val_accuracy: 0.0687 - 84ms/epoch - 4ms/step\n",
            "Epoch 51/150\n",
            "22/22 - 0s - loss: 82735.3750 - accuracy: 0.0990 - val_loss: 17756.3672 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 52/150\n",
            "22/22 - 0s - loss: 82735.3125 - accuracy: 0.0990 - val_loss: 17756.3105 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 53/150\n",
            "22/22 - 0s - loss: 82735.2422 - accuracy: 0.0990 - val_loss: 17756.2539 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 54/150\n",
            "22/22 - 0s - loss: 82735.1953 - accuracy: 0.0990 - val_loss: 17756.1973 - val_accuracy: 0.0687 - 83ms/epoch - 4ms/step\n",
            "Epoch 55/150\n",
            "22/22 - 0s - loss: 82735.1328 - accuracy: 0.0990 - val_loss: 17756.1426 - val_accuracy: 0.0687 - 75ms/epoch - 3ms/step\n",
            "Epoch 56/150\n",
            "22/22 - 0s - loss: 82735.0781 - accuracy: 0.0990 - val_loss: 17756.0859 - val_accuracy: 0.0687 - 76ms/epoch - 3ms/step\n",
            "Epoch 57/150\n",
            "22/22 - 0s - loss: 82735.0234 - accuracy: 0.0990 - val_loss: 17756.0312 - val_accuracy: 0.0687 - 91ms/epoch - 4ms/step\n",
            "Epoch 58/150\n",
            "22/22 - 0s - loss: 82734.9531 - accuracy: 0.0990 - val_loss: 17755.9746 - val_accuracy: 0.0687 - 98ms/epoch - 4ms/step\n",
            "Epoch 59/150\n",
            "22/22 - 0s - loss: 82734.9062 - accuracy: 0.0990 - val_loss: 17755.9160 - val_accuracy: 0.0687 - 90ms/epoch - 4ms/step\n",
            "Epoch 60/150\n",
            "22/22 - 0s - loss: 82734.8438 - accuracy: 0.0990 - val_loss: 17755.8613 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 61/150\n",
            "22/22 - 0s - loss: 82734.7969 - accuracy: 0.0990 - val_loss: 17755.8047 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 62/150\n",
            "22/22 - 0s - loss: 82734.7266 - accuracy: 0.0990 - val_loss: 17755.7480 - val_accuracy: 0.0687 - 91ms/epoch - 4ms/step\n",
            "Epoch 63/150\n",
            "22/22 - 0s - loss: 82734.6719 - accuracy: 0.0990 - val_loss: 17755.6934 - val_accuracy: 0.0687 - 82ms/epoch - 4ms/step\n",
            "Epoch 64/150\n",
            "22/22 - 0s - loss: 82734.6094 - accuracy: 0.0990 - val_loss: 17755.6367 - val_accuracy: 0.0687 - 84ms/epoch - 4ms/step\n",
            "Epoch 65/150\n",
            "22/22 - 0s - loss: 82734.5469 - accuracy: 0.0990 - val_loss: 17755.5820 - val_accuracy: 0.0687 - 76ms/epoch - 3ms/step\n",
            "Epoch 66/150\n",
            "22/22 - 0s - loss: 82734.5078 - accuracy: 0.0990 - val_loss: 17755.5254 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 67/150\n",
            "22/22 - 0s - loss: 82734.4375 - accuracy: 0.0990 - val_loss: 17755.4688 - val_accuracy: 0.0687 - 76ms/epoch - 3ms/step\n",
            "Epoch 68/150\n",
            "22/22 - 0s - loss: 82734.3906 - accuracy: 0.0990 - val_loss: 17755.4121 - val_accuracy: 0.0687 - 83ms/epoch - 4ms/step\n",
            "Epoch 69/150\n",
            "22/22 - 0s - loss: 82734.3359 - accuracy: 0.0990 - val_loss: 17755.3574 - val_accuracy: 0.0687 - 90ms/epoch - 4ms/step\n",
            "Epoch 70/150\n",
            "22/22 - 0s - loss: 82734.2656 - accuracy: 0.0990 - val_loss: 17755.2988 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 71/150\n",
            "22/22 - 0s - loss: 82734.2188 - accuracy: 0.0990 - val_loss: 17755.2461 - val_accuracy: 0.0687 - 84ms/epoch - 4ms/step\n",
            "Epoch 72/150\n",
            "22/22 - 0s - loss: 82734.1562 - accuracy: 0.0990 - val_loss: 17755.1895 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 73/150\n",
            "22/22 - 0s - loss: 82734.1016 - accuracy: 0.0990 - val_loss: 17755.1328 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 74/150\n",
            "22/22 - 0s - loss: 82734.0312 - accuracy: 0.0990 - val_loss: 17755.0781 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 75/150\n",
            "22/22 - 0s - loss: 82733.9766 - accuracy: 0.0990 - val_loss: 17755.0215 - val_accuracy: 0.0687 - 86ms/epoch - 4ms/step\n",
            "Epoch 76/150\n",
            "22/22 - 0s - loss: 82733.9141 - accuracy: 0.0990 - val_loss: 17754.9648 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 77/150\n",
            "22/22 - 0s - loss: 82733.8750 - accuracy: 0.0990 - val_loss: 17754.9121 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 78/150\n",
            "22/22 - 0s - loss: 82733.8125 - accuracy: 0.0990 - val_loss: 17754.8535 - val_accuracy: 0.0687 - 82ms/epoch - 4ms/step\n",
            "Epoch 79/150\n",
            "22/22 - 0s - loss: 82733.7500 - accuracy: 0.0990 - val_loss: 17754.7969 - val_accuracy: 0.0687 - 76ms/epoch - 3ms/step\n",
            "Epoch 80/150\n",
            "22/22 - 0s - loss: 82733.6875 - accuracy: 0.0990 - val_loss: 17754.7422 - val_accuracy: 0.0687 - 94ms/epoch - 4ms/step\n",
            "Epoch 81/150\n",
            "22/22 - 0s - loss: 82733.6406 - accuracy: 0.0990 - val_loss: 17754.6875 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 82/150\n",
            "22/22 - 0s - loss: 82733.5703 - accuracy: 0.0990 - val_loss: 17754.6289 - val_accuracy: 0.0687 - 83ms/epoch - 4ms/step\n",
            "Epoch 83/150\n",
            "22/22 - 0s - loss: 82733.5156 - accuracy: 0.0990 - val_loss: 17754.5762 - val_accuracy: 0.0687 - 91ms/epoch - 4ms/step\n",
            "Epoch 84/150\n",
            "22/22 - 0s - loss: 82733.4531 - accuracy: 0.0990 - val_loss: 17754.5195 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 85/150\n",
            "22/22 - 0s - loss: 82733.3984 - accuracy: 0.0990 - val_loss: 17754.4648 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 86/150\n",
            "22/22 - 0s - loss: 82733.3594 - accuracy: 0.0990 - val_loss: 17754.4102 - val_accuracy: 0.0687 - 87ms/epoch - 4ms/step\n",
            "Epoch 87/150\n",
            "22/22 - 0s - loss: 82733.2969 - accuracy: 0.0990 - val_loss: 17754.3535 - val_accuracy: 0.0687 - 85ms/epoch - 4ms/step\n",
            "Epoch 88/150\n",
            "22/22 - 0s - loss: 82733.2266 - accuracy: 0.0990 - val_loss: 17754.2969 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 89/150\n",
            "22/22 - 0s - loss: 82733.1719 - accuracy: 0.0990 - val_loss: 17754.2422 - val_accuracy: 0.0687 - 91ms/epoch - 4ms/step\n",
            "Epoch 90/150\n",
            "22/22 - 0s - loss: 82733.1016 - accuracy: 0.0990 - val_loss: 17754.1875 - val_accuracy: 0.0687 - 83ms/epoch - 4ms/step\n",
            "Epoch 91/150\n",
            "22/22 - 0s - loss: 82733.0547 - accuracy: 0.0990 - val_loss: 17754.1328 - val_accuracy: 0.0687 - 82ms/epoch - 4ms/step\n",
            "Epoch 92/150\n",
            "22/22 - 0s - loss: 82732.9922 - accuracy: 0.0990 - val_loss: 17754.0762 - val_accuracy: 0.0687 - 87ms/epoch - 4ms/step\n",
            "Epoch 93/150\n",
            "22/22 - 0s - loss: 82732.9453 - accuracy: 0.0990 - val_loss: 17754.0215 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 94/150\n",
            "22/22 - 0s - loss: 82732.8750 - accuracy: 0.0990 - val_loss: 17753.9648 - val_accuracy: 0.0687 - 77ms/epoch - 3ms/step\n",
            "Epoch 95/150\n",
            "22/22 - 0s - loss: 82732.8203 - accuracy: 0.0990 - val_loss: 17753.9102 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 96/150\n",
            "22/22 - 0s - loss: 82732.7656 - accuracy: 0.0990 - val_loss: 17753.8555 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 97/150\n",
            "22/22 - 0s - loss: 82732.7188 - accuracy: 0.0990 - val_loss: 17753.8008 - val_accuracy: 0.0687 - 77ms/epoch - 4ms/step\n",
            "Epoch 98/150\n",
            "22/22 - 0s - loss: 82732.6562 - accuracy: 0.0990 - val_loss: 17753.7461 - val_accuracy: 0.0687 - 87ms/epoch - 4ms/step\n",
            "Epoch 99/150\n",
            "22/22 - 0s - loss: 82732.5781 - accuracy: 0.0990 - val_loss: 17753.6914 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 100/150\n",
            "22/22 - 0s - loss: 82732.5391 - accuracy: 0.0990 - val_loss: 17753.6348 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 101/150\n",
            "22/22 - 0s - loss: 82732.4844 - accuracy: 0.0990 - val_loss: 17753.5781 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 102/150\n",
            "22/22 - 0s - loss: 82732.4219 - accuracy: 0.0990 - val_loss: 17753.5254 - val_accuracy: 0.0687 - 77ms/epoch - 4ms/step\n",
            "Epoch 103/150\n",
            "22/22 - 0s - loss: 82732.3516 - accuracy: 0.0990 - val_loss: 17753.4668 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 104/150\n",
            "22/22 - 0s - loss: 82732.3047 - accuracy: 0.0990 - val_loss: 17753.4141 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 105/150\n",
            "22/22 - 0s - loss: 82732.2344 - accuracy: 0.0990 - val_loss: 17753.3574 - val_accuracy: 0.0687 - 77ms/epoch - 4ms/step\n",
            "Epoch 106/150\n",
            "22/22 - 0s - loss: 82732.1719 - accuracy: 0.0990 - val_loss: 17753.3027 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 107/150\n",
            "22/22 - 0s - loss: 82732.1406 - accuracy: 0.0990 - val_loss: 17753.2480 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 108/150\n",
            "22/22 - 0s - loss: 82732.0625 - accuracy: 0.0990 - val_loss: 17753.1953 - val_accuracy: 0.0687 - 90ms/epoch - 4ms/step\n",
            "Epoch 109/150\n",
            "22/22 - 0s - loss: 82732.0078 - accuracy: 0.0990 - val_loss: 17753.1387 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 110/150\n",
            "22/22 - 0s - loss: 82731.9609 - accuracy: 0.0990 - val_loss: 17753.0840 - val_accuracy: 0.0687 - 84ms/epoch - 4ms/step\n",
            "Epoch 111/150\n",
            "22/22 - 0s - loss: 82731.9141 - accuracy: 0.0990 - val_loss: 17753.0312 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 112/150\n",
            "22/22 - 0s - loss: 82731.8516 - accuracy: 0.0990 - val_loss: 17752.9746 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 113/150\n",
            "22/22 - 0s - loss: 82731.7812 - accuracy: 0.0990 - val_loss: 17752.9199 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 114/150\n",
            "22/22 - 0s - loss: 82731.7344 - accuracy: 0.0990 - val_loss: 17752.8652 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 115/150\n",
            "22/22 - 0s - loss: 82731.6641 - accuracy: 0.0990 - val_loss: 17752.8105 - val_accuracy: 0.0687 - 105ms/epoch - 5ms/step\n",
            "Epoch 116/150\n",
            "22/22 - 0s - loss: 82731.6250 - accuracy: 0.0990 - val_loss: 17752.7578 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 117/150\n",
            "22/22 - 0s - loss: 82731.5547 - accuracy: 0.0990 - val_loss: 17752.7012 - val_accuracy: 0.0687 - 77ms/epoch - 4ms/step\n",
            "Epoch 118/150\n",
            "22/22 - 0s - loss: 82731.5000 - accuracy: 0.0990 - val_loss: 17752.6465 - val_accuracy: 0.0687 - 77ms/epoch - 3ms/step\n",
            "Epoch 119/150\n",
            "22/22 - 0s - loss: 82731.4453 - accuracy: 0.0990 - val_loss: 17752.5918 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 120/150\n",
            "22/22 - 0s - loss: 82731.3906 - accuracy: 0.0990 - val_loss: 17752.5371 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 121/150\n",
            "22/22 - 0s - loss: 82731.3281 - accuracy: 0.0990 - val_loss: 17752.4805 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 122/150\n",
            "22/22 - 0s - loss: 82731.2812 - accuracy: 0.0990 - val_loss: 17752.4277 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 123/150\n",
            "22/22 - 0s - loss: 82731.2109 - accuracy: 0.0990 - val_loss: 17752.3711 - val_accuracy: 0.0687 - 74ms/epoch - 3ms/step\n",
            "Epoch 124/150\n",
            "22/22 - 0s - loss: 82731.1641 - accuracy: 0.0990 - val_loss: 17752.3184 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 125/150\n",
            "22/22 - 0s - loss: 82731.0859 - accuracy: 0.0990 - val_loss: 17752.2617 - val_accuracy: 0.0687 - 88ms/epoch - 4ms/step\n",
            "Epoch 126/150\n",
            "22/22 - 0s - loss: 82731.0391 - accuracy: 0.0990 - val_loss: 17752.2090 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 127/150\n",
            "22/22 - 0s - loss: 82730.9844 - accuracy: 0.0990 - val_loss: 17752.1523 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 128/150\n",
            "22/22 - 0s - loss: 82730.9297 - accuracy: 0.0990 - val_loss: 17752.0977 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 129/150\n",
            "22/22 - 0s - loss: 82730.8750 - accuracy: 0.0990 - val_loss: 17752.0410 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 130/150\n",
            "22/22 - 0s - loss: 82730.8203 - accuracy: 0.0990 - val_loss: 17751.9863 - val_accuracy: 0.0687 - 89ms/epoch - 4ms/step\n",
            "Epoch 131/150\n",
            "22/22 - 0s - loss: 82730.7656 - accuracy: 0.0990 - val_loss: 17751.9316 - val_accuracy: 0.0687 - 88ms/epoch - 4ms/step\n",
            "Epoch 132/150\n",
            "22/22 - 0s - loss: 82730.7031 - accuracy: 0.0990 - val_loss: 17751.8750 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 133/150\n",
            "22/22 - 0s - loss: 82730.6484 - accuracy: 0.0990 - val_loss: 17751.8223 - val_accuracy: 0.0687 - 79ms/epoch - 4ms/step\n",
            "Epoch 134/150\n",
            "22/22 - 0s - loss: 82730.5938 - accuracy: 0.0990 - val_loss: 17751.7676 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 135/150\n",
            "22/22 - 0s - loss: 82730.5312 - accuracy: 0.0990 - val_loss: 17751.7109 - val_accuracy: 0.0687 - 75ms/epoch - 3ms/step\n",
            "Epoch 136/150\n",
            "22/22 - 0s - loss: 82730.4609 - accuracy: 0.0990 - val_loss: 17751.6562 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 137/150\n",
            "22/22 - 0s - loss: 82730.4297 - accuracy: 0.0990 - val_loss: 17751.6035 - val_accuracy: 0.0687 - 75ms/epoch - 3ms/step\n",
            "Epoch 138/150\n",
            "22/22 - 0s - loss: 82730.3672 - accuracy: 0.0990 - val_loss: 17751.5469 - val_accuracy: 0.0687 - 98ms/epoch - 4ms/step\n",
            "Epoch 139/150\n",
            "22/22 - 0s - loss: 82730.3125 - accuracy: 0.0990 - val_loss: 17751.4922 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 140/150\n",
            "22/22 - 0s - loss: 82730.2578 - accuracy: 0.0990 - val_loss: 17751.4395 - val_accuracy: 0.0687 - 83ms/epoch - 4ms/step\n",
            "Epoch 141/150\n",
            "22/22 - 0s - loss: 82730.1953 - accuracy: 0.0990 - val_loss: 17751.3828 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 142/150\n",
            "22/22 - 0s - loss: 82730.1406 - accuracy: 0.0990 - val_loss: 17751.3281 - val_accuracy: 0.0687 - 83ms/epoch - 4ms/step\n",
            "Epoch 143/150\n",
            "22/22 - 0s - loss: 82730.0938 - accuracy: 0.0990 - val_loss: 17751.2734 - val_accuracy: 0.0687 - 96ms/epoch - 4ms/step\n",
            "Epoch 144/150\n",
            "22/22 - 0s - loss: 82730.0234 - accuracy: 0.0990 - val_loss: 17751.2168 - val_accuracy: 0.0687 - 82ms/epoch - 4ms/step\n",
            "Epoch 145/150\n",
            "22/22 - 0s - loss: 82729.9766 - accuracy: 0.0990 - val_loss: 17751.1621 - val_accuracy: 0.0687 - 78ms/epoch - 4ms/step\n",
            "Epoch 146/150\n",
            "22/22 - 0s - loss: 82729.9141 - accuracy: 0.0990 - val_loss: 17751.1094 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 147/150\n",
            "22/22 - 0s - loss: 82729.8672 - accuracy: 0.0990 - val_loss: 17751.0527 - val_accuracy: 0.0687 - 81ms/epoch - 4ms/step\n",
            "Epoch 148/150\n",
            "22/22 - 0s - loss: 82729.7969 - accuracy: 0.0990 - val_loss: 17750.9980 - val_accuracy: 0.0687 - 80ms/epoch - 4ms/step\n",
            "Epoch 149/150\n",
            "22/22 - 0s - loss: 82729.7344 - accuracy: 0.0990 - val_loss: 17750.9434 - val_accuracy: 0.0687 - 92ms/epoch - 4ms/step\n",
            "Epoch 150/150\n",
            "22/22 - 0s - loss: 82729.6875 - accuracy: 0.0990 - val_loss: 17750.8887 - val_accuracy: 0.0687 - 88ms/epoch - 4ms/step\n",
            "[[  0.17824225  16.           8.          20.         100.\n",
            "    8.          16.        ]]\n",
            "l1 16\n",
            "epochs 100\n",
            "20\n",
            "0.1782422452051219\n",
            "Epoch 1/100\n",
            "63/63 - 1s - loss: 140331.0625 - accuracy: 0.2995 - val_loss: 33840.7969 - val_accuracy: 0.2831 - 706ms/epoch - 11ms/step\n",
            "Epoch 2/100\n",
            "63/63 - 0s - loss: 86917.3672 - accuracy: 0.3219 - val_loss: 18483.8730 - val_accuracy: 0.6434 - 205ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "63/63 - 0s - loss: 82725.9453 - accuracy: 0.5895 - val_loss: 18427.9395 - val_accuracy: 0.6471 - 231ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "63/63 - 0s - loss: 82668.2109 - accuracy: 0.5950 - val_loss: 18405.1543 - val_accuracy: 0.6471 - 226ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "63/63 - 0s - loss: 82650.7578 - accuracy: 0.5887 - val_loss: 18360.9707 - val_accuracy: 0.6471 - 230ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "63/63 - 0s - loss: 82638.4766 - accuracy: 0.5950 - val_loss: 18461.8359 - val_accuracy: 0.6471 - 192ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "63/63 - 0s - loss: 82659.1094 - accuracy: 0.5950 - val_loss: 18541.3906 - val_accuracy: 0.6176 - 227ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "63/63 - 0s - loss: 82642.3359 - accuracy: 0.5927 - val_loss: 18357.3496 - val_accuracy: 0.6507 - 229ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "63/63 - 0s - loss: 82602.6953 - accuracy: 0.5966 - val_loss: 18587.8770 - val_accuracy: 0.6066 - 224ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "63/63 - 0s - loss: 82640.9062 - accuracy: 0.5935 - val_loss: 18375.5703 - val_accuracy: 0.6471 - 226ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "63/63 - 0s - loss: 82637.9688 - accuracy: 0.5950 - val_loss: 18373.7715 - val_accuracy: 0.6471 - 191ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "63/63 - 0s - loss: 82615.3125 - accuracy: 0.5982 - val_loss: 18385.2383 - val_accuracy: 0.6471 - 189ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "63/63 - 0s - loss: 82603.8672 - accuracy: 0.5966 - val_loss: 18416.9746 - val_accuracy: 0.6434 - 185ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "63/63 - 0s - loss: 82597.0000 - accuracy: 0.5998 - val_loss: 18417.2031 - val_accuracy: 0.6397 - 222ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "63/63 - 0s - loss: 82627.1328 - accuracy: 0.5942 - val_loss: 18316.7285 - val_accuracy: 0.6471 - 182ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "63/63 - 0s - loss: 82645.4688 - accuracy: 0.5559 - val_loss: 18849.1797 - val_accuracy: 0.0735 - 190ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "63/63 - 0s - loss: 82613.9062 - accuracy: 0.5687 - val_loss: 18322.0918 - val_accuracy: 0.6471 - 252ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "63/63 - 0s - loss: 82572.5469 - accuracy: 0.6030 - val_loss: 18400.0566 - val_accuracy: 0.6471 - 226ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "63/63 - 0s - loss: 82682.6719 - accuracy: 0.6006 - val_loss: 18372.9961 - val_accuracy: 0.6471 - 195ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "63/63 - 0s - loss: 82578.6250 - accuracy: 0.6030 - val_loss: 18320.6230 - val_accuracy: 0.6434 - 189ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "63/63 - 0s - loss: 82557.0078 - accuracy: 0.6030 - val_loss: 18302.2285 - val_accuracy: 0.6434 - 190ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "63/63 - 0s - loss: 82554.9609 - accuracy: 0.6030 - val_loss: 18382.2539 - val_accuracy: 0.6434 - 183ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "63/63 - 0s - loss: 82539.7812 - accuracy: 0.6038 - val_loss: 18318.7891 - val_accuracy: 0.6434 - 185ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "63/63 - 0s - loss: 82556.6875 - accuracy: 0.6038 - val_loss: 18387.5195 - val_accuracy: 0.6434 - 178ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "63/63 - 0s - loss: 82568.0859 - accuracy: 0.6030 - val_loss: 18282.7090 - val_accuracy: 0.6434 - 225ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "63/63 - 0s - loss: 82539.3516 - accuracy: 0.5966 - val_loss: 18346.6797 - val_accuracy: 0.6434 - 193ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "63/63 - 0s - loss: 82592.4219 - accuracy: 0.5927 - val_loss: 18280.3906 - val_accuracy: 0.6434 - 183ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "63/63 - 0s - loss: 82546.8203 - accuracy: 0.6022 - val_loss: 18249.8379 - val_accuracy: 0.6434 - 183ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "63/63 - 0s - loss: 82547.0078 - accuracy: 0.5927 - val_loss: 18310.5000 - val_accuracy: 0.6434 - 221ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "63/63 - 0s - loss: 82503.4766 - accuracy: 0.6022 - val_loss: 18248.2578 - val_accuracy: 0.6434 - 225ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "63/63 - 0s - loss: 82491.7656 - accuracy: 0.6022 - val_loss: 18360.0977 - val_accuracy: 0.6434 - 200ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "63/63 - 0s - loss: 82554.0625 - accuracy: 0.5831 - val_loss: 18246.9668 - val_accuracy: 0.6434 - 189ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "63/63 - 0s - loss: 82480.2969 - accuracy: 0.5887 - val_loss: 18286.3027 - val_accuracy: 0.6434 - 223ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "63/63 - 0s - loss: 82505.0625 - accuracy: 0.5647 - val_loss: 18235.3125 - val_accuracy: 0.6434 - 180ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "63/63 - 0s - loss: 82511.0703 - accuracy: 0.6022 - val_loss: 18232.5000 - val_accuracy: 0.6434 - 226ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "63/63 - 0s - loss: 82448.8594 - accuracy: 0.6022 - val_loss: 18277.8789 - val_accuracy: 0.6434 - 238ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "63/63 - 0s - loss: 82518.0234 - accuracy: 0.5903 - val_loss: 18266.4980 - val_accuracy: 0.6434 - 188ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "63/63 - 0s - loss: 82500.6797 - accuracy: 0.5591 - val_loss: 18247.5176 - val_accuracy: 0.6434 - 230ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "63/63 - 0s - loss: 82478.0234 - accuracy: 0.5807 - val_loss: 18228.7656 - val_accuracy: 0.6434 - 190ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "63/63 - 0s - loss: 82504.8594 - accuracy: 0.5807 - val_loss: 18335.5859 - val_accuracy: 0.6434 - 184ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "63/63 - 0s - loss: 82509.5312 - accuracy: 0.5927 - val_loss: 18260.8535 - val_accuracy: 0.6434 - 232ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "63/63 - 0s - loss: 82496.0234 - accuracy: 0.5942 - val_loss: 18237.4844 - val_accuracy: 0.6434 - 199ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "63/63 - 0s - loss: 82474.8438 - accuracy: 0.5974 - val_loss: 18307.5195 - val_accuracy: 0.6434 - 230ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "63/63 - 0s - loss: 82568.3672 - accuracy: 0.5927 - val_loss: 18309.2715 - val_accuracy: 0.6434 - 194ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "63/63 - 0s - loss: 82499.8359 - accuracy: 0.5847 - val_loss: 18282.4219 - val_accuracy: 0.6434 - 234ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "63/63 - 0s - loss: 82468.0625 - accuracy: 0.6022 - val_loss: 18252.9883 - val_accuracy: 0.6434 - 228ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "63/63 - 0s - loss: 82535.3594 - accuracy: 0.5759 - val_loss: 18317.0547 - val_accuracy: 0.6434 - 221ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "63/63 - 0s - loss: 82487.3203 - accuracy: 0.5887 - val_loss: 18262.3906 - val_accuracy: 0.6434 - 221ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "63/63 - 0s - loss: 82456.2109 - accuracy: 0.6022 - val_loss: 18217.7871 - val_accuracy: 0.6434 - 225ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "63/63 - 0s - loss: 82475.0703 - accuracy: 0.5735 - val_loss: 18504.0723 - val_accuracy: 0.6434 - 243ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "63/63 - 0s - loss: 82492.8438 - accuracy: 0.6022 - val_loss: 18209.2617 - val_accuracy: 0.6434 - 216ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "63/63 - 0s - loss: 82420.1797 - accuracy: 0.5998 - val_loss: 18273.7715 - val_accuracy: 0.6324 - 225ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "63/63 - 0s - loss: 82462.0000 - accuracy: 0.5927 - val_loss: 18257.3965 - val_accuracy: 0.6434 - 221ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "63/63 - 0s - loss: 82432.0312 - accuracy: 0.6022 - val_loss: 18215.9043 - val_accuracy: 0.6434 - 191ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "63/63 - 0s - loss: 82436.1094 - accuracy: 0.5927 - val_loss: 18307.1426 - val_accuracy: 0.6434 - 188ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "63/63 - 0s - loss: 82455.6719 - accuracy: 0.5647 - val_loss: 18234.5215 - val_accuracy: 0.6434 - 216ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "63/63 - 0s - loss: 82488.6172 - accuracy: 0.6022 - val_loss: 18272.2422 - val_accuracy: 0.6434 - 183ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "63/63 - 0s - loss: 82462.7500 - accuracy: 0.5863 - val_loss: 18194.4961 - val_accuracy: 0.6434 - 224ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "63/63 - 0s - loss: 82431.6406 - accuracy: 0.6022 - val_loss: 18220.0918 - val_accuracy: 0.6434 - 192ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "63/63 - 0s - loss: 82463.5547 - accuracy: 0.6022 - val_loss: 18218.5742 - val_accuracy: 0.6434 - 224ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "63/63 - 0s - loss: 82473.4219 - accuracy: 0.6022 - val_loss: 18206.8164 - val_accuracy: 0.6434 - 189ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "63/63 - 0s - loss: 82430.3828 - accuracy: 0.6022 - val_loss: 18299.2383 - val_accuracy: 0.6434 - 187ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "63/63 - 0s - loss: 82432.6719 - accuracy: 0.5982 - val_loss: 18238.4082 - val_accuracy: 0.6434 - 184ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "63/63 - 0s - loss: 82458.7578 - accuracy: 0.6022 - val_loss: 18275.9824 - val_accuracy: 0.6434 - 199ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "63/63 - 0s - loss: 82467.7578 - accuracy: 0.5815 - val_loss: 18208.8555 - val_accuracy: 0.6434 - 208ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "63/63 - 0s - loss: 82451.7734 - accuracy: 0.6022 - val_loss: 18210.4844 - val_accuracy: 0.6434 - 187ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "63/63 - 0s - loss: 82419.7344 - accuracy: 0.6022 - val_loss: 18497.5879 - val_accuracy: 0.6434 - 187ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "63/63 - 0s - loss: 82487.0312 - accuracy: 0.6022 - val_loss: 18348.9570 - val_accuracy: 0.6434 - 221ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "63/63 - 0s - loss: 82448.1250 - accuracy: 0.5735 - val_loss: 18253.8926 - val_accuracy: 0.6434 - 192ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "63/63 - 0s - loss: 82436.1562 - accuracy: 0.5743 - val_loss: 18229.7266 - val_accuracy: 0.6434 - 184ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "63/63 - 0s - loss: 82440.2969 - accuracy: 0.6022 - val_loss: 18729.1855 - val_accuracy: 0.3088 - 188ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "63/63 - 0s - loss: 82459.7578 - accuracy: 0.5927 - val_loss: 18236.4922 - val_accuracy: 0.6434 - 180ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "63/63 - 0s - loss: 82446.4062 - accuracy: 0.5927 - val_loss: 18281.2812 - val_accuracy: 0.6434 - 188ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "63/63 - 0s - loss: 82424.9688 - accuracy: 0.5911 - val_loss: 18344.7949 - val_accuracy: 0.6434 - 233ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "63/63 - 0s - loss: 82439.9375 - accuracy: 0.6030 - val_loss: 18212.1641 - val_accuracy: 0.6434 - 184ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "63/63 - 0s - loss: 82454.6328 - accuracy: 0.5942 - val_loss: 18246.7539 - val_accuracy: 0.6434 - 229ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "63/63 - 0s - loss: 82419.8125 - accuracy: 0.5927 - val_loss: 18170.7012 - val_accuracy: 0.6434 - 181ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "63/63 - 0s - loss: 82425.5938 - accuracy: 0.5855 - val_loss: 18234.0645 - val_accuracy: 0.6434 - 216ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "63/63 - 0s - loss: 82416.8984 - accuracy: 0.6022 - val_loss: 18272.1582 - val_accuracy: 0.6434 - 234ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "63/63 - 0s - loss: 82442.7266 - accuracy: 0.6022 - val_loss: 18387.6523 - val_accuracy: 0.6434 - 186ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "63/63 - 0s - loss: 82488.4219 - accuracy: 0.5974 - val_loss: 18537.0762 - val_accuracy: 0.2941 - 181ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "63/63 - 0s - loss: 82460.3672 - accuracy: 0.5911 - val_loss: 18268.6934 - val_accuracy: 0.6434 - 187ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "63/63 - 0s - loss: 82446.7500 - accuracy: 0.5847 - val_loss: 18294.3633 - val_accuracy: 0.6434 - 222ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "63/63 - 0s - loss: 82432.2266 - accuracy: 0.6022 - val_loss: 18246.6914 - val_accuracy: 0.6434 - 193ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "63/63 - 0s - loss: 82417.2031 - accuracy: 0.6022 - val_loss: 18236.5938 - val_accuracy: 0.6434 - 182ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "63/63 - 0s - loss: 82447.2109 - accuracy: 0.5990 - val_loss: 18247.6055 - val_accuracy: 0.6434 - 197ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "63/63 - 0s - loss: 82404.9531 - accuracy: 0.6022 - val_loss: 18193.4531 - val_accuracy: 0.6434 - 184ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "63/63 - 0s - loss: 82474.1094 - accuracy: 0.6022 - val_loss: 18350.3691 - val_accuracy: 0.6434 - 230ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "63/63 - 0s - loss: 82400.7031 - accuracy: 0.6022 - val_loss: 18314.4629 - val_accuracy: 0.6434 - 200ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "63/63 - 0s - loss: 82448.8750 - accuracy: 0.6022 - val_loss: 18238.9941 - val_accuracy: 0.6434 - 222ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "63/63 - 0s - loss: 82447.0859 - accuracy: 0.6022 - val_loss: 18227.6504 - val_accuracy: 0.6434 - 177ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "63/63 - 0s - loss: 82426.7266 - accuracy: 0.6022 - val_loss: 18225.8691 - val_accuracy: 0.6434 - 219ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "63/63 - 0s - loss: 82421.6484 - accuracy: 0.6022 - val_loss: 18181.6074 - val_accuracy: 0.6434 - 227ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "63/63 - 0s - loss: 82386.2266 - accuracy: 0.6022 - val_loss: 18189.5098 - val_accuracy: 0.6434 - 235ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "63/63 - 0s - loss: 82377.4453 - accuracy: 0.6022 - val_loss: 18302.5684 - val_accuracy: 0.6434 - 185ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "63/63 - 0s - loss: 82476.3359 - accuracy: 0.6022 - val_loss: 18215.6719 - val_accuracy: 0.6434 - 185ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "63/63 - 0s - loss: 82429.8672 - accuracy: 0.6022 - val_loss: 18197.4238 - val_accuracy: 0.6434 - 188ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "63/63 - 0s - loss: 82422.8672 - accuracy: 0.6022 - val_loss: 18224.6211 - val_accuracy: 0.6434 - 216ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "63/63 - 0s - loss: 82384.8750 - accuracy: 0.6022 - val_loss: 18249.8770 - val_accuracy: 0.6434 - 212ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "63/63 - 0s - loss: 82417.6484 - accuracy: 0.6022 - val_loss: 18205.1758 - val_accuracy: 0.6434 - 182ms/epoch - 3ms/step\n",
            "[[1.84346251e-02 8.00000000e+00 1.60000000e+01 6.00000000e+01\n",
            "  1.00000000e+02 1.60000000e+01 1.60000000e+01]]\n",
            "l1 8\n",
            "epochs 100\n",
            "60\n",
            "0.018434625083202625\n",
            "Epoch 1/100\n",
            "25/25 - 1s - loss: 162367.0312 - accuracy: 0.1953 - val_loss: 62236.0859 - val_accuracy: 0.7586 - 603ms/epoch - 24ms/step\n",
            "Epoch 2/100\n",
            "25/25 - 0s - loss: 82458.0625 - accuracy: 0.6067 - val_loss: 27305.1484 - val_accuracy: 0.7586 - 87ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "25/25 - 0s - loss: 72138.2969 - accuracy: 0.6067 - val_loss: 27186.1582 - val_accuracy: 0.7586 - 82ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "25/25 - 0s - loss: 72064.4141 - accuracy: 0.6074 - val_loss: 27188.5781 - val_accuracy: 0.7586 - 97ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "25/25 - 0s - loss: 72061.4766 - accuracy: 0.6067 - val_loss: 27259.2930 - val_accuracy: 0.7586 - 86ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "25/25 - 0s - loss: 72059.5469 - accuracy: 0.6080 - val_loss: 27184.4668 - val_accuracy: 0.7586 - 79ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "25/25 - 0s - loss: 72027.1172 - accuracy: 0.6067 - val_loss: 27472.7500 - val_accuracy: 0.7586 - 84ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "25/25 - 0s - loss: 72157.1875 - accuracy: 0.6033 - val_loss: 27158.3164 - val_accuracy: 0.7586 - 80ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "25/25 - 0s - loss: 72051.4062 - accuracy: 0.6040 - val_loss: 27176.4004 - val_accuracy: 0.7586 - 79ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "25/25 - 0s - loss: 72025.3984 - accuracy: 0.6033 - val_loss: 27188.8887 - val_accuracy: 0.7586 - 81ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "25/25 - 0s - loss: 72054.3594 - accuracy: 0.6067 - val_loss: 27553.5898 - val_accuracy: 0.7586 - 79ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "25/25 - 0s - loss: 72153.9609 - accuracy: 0.6087 - val_loss: 27187.0176 - val_accuracy: 0.7586 - 78ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "25/25 - 0s - loss: 72016.0469 - accuracy: 0.6094 - val_loss: 27327.3594 - val_accuracy: 0.7586 - 80ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "25/25 - 0s - loss: 72012.7656 - accuracy: 0.6067 - val_loss: 27342.2754 - val_accuracy: 0.7586 - 82ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "25/25 - 0s - loss: 72121.2109 - accuracy: 0.6054 - val_loss: 27488.0957 - val_accuracy: 0.7586 - 83ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "25/25 - 0s - loss: 72035.8828 - accuracy: 0.6027 - val_loss: 27152.1992 - val_accuracy: 0.7586 - 88ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "25/25 - 0s - loss: 72015.3516 - accuracy: 0.6040 - val_loss: 27184.4414 - val_accuracy: 0.7586 - 86ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "25/25 - 0s - loss: 72069.4844 - accuracy: 0.6033 - val_loss: 27166.4668 - val_accuracy: 0.7586 - 84ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "25/25 - 0s - loss: 72038.1094 - accuracy: 0.6080 - val_loss: 27205.0684 - val_accuracy: 0.7586 - 77ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "25/25 - 0s - loss: 72032.4219 - accuracy: 0.6074 - val_loss: 27146.8906 - val_accuracy: 0.7586 - 82ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "25/25 - 0s - loss: 71992.3125 - accuracy: 0.6060 - val_loss: 27225.0469 - val_accuracy: 0.7586 - 75ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "25/25 - 0s - loss: 71996.0781 - accuracy: 0.6033 - val_loss: 27204.0039 - val_accuracy: 0.7586 - 80ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "25/25 - 0s - loss: 72032.9609 - accuracy: 0.6054 - val_loss: 27424.6855 - val_accuracy: 0.7586 - 86ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "25/25 - 0s - loss: 72089.5703 - accuracy: 0.6074 - val_loss: 27230.7207 - val_accuracy: 0.7586 - 76ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "25/25 - 0s - loss: 72111.0000 - accuracy: 0.6033 - val_loss: 27150.5996 - val_accuracy: 0.7586 - 83ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "25/25 - 0s - loss: 71993.9219 - accuracy: 0.6040 - val_loss: 27373.3496 - val_accuracy: 0.7931 - 81ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "25/25 - 0s - loss: 72027.7656 - accuracy: 0.6080 - val_loss: 27206.4609 - val_accuracy: 0.7931 - 79ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "25/25 - 0s - loss: 71984.2500 - accuracy: 0.6067 - val_loss: 27224.1758 - val_accuracy: 0.7931 - 93ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "25/25 - 0s - loss: 72017.8828 - accuracy: 0.6080 - val_loss: 27151.3887 - val_accuracy: 0.7931 - 83ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "25/25 - 0s - loss: 71997.1641 - accuracy: 0.6087 - val_loss: 27150.3516 - val_accuracy: 0.7931 - 76ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "25/25 - 0s - loss: 71968.6562 - accuracy: 0.6067 - val_loss: 27401.5840 - val_accuracy: 0.7931 - 78ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "25/25 - 0s - loss: 72043.0781 - accuracy: 0.6054 - val_loss: 27178.4492 - val_accuracy: 0.7931 - 75ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "25/25 - 0s - loss: 71996.3359 - accuracy: 0.6080 - val_loss: 27223.3828 - val_accuracy: 0.7931 - 83ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "25/25 - 0s - loss: 72101.8125 - accuracy: 0.5993 - val_loss: 27373.9824 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "25/25 - 0s - loss: 71997.6797 - accuracy: 0.6087 - val_loss: 27196.4668 - val_accuracy: 0.7931 - 78ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "25/25 - 0s - loss: 71958.5781 - accuracy: 0.6047 - val_loss: 27138.0996 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "25/25 - 0s - loss: 71967.7188 - accuracy: 0.6087 - val_loss: 27201.0645 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "25/25 - 0s - loss: 72013.4922 - accuracy: 0.6033 - val_loss: 27353.5234 - val_accuracy: 0.7931 - 84ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "25/25 - 0s - loss: 71989.7656 - accuracy: 0.6047 - val_loss: 27160.2324 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "25/25 - 0s - loss: 72091.2344 - accuracy: 0.6047 - val_loss: 27129.8008 - val_accuracy: 0.7931 - 99ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "25/25 - 0s - loss: 72060.8672 - accuracy: 0.6074 - val_loss: 27141.0703 - val_accuracy: 0.7931 - 85ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "25/25 - 0s - loss: 72027.0859 - accuracy: 0.6027 - val_loss: 27251.8281 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "25/25 - 0s - loss: 71965.4297 - accuracy: 0.6040 - val_loss: 27132.2051 - val_accuracy: 0.7931 - 89ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "25/25 - 0s - loss: 71950.7109 - accuracy: 0.6047 - val_loss: 27176.4824 - val_accuracy: 0.7931 - 78ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "25/25 - 0s - loss: 71958.6953 - accuracy: 0.6054 - val_loss: 27290.1230 - val_accuracy: 0.7931 - 87ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "25/25 - 0s - loss: 72010.2188 - accuracy: 0.6060 - val_loss: 27126.7559 - val_accuracy: 0.7931 - 78ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "25/25 - 0s - loss: 71931.5391 - accuracy: 0.6047 - val_loss: 27187.3301 - val_accuracy: 0.7931 - 89ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "25/25 - 0s - loss: 72042.4531 - accuracy: 0.6000 - val_loss: 27166.3379 - val_accuracy: 0.7931 - 77ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "25/25 - 0s - loss: 71946.8438 - accuracy: 0.6033 - val_loss: 27174.5762 - val_accuracy: 0.7931 - 76ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "25/25 - 0s - loss: 72025.3750 - accuracy: 0.5987 - val_loss: 27345.9531 - val_accuracy: 0.7931 - 81ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "25/25 - 0s - loss: 72030.8516 - accuracy: 0.6080 - val_loss: 27135.3965 - val_accuracy: 0.7931 - 88ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "25/25 - 0s - loss: 71940.4453 - accuracy: 0.6060 - val_loss: 27140.5352 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "25/25 - 0s - loss: 71942.8438 - accuracy: 0.5993 - val_loss: 27153.3672 - val_accuracy: 0.7931 - 87ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "25/25 - 0s - loss: 71948.0703 - accuracy: 0.6060 - val_loss: 27159.5703 - val_accuracy: 0.7931 - 78ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "25/25 - 0s - loss: 71922.9531 - accuracy: 0.6047 - val_loss: 27116.2031 - val_accuracy: 0.7931 - 75ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "25/25 - 0s - loss: 71945.6016 - accuracy: 0.6020 - val_loss: 27122.8945 - val_accuracy: 0.7931 - 81ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "25/25 - 0s - loss: 72005.3906 - accuracy: 0.6033 - val_loss: 27587.5918 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "25/25 - 0s - loss: 71959.2578 - accuracy: 0.6027 - val_loss: 27157.1602 - val_accuracy: 0.7931 - 83ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "25/25 - 0s - loss: 71931.1953 - accuracy: 0.6040 - val_loss: 27116.9648 - val_accuracy: 0.7931 - 83ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "25/25 - 0s - loss: 71926.3359 - accuracy: 0.6020 - val_loss: 27126.0566 - val_accuracy: 0.7931 - 79ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "25/25 - 0s - loss: 71929.0781 - accuracy: 0.6020 - val_loss: 27152.4004 - val_accuracy: 0.7931 - 74ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "25/25 - 0s - loss: 72015.0938 - accuracy: 0.6000 - val_loss: 27265.9492 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "25/25 - 0s - loss: 71933.8828 - accuracy: 0.6013 - val_loss: 27148.7207 - val_accuracy: 0.7931 - 90ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "25/25 - 0s - loss: 71946.1875 - accuracy: 0.6007 - val_loss: 27158.1406 - val_accuracy: 0.7931 - 78ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "25/25 - 0s - loss: 72050.5938 - accuracy: 0.5980 - val_loss: 27404.5781 - val_accuracy: 0.7586 - 84ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "25/25 - 0s - loss: 71976.1641 - accuracy: 0.6000 - val_loss: 27219.9141 - val_accuracy: 0.7931 - 79ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "25/25 - 0s - loss: 71981.1250 - accuracy: 0.6007 - val_loss: 27138.8008 - val_accuracy: 0.7931 - 73ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "25/25 - 0s - loss: 71926.7500 - accuracy: 0.6013 - val_loss: 27174.0801 - val_accuracy: 0.7931 - 81ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "25/25 - 0s - loss: 71932.6641 - accuracy: 0.6027 - val_loss: 27137.0469 - val_accuracy: 0.7931 - 81ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "25/25 - 0s - loss: 71904.3125 - accuracy: 0.6033 - val_loss: 27117.2461 - val_accuracy: 0.7931 - 77ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "25/25 - 0s - loss: 71923.8203 - accuracy: 0.6020 - val_loss: 27107.0137 - val_accuracy: 0.7931 - 87ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "25/25 - 0s - loss: 71952.2422 - accuracy: 0.6033 - val_loss: 27139.5781 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "25/25 - 0s - loss: 71970.1328 - accuracy: 0.6007 - val_loss: 27315.5391 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "25/25 - 0s - loss: 72041.5000 - accuracy: 0.6007 - val_loss: 27556.5605 - val_accuracy: 0.7586 - 76ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "25/25 - 0s - loss: 72016.6719 - accuracy: 0.5987 - val_loss: 27172.7988 - val_accuracy: 0.7931 - 94ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "25/25 - 0s - loss: 71905.5156 - accuracy: 0.6054 - val_loss: 27109.0352 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "25/25 - 0s - loss: 71905.5078 - accuracy: 0.6000 - val_loss: 27110.3789 - val_accuracy: 0.7931 - 86ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "25/25 - 0s - loss: 71976.5781 - accuracy: 0.6033 - val_loss: 27398.7637 - val_accuracy: 0.7586 - 85ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "25/25 - 0s - loss: 71987.0703 - accuracy: 0.5993 - val_loss: 27237.3105 - val_accuracy: 0.7931 - 77ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "25/25 - 0s - loss: 72010.1172 - accuracy: 0.5973 - val_loss: 27366.9727 - val_accuracy: 0.7586 - 81ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "25/25 - 0s - loss: 71939.2891 - accuracy: 0.6020 - val_loss: 27163.7441 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "25/25 - 0s - loss: 71910.6797 - accuracy: 0.6013 - val_loss: 27302.0176 - val_accuracy: 0.7931 - 87ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "25/25 - 0s - loss: 71949.4062 - accuracy: 0.6047 - val_loss: 27325.3008 - val_accuracy: 0.7931 - 77ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "25/25 - 0s - loss: 71927.4297 - accuracy: 0.6000 - val_loss: 27114.9961 - val_accuracy: 0.7931 - 77ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "25/25 - 0s - loss: 71900.4453 - accuracy: 0.6047 - val_loss: 27148.4727 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "25/25 - 0s - loss: 71907.2031 - accuracy: 0.6027 - val_loss: 27107.3105 - val_accuracy: 0.7931 - 85ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "25/25 - 0s - loss: 71887.4141 - accuracy: 0.6027 - val_loss: 27095.3555 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "25/25 - 0s - loss: 71897.9688 - accuracy: 0.6027 - val_loss: 27129.7754 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "25/25 - 0s - loss: 71908.5859 - accuracy: 0.6020 - val_loss: 27361.6699 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "25/25 - 0s - loss: 71959.4297 - accuracy: 0.6020 - val_loss: 27104.8262 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "25/25 - 0s - loss: 71903.3828 - accuracy: 0.6007 - val_loss: 27181.0137 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "25/25 - 0s - loss: 71925.3125 - accuracy: 0.6060 - val_loss: 27145.0879 - val_accuracy: 0.7931 - 83ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "25/25 - 0s - loss: 71946.3828 - accuracy: 0.6020 - val_loss: 27106.2480 - val_accuracy: 0.7931 - 82ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "25/25 - 0s - loss: 71985.7031 - accuracy: 0.6013 - val_loss: 27143.6230 - val_accuracy: 0.7931 - 77ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "25/25 - 0s - loss: 71883.9297 - accuracy: 0.6013 - val_loss: 27138.6445 - val_accuracy: 0.7931 - 76ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "25/25 - 0s - loss: 71875.0625 - accuracy: 0.6040 - val_loss: 27189.2578 - val_accuracy: 0.7931 - 78ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "25/25 - 0s - loss: 71892.7500 - accuracy: 0.6000 - val_loss: 27100.2070 - val_accuracy: 0.7931 - 80ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "25/25 - 0s - loss: 71867.4609 - accuracy: 0.6060 - val_loss: 27097.3984 - val_accuracy: 0.7931 - 83ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "25/25 - 0s - loss: 71904.7891 - accuracy: 0.6054 - val_loss: 27278.7891 - val_accuracy: 0.7931 - 77ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "25/25 - 0s - loss: 71953.0859 - accuracy: 0.6013 - val_loss: 27268.1816 - val_accuracy: 0.7931 - 94ms/epoch - 4ms/step\n",
            "[[1.6704017e-01 6.4000000e+01 6.4000000e+01 6.0000000e+01 2.0000000e+02\n",
            "  8.0000000e+00 8.0000000e+00]]\n",
            "l1 64\n",
            "epochs 200\n",
            "60\n",
            "0.16704017042461164\n",
            "Epoch 1/200\n",
            "22/22 - 1s - loss: 108936.2422 - accuracy: 0.4303 - val_loss: 20954.9570 - val_accuracy: 0.6471 - 611ms/epoch - 28ms/step\n",
            "Epoch 2/200\n",
            "22/22 - 0s - loss: 84270.7109 - accuracy: 0.3184 - val_loss: 18678.9902 - val_accuracy: 0.2902 - 93ms/epoch - 4ms/step\n",
            "Epoch 3/200\n",
            "22/22 - 0s - loss: 82536.4531 - accuracy: 0.2853 - val_loss: 18266.0078 - val_accuracy: 0.2706 - 89ms/epoch - 4ms/step\n",
            "Epoch 4/200\n",
            "22/22 - 0s - loss: 82342.5703 - accuracy: 0.1844 - val_loss: 18451.1387 - val_accuracy: 0.2902 - 94ms/epoch - 4ms/step\n",
            "Epoch 5/200\n",
            "22/22 - 0s - loss: 82340.1719 - accuracy: 0.1655 - val_loss: 18180.3105 - val_accuracy: 0.0902 - 78ms/epoch - 4ms/step\n",
            "Epoch 6/200\n",
            "22/22 - 0s - loss: 82307.0703 - accuracy: 0.1316 - val_loss: 18180.9824 - val_accuracy: 0.0863 - 95ms/epoch - 4ms/step\n",
            "Epoch 7/200\n",
            "22/22 - 0s - loss: 82322.7734 - accuracy: 0.1545 - val_loss: 18179.6680 - val_accuracy: 0.0706 - 85ms/epoch - 4ms/step\n",
            "Epoch 8/200\n",
            "22/22 - 0s - loss: 82295.2031 - accuracy: 0.1040 - val_loss: 18179.6367 - val_accuracy: 0.0706 - 94ms/epoch - 4ms/step\n",
            "Epoch 9/200\n",
            "22/22 - 0s - loss: 82294.3438 - accuracy: 0.1056 - val_loss: 18179.6113 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 10/200\n",
            "22/22 - 0s - loss: 82294.1562 - accuracy: 0.1040 - val_loss: 18179.5879 - val_accuracy: 0.0706 - 81ms/epoch - 4ms/step\n",
            "Epoch 11/200\n",
            "22/22 - 0s - loss: 82294.0859 - accuracy: 0.1032 - val_loss: 18179.5625 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 12/200\n",
            "22/22 - 0s - loss: 82294.1250 - accuracy: 0.1040 - val_loss: 18179.5430 - val_accuracy: 0.0706 - 82ms/epoch - 4ms/step\n",
            "Epoch 13/200\n",
            "22/22 - 0s - loss: 82294.5938 - accuracy: 0.1024 - val_loss: 18179.5156 - val_accuracy: 0.0706 - 102ms/epoch - 5ms/step\n",
            "Epoch 14/200\n",
            "22/22 - 0s - loss: 82294.0078 - accuracy: 0.1024 - val_loss: 18179.4902 - val_accuracy: 0.0706 - 81ms/epoch - 4ms/step\n",
            "Epoch 15/200\n",
            "22/22 - 0s - loss: 82293.9844 - accuracy: 0.1024 - val_loss: 18179.4648 - val_accuracy: 0.0706 - 87ms/epoch - 4ms/step\n",
            "Epoch 16/200\n",
            "22/22 - 0s - loss: 82293.9453 - accuracy: 0.1024 - val_loss: 18179.4414 - val_accuracy: 0.0706 - 79ms/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "22/22 - 0s - loss: 82293.9141 - accuracy: 0.1024 - val_loss: 18179.4160 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 18/200\n",
            "22/22 - 0s - loss: 82293.8906 - accuracy: 0.1024 - val_loss: 18179.3906 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 19/200\n",
            "22/22 - 0s - loss: 82293.8672 - accuracy: 0.1024 - val_loss: 18179.3652 - val_accuracy: 0.0706 - 92ms/epoch - 4ms/step\n",
            "Epoch 20/200\n",
            "22/22 - 0s - loss: 82293.8281 - accuracy: 0.1024 - val_loss: 18179.3379 - val_accuracy: 0.0706 - 98ms/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "22/22 - 0s - loss: 82293.8281 - accuracy: 0.1024 - val_loss: 18179.3145 - val_accuracy: 0.0706 - 82ms/epoch - 4ms/step\n",
            "Epoch 22/200\n",
            "22/22 - 0s - loss: 82293.9609 - accuracy: 0.1032 - val_loss: 18179.3027 - val_accuracy: 0.0706 - 84ms/epoch - 4ms/step\n",
            "Epoch 23/200\n",
            "22/22 - 0s - loss: 82294.5938 - accuracy: 0.1017 - val_loss: 18179.2832 - val_accuracy: 0.0706 - 76ms/epoch - 3ms/step\n",
            "Epoch 24/200\n",
            "22/22 - 0s - loss: 82293.7578 - accuracy: 0.1024 - val_loss: 18179.2656 - val_accuracy: 0.0706 - 90ms/epoch - 4ms/step\n",
            "Epoch 25/200\n",
            "22/22 - 0s - loss: 82293.7344 - accuracy: 0.1024 - val_loss: 18179.2461 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 26/200\n",
            "22/22 - 0s - loss: 82293.7188 - accuracy: 0.1024 - val_loss: 18179.2305 - val_accuracy: 0.0706 - 86ms/epoch - 4ms/step\n",
            "Epoch 27/200\n",
            "22/22 - 0s - loss: 82293.7031 - accuracy: 0.1024 - val_loss: 18179.2148 - val_accuracy: 0.0706 - 87ms/epoch - 4ms/step\n",
            "Epoch 28/200\n",
            "22/22 - 0s - loss: 82293.6797 - accuracy: 0.1024 - val_loss: 18179.1973 - val_accuracy: 0.0706 - 81ms/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "22/22 - 0s - loss: 82293.6562 - accuracy: 0.1024 - val_loss: 18179.1777 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 30/200\n",
            "22/22 - 0s - loss: 82293.6406 - accuracy: 0.1017 - val_loss: 18179.1602 - val_accuracy: 0.0706 - 88ms/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "22/22 - 0s - loss: 82293.6328 - accuracy: 0.1017 - val_loss: 18179.1445 - val_accuracy: 0.0706 - 92ms/epoch - 4ms/step\n",
            "Epoch 32/200\n",
            "22/22 - 0s - loss: 82293.6094 - accuracy: 0.1017 - val_loss: 18179.1250 - val_accuracy: 0.0706 - 84ms/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "22/22 - 0s - loss: 82293.6016 - accuracy: 0.1017 - val_loss: 18179.1094 - val_accuracy: 0.0706 - 92ms/epoch - 4ms/step\n",
            "Epoch 34/200\n",
            "22/22 - 0s - loss: 82293.5703 - accuracy: 0.1017 - val_loss: 18179.0898 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 35/200\n",
            "22/22 - 0s - loss: 82293.5625 - accuracy: 0.1017 - val_loss: 18179.0742 - val_accuracy: 0.0706 - 99ms/epoch - 4ms/step\n",
            "Epoch 36/200\n",
            "22/22 - 0s - loss: 82293.5391 - accuracy: 0.1017 - val_loss: 18179.0547 - val_accuracy: 0.0706 - 100ms/epoch - 5ms/step\n",
            "Epoch 37/200\n",
            "22/22 - 0s - loss: 82293.5156 - accuracy: 0.1017 - val_loss: 18179.0371 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 38/200\n",
            "22/22 - 0s - loss: 82293.5000 - accuracy: 0.1017 - val_loss: 18179.0195 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "22/22 - 0s - loss: 82293.4688 - accuracy: 0.1017 - val_loss: 18179.0000 - val_accuracy: 0.0706 - 81ms/epoch - 4ms/step\n",
            "Epoch 40/200\n",
            "22/22 - 0s - loss: 82293.4688 - accuracy: 0.1017 - val_loss: 18178.9805 - val_accuracy: 0.0706 - 86ms/epoch - 4ms/step\n",
            "Epoch 41/200\n",
            "22/22 - 0s - loss: 82293.4453 - accuracy: 0.1017 - val_loss: 18178.9629 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 42/200\n",
            "22/22 - 0s - loss: 82293.4375 - accuracy: 0.1017 - val_loss: 18178.9453 - val_accuracy: 0.0706 - 84ms/epoch - 4ms/step\n",
            "Epoch 43/200\n",
            "22/22 - 0s - loss: 82293.4141 - accuracy: 0.1017 - val_loss: 18178.9258 - val_accuracy: 0.0706 - 84ms/epoch - 4ms/step\n",
            "Epoch 44/200\n",
            "22/22 - 0s - loss: 82293.3984 - accuracy: 0.1017 - val_loss: 18178.9082 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 45/200\n",
            "22/22 - 0s - loss: 82293.3672 - accuracy: 0.1017 - val_loss: 18178.8867 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 46/200\n",
            "22/22 - 0s - loss: 82293.3438 - accuracy: 0.1017 - val_loss: 18178.8691 - val_accuracy: 0.0706 - 91ms/epoch - 4ms/step\n",
            "Epoch 47/200\n",
            "22/22 - 0s - loss: 82293.3359 - accuracy: 0.1017 - val_loss: 18178.8516 - val_accuracy: 0.0706 - 85ms/epoch - 4ms/step\n",
            "Epoch 48/200\n",
            "22/22 - 0s - loss: 82293.3125 - accuracy: 0.1017 - val_loss: 18178.8320 - val_accuracy: 0.0706 - 93ms/epoch - 4ms/step\n",
            "Epoch 49/200\n",
            "22/22 - 0s - loss: 82293.2891 - accuracy: 0.1017 - val_loss: 18178.8125 - val_accuracy: 0.0706 - 93ms/epoch - 4ms/step\n",
            "Epoch 50/200\n",
            "22/22 - 0s - loss: 82293.2656 - accuracy: 0.1017 - val_loss: 18178.7930 - val_accuracy: 0.0706 - 95ms/epoch - 4ms/step\n",
            "Epoch 51/200\n",
            "22/22 - 0s - loss: 82293.2578 - accuracy: 0.1017 - val_loss: 18178.7754 - val_accuracy: 0.0706 - 90ms/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "22/22 - 0s - loss: 82293.2344 - accuracy: 0.1017 - val_loss: 18178.7559 - val_accuracy: 0.0706 - 94ms/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "22/22 - 0s - loss: 82293.2109 - accuracy: 0.1017 - val_loss: 18178.7344 - val_accuracy: 0.0706 - 91ms/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "22/22 - 0s - loss: 82293.1797 - accuracy: 0.1017 - val_loss: 18178.7168 - val_accuracy: 0.0706 - 78ms/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "22/22 - 0s - loss: 82293.1719 - accuracy: 0.1017 - val_loss: 18178.6953 - val_accuracy: 0.0706 - 86ms/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "22/22 - 0s - loss: 82293.1484 - accuracy: 0.1017 - val_loss: 18178.6758 - val_accuracy: 0.0706 - 79ms/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "22/22 - 0s - loss: 82293.1406 - accuracy: 0.1017 - val_loss: 18178.6582 - val_accuracy: 0.0706 - 90ms/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "22/22 - 0s - loss: 82293.1172 - accuracy: 0.0993 - val_loss: 18178.6387 - val_accuracy: 0.0706 - 90ms/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "22/22 - 0s - loss: 82293.0938 - accuracy: 0.0993 - val_loss: 18178.6172 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "22/22 - 0s - loss: 82293.0781 - accuracy: 0.0993 - val_loss: 18178.5977 - val_accuracy: 0.0706 - 87ms/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "22/22 - 0s - loss: 82293.0703 - accuracy: 0.0993 - val_loss: 18178.5781 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "22/22 - 0s - loss: 82293.0391 - accuracy: 0.0993 - val_loss: 18178.5586 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "22/22 - 0s - loss: 82293.0078 - accuracy: 0.0993 - val_loss: 18178.5371 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "22/22 - 0s - loss: 82293.0000 - accuracy: 0.0993 - val_loss: 18178.5176 - val_accuracy: 0.0706 - 103ms/epoch - 5ms/step\n",
            "Epoch 65/200\n",
            "22/22 - 0s - loss: 82292.9766 - accuracy: 0.0993 - val_loss: 18178.4980 - val_accuracy: 0.0706 - 79ms/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "22/22 - 0s - loss: 82292.9453 - accuracy: 0.0993 - val_loss: 18178.4766 - val_accuracy: 0.0706 - 85ms/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "22/22 - 0s - loss: 82292.9453 - accuracy: 0.0993 - val_loss: 18178.4570 - val_accuracy: 0.0706 - 91ms/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "22/22 - 0s - loss: 82292.9062 - accuracy: 0.0993 - val_loss: 18178.4375 - val_accuracy: 0.0706 - 98ms/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "22/22 - 0s - loss: 82292.8906 - accuracy: 0.0993 - val_loss: 18178.4180 - val_accuracy: 0.0706 - 86ms/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "22/22 - 0s - loss: 82292.8828 - accuracy: 0.0993 - val_loss: 18178.3965 - val_accuracy: 0.0706 - 85ms/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "22/22 - 0s - loss: 82292.8516 - accuracy: 0.0993 - val_loss: 18178.3770 - val_accuracy: 0.0706 - 89ms/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "22/22 - 0s - loss: 82292.8281 - accuracy: 0.0993 - val_loss: 18178.3574 - val_accuracy: 0.0706 - 97ms/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "22/22 - 0s - loss: 82292.8125 - accuracy: 0.0993 - val_loss: 18178.3340 - val_accuracy: 0.0706 - 78ms/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "22/22 - 0s - loss: 82292.7891 - accuracy: 0.0993 - val_loss: 18178.3145 - val_accuracy: 0.0706 - 86ms/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "22/22 - 0s - loss: 82292.7578 - accuracy: 0.0993 - val_loss: 18178.2930 - val_accuracy: 0.0706 - 76ms/epoch - 3ms/step\n",
            "Epoch 76/200\n",
            "22/22 - 0s - loss: 82292.7422 - accuracy: 0.0993 - val_loss: 18178.2734 - val_accuracy: 0.0706 - 84ms/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "22/22 - 0s - loss: 82292.7266 - accuracy: 0.0993 - val_loss: 18178.2480 - val_accuracy: 0.0706 - 80ms/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "22/22 - 0s - loss: 82292.7031 - accuracy: 0.0993 - val_loss: 18178.2266 - val_accuracy: 0.0706 - 79ms/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "22/22 - 0s - loss: 82292.6875 - accuracy: 0.0993 - val_loss: 18178.2070 - val_accuracy: 0.0706 - 84ms/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "22/22 - 0s - loss: 82292.6641 - accuracy: 0.0993 - val_loss: 18178.1855 - val_accuracy: 0.0706 - 87ms/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "22/22 - 0s - loss: 82292.6406 - accuracy: 0.0993 - val_loss: 18178.1660 - val_accuracy: 0.0706 - 78ms/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "22/22 - 0s - loss: 82292.6250 - accuracy: 0.0993 - val_loss: 18178.1445 - val_accuracy: 0.0706 - 92ms/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "22/22 - 0s - loss: 82292.6016 - accuracy: 0.0993 - val_loss: 18178.1211 - val_accuracy: 0.0706 - 78ms/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "22/22 - 0s - loss: 82292.5781 - accuracy: 0.0993 - val_loss: 18178.1016 - val_accuracy: 0.0706 - 81ms/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "22/22 - 0s - loss: 82292.5547 - accuracy: 0.0993 - val_loss: 18178.0801 - val_accuracy: 0.0706 - 86ms/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "22/22 - 0s - loss: 82292.5312 - accuracy: 0.0993 - val_loss: 18178.0605 - val_accuracy: 0.0706 - 83ms/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "22/22 - 0s - loss: 82292.5156 - accuracy: 0.0993 - val_loss: 18178.0371 - val_accuracy: 0.0706 - 85ms/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "22/22 - 0s - loss: 82292.4922 - accuracy: 0.0993 - val_loss: 18178.0156 - val_accuracy: 0.0706 - 82ms/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "22/22 - 0s - loss: 82292.4609 - accuracy: 0.0993 - val_loss: 18177.9961 - val_accuracy: 0.0706 - 94ms/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "22/22 - 0s - loss: 82292.4453 - accuracy: 0.0993 - val_loss: 18177.9727 - val_accuracy: 0.0706 - 94ms/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "22/22 - 0s - loss: 82292.4219 - accuracy: 0.0993 - val_loss: 18177.9492 - val_accuracy: 0.0706 - 97ms/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "22/22 - 0s - loss: 82293.7500 - accuracy: 0.1032 - val_loss: 18177.9238 - val_accuracy: 0.0706 - 88ms/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "22/22 - 0s - loss: 82292.5156 - accuracy: 0.1001 - val_loss: 18177.9375 - val_accuracy: 0.0745 - 84ms/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "22/22 - 0s - loss: 82293.0938 - accuracy: 0.1072 - val_loss: 18177.8809 - val_accuracy: 0.0706 - 96ms/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "22/22 - 0s - loss: 82294.0312 - accuracy: 0.1001 - val_loss: 18177.8691 - val_accuracy: 0.0706 - 81ms/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "22/22 - 0s - loss: 82293.4375 - accuracy: 0.1001 - val_loss: 18177.8418 - val_accuracy: 0.0706 - 89ms/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "22/22 - 0s - loss: 82293.7578 - accuracy: 0.0993 - val_loss: 18177.8301 - val_accuracy: 0.0706 - 89ms/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "22/22 - 0s - loss: 82293.5078 - accuracy: 0.1009 - val_loss: 18177.8047 - val_accuracy: 0.0706 - 78ms/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "22/22 - 0s - loss: 82294.1016 - accuracy: 0.1001 - val_loss: 18177.7910 - val_accuracy: 0.0706 - 86ms/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "22/22 - 0s - loss: 82294.3438 - accuracy: 0.1017 - val_loss: 18177.7695 - val_accuracy: 0.0706 - 84ms/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "22/22 - 0s - loss: 83865.8438 - accuracy: 0.1781 - val_loss: 19447.6621 - val_accuracy: 0.2902 - 91ms/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "22/22 - 0s - loss: 82359.0078 - accuracy: 0.1064 - val_loss: 18177.7891 - val_accuracy: 0.0667 - 88ms/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "22/22 - 0s - loss: 82292.2656 - accuracy: 0.0993 - val_loss: 18177.7715 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "22/22 - 0s - loss: 82292.2500 - accuracy: 0.0993 - val_loss: 18177.7461 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "22/22 - 0s - loss: 82292.2109 - accuracy: 0.0993 - val_loss: 18177.7266 - val_accuracy: 0.0667 - 81ms/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "22/22 - 0s - loss: 82292.1953 - accuracy: 0.0993 - val_loss: 18177.7031 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "22/22 - 0s - loss: 82292.1719 - accuracy: 0.0993 - val_loss: 18177.6816 - val_accuracy: 0.0667 - 90ms/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "22/22 - 0s - loss: 82292.1562 - accuracy: 0.0993 - val_loss: 18177.6602 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "22/22 - 0s - loss: 82292.1328 - accuracy: 0.0993 - val_loss: 18177.6367 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "22/22 - 0s - loss: 82292.1016 - accuracy: 0.0993 - val_loss: 18177.6133 - val_accuracy: 0.0667 - 85ms/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "22/22 - 0s - loss: 82292.0781 - accuracy: 0.0993 - val_loss: 18177.5918 - val_accuracy: 0.0667 - 81ms/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "22/22 - 0s - loss: 82292.0547 - accuracy: 0.0993 - val_loss: 18177.5684 - val_accuracy: 0.0667 - 82ms/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "22/22 - 0s - loss: 82292.0312 - accuracy: 0.0993 - val_loss: 18177.5449 - val_accuracy: 0.0667 - 94ms/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "22/22 - 0s - loss: 82292.0078 - accuracy: 0.0993 - val_loss: 18177.5234 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "22/22 - 0s - loss: 82291.9922 - accuracy: 0.0993 - val_loss: 18177.5020 - val_accuracy: 0.0667 - 94ms/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "22/22 - 0s - loss: 82291.9688 - accuracy: 0.0993 - val_loss: 18177.4785 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "22/22 - 0s - loss: 82291.9375 - accuracy: 0.0993 - val_loss: 18177.4551 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "22/22 - 0s - loss: 82291.9219 - accuracy: 0.0993 - val_loss: 18177.4336 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "22/22 - 0s - loss: 82291.8984 - accuracy: 0.0993 - val_loss: 18177.4102 - val_accuracy: 0.0667 - 90ms/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "22/22 - 0s - loss: 82291.8750 - accuracy: 0.0993 - val_loss: 18177.3867 - val_accuracy: 0.0667 - 81ms/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "22/22 - 0s - loss: 82291.8594 - accuracy: 0.0993 - val_loss: 18177.3652 - val_accuracy: 0.0667 - 86ms/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "22/22 - 0s - loss: 82291.8359 - accuracy: 0.0993 - val_loss: 18177.3418 - val_accuracy: 0.0667 - 90ms/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "22/22 - 0s - loss: 82291.7891 - accuracy: 0.0993 - val_loss: 18177.3184 - val_accuracy: 0.0667 - 88ms/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "22/22 - 0s - loss: 82291.7734 - accuracy: 0.0993 - val_loss: 18177.2949 - val_accuracy: 0.0667 - 102ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "22/22 - 0s - loss: 82291.7422 - accuracy: 0.0993 - val_loss: 18177.2715 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "22/22 - 0s - loss: 82291.7266 - accuracy: 0.0993 - val_loss: 18177.2461 - val_accuracy: 0.0667 - 92ms/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "22/22 - 0s - loss: 82291.7031 - accuracy: 0.0993 - val_loss: 18177.2227 - val_accuracy: 0.0667 - 87ms/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "22/22 - 0s - loss: 82291.6875 - accuracy: 0.0993 - val_loss: 18177.2012 - val_accuracy: 0.0667 - 94ms/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "22/22 - 0s - loss: 82291.6484 - accuracy: 0.0993 - val_loss: 18177.1758 - val_accuracy: 0.0667 - 87ms/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "22/22 - 0s - loss: 82291.6328 - accuracy: 0.0993 - val_loss: 18177.1523 - val_accuracy: 0.0667 - 79ms/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "22/22 - 0s - loss: 82291.5938 - accuracy: 0.0993 - val_loss: 18177.1289 - val_accuracy: 0.0667 - 82ms/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "22/22 - 0s - loss: 82291.5859 - accuracy: 0.0993 - val_loss: 18177.1055 - val_accuracy: 0.0667 - 91ms/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "22/22 - 0s - loss: 82291.5625 - accuracy: 0.0993 - val_loss: 18177.0820 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "22/22 - 0s - loss: 82291.5391 - accuracy: 0.0993 - val_loss: 18177.0586 - val_accuracy: 0.0667 - 85ms/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "22/22 - 0s - loss: 82291.5156 - accuracy: 0.0993 - val_loss: 18177.0332 - val_accuracy: 0.0667 - 90ms/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "22/22 - 0s - loss: 82291.4922 - accuracy: 0.0993 - val_loss: 18177.0098 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "22/22 - 0s - loss: 82291.4609 - accuracy: 0.0993 - val_loss: 18176.9863 - val_accuracy: 0.0667 - 102ms/epoch - 5ms/step\n",
            "Epoch 138/200\n",
            "22/22 - 0s - loss: 82291.4375 - accuracy: 0.0993 - val_loss: 18176.9629 - val_accuracy: 0.0667 - 85ms/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "22/22 - 0s - loss: 82291.4141 - accuracy: 0.0993 - val_loss: 18176.9375 - val_accuracy: 0.0667 - 93ms/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "22/22 - 0s - loss: 82291.3906 - accuracy: 0.0993 - val_loss: 18176.9141 - val_accuracy: 0.0667 - 101ms/epoch - 5ms/step\n",
            "Epoch 141/200\n",
            "22/22 - 0s - loss: 82291.3672 - accuracy: 0.0993 - val_loss: 18176.8906 - val_accuracy: 0.0667 - 88ms/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "22/22 - 0s - loss: 82291.3438 - accuracy: 0.0993 - val_loss: 18176.8672 - val_accuracy: 0.0667 - 89ms/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "22/22 - 0s - loss: 82291.3125 - accuracy: 0.0993 - val_loss: 18176.8418 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "22/22 - 0s - loss: 82291.2812 - accuracy: 0.0993 - val_loss: 18176.8184 - val_accuracy: 0.0667 - 94ms/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "22/22 - 0s - loss: 82291.2891 - accuracy: 0.0993 - val_loss: 18176.7930 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "22/22 - 0s - loss: 82291.2500 - accuracy: 0.0993 - val_loss: 18176.7695 - val_accuracy: 0.0667 - 99ms/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "22/22 - 0s - loss: 82291.2188 - accuracy: 0.0993 - val_loss: 18176.7422 - val_accuracy: 0.0667 - 82ms/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "22/22 - 0s - loss: 82291.1875 - accuracy: 0.0993 - val_loss: 18176.7188 - val_accuracy: 0.0667 - 88ms/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "22/22 - 0s - loss: 82291.1719 - accuracy: 0.0993 - val_loss: 18176.6934 - val_accuracy: 0.0667 - 91ms/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "22/22 - 0s - loss: 82291.1406 - accuracy: 0.0993 - val_loss: 18176.6699 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "22/22 - 0s - loss: 82291.1172 - accuracy: 0.0993 - val_loss: 18176.6445 - val_accuracy: 0.0667 - 85ms/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "22/22 - 0s - loss: 82291.1016 - accuracy: 0.0993 - val_loss: 18176.6191 - val_accuracy: 0.0667 - 86ms/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "22/22 - 0s - loss: 82291.0625 - accuracy: 0.0993 - val_loss: 18176.5957 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "22/22 - 0s - loss: 82291.0391 - accuracy: 0.0993 - val_loss: 18176.5703 - val_accuracy: 0.0667 - 75ms/epoch - 3ms/step\n",
            "Epoch 155/200\n",
            "22/22 - 0s - loss: 82291.0234 - accuracy: 0.0993 - val_loss: 18176.5449 - val_accuracy: 0.0667 - 85ms/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "22/22 - 0s - loss: 82290.9844 - accuracy: 0.0993 - val_loss: 18176.5215 - val_accuracy: 0.0667 - 77ms/epoch - 3ms/step\n",
            "Epoch 157/200\n",
            "22/22 - 0s - loss: 82290.9609 - accuracy: 0.0993 - val_loss: 18176.4961 - val_accuracy: 0.0667 - 96ms/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "22/22 - 0s - loss: 82290.9375 - accuracy: 0.0993 - val_loss: 18176.4707 - val_accuracy: 0.0667 - 88ms/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "22/22 - 0s - loss: 82290.9062 - accuracy: 0.0993 - val_loss: 18176.4473 - val_accuracy: 0.0667 - 86ms/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "22/22 - 0s - loss: 82290.8906 - accuracy: 0.0993 - val_loss: 18176.4219 - val_accuracy: 0.0667 - 82ms/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "22/22 - 0s - loss: 82290.8594 - accuracy: 0.0993 - val_loss: 18176.3965 - val_accuracy: 0.0667 - 87ms/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "22/22 - 0s - loss: 82290.8203 - accuracy: 0.0993 - val_loss: 18176.3711 - val_accuracy: 0.0667 - 97ms/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "22/22 - 0s - loss: 82290.8047 - accuracy: 0.0993 - val_loss: 18176.3457 - val_accuracy: 0.0667 - 88ms/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "22/22 - 0s - loss: 82290.7656 - accuracy: 0.0993 - val_loss: 18176.3223 - val_accuracy: 0.0667 - 89ms/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "22/22 - 0s - loss: 82290.7578 - accuracy: 0.0993 - val_loss: 18176.2949 - val_accuracy: 0.0667 - 77ms/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "22/22 - 0s - loss: 82290.7188 - accuracy: 0.0993 - val_loss: 18176.2715 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "22/22 - 0s - loss: 82290.6953 - accuracy: 0.0993 - val_loss: 18176.2422 - val_accuracy: 0.0667 - 85ms/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "22/22 - 0s - loss: 82290.6641 - accuracy: 0.0993 - val_loss: 18176.2188 - val_accuracy: 0.0667 - 95ms/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "22/22 - 0s - loss: 82290.6406 - accuracy: 0.0993 - val_loss: 18176.1914 - val_accuracy: 0.0667 - 85ms/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "22/22 - 0s - loss: 82290.6250 - accuracy: 0.0993 - val_loss: 18176.1680 - val_accuracy: 0.0667 - 88ms/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "22/22 - 0s - loss: 82290.5938 - accuracy: 0.0993 - val_loss: 18176.1426 - val_accuracy: 0.0667 - 81ms/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "22/22 - 0s - loss: 82290.5625 - accuracy: 0.0993 - val_loss: 18176.1172 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "22/22 - 0s - loss: 82290.5469 - accuracy: 0.0993 - val_loss: 18176.0918 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "22/22 - 0s - loss: 82290.5234 - accuracy: 0.0993 - val_loss: 18176.0664 - val_accuracy: 0.0667 - 78ms/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "22/22 - 0s - loss: 82290.4844 - accuracy: 0.0993 - val_loss: 18176.0410 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "22/22 - 0s - loss: 82290.4688 - accuracy: 0.0993 - val_loss: 18176.0156 - val_accuracy: 0.0667 - 82ms/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "22/22 - 0s - loss: 82290.4297 - accuracy: 0.0993 - val_loss: 18175.9922 - val_accuracy: 0.0667 - 86ms/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "22/22 - 0s - loss: 82290.4219 - accuracy: 0.0993 - val_loss: 18175.9648 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "22/22 - 0s - loss: 82290.3984 - accuracy: 0.0993 - val_loss: 18175.9375 - val_accuracy: 0.0667 - 82ms/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "22/22 - 0s - loss: 82290.3359 - accuracy: 0.0993 - val_loss: 18175.9121 - val_accuracy: 0.0667 - 95ms/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "22/22 - 0s - loss: 82290.3359 - accuracy: 0.0993 - val_loss: 18175.8887 - val_accuracy: 0.0667 - 93ms/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "22/22 - 0s - loss: 82290.3047 - accuracy: 0.0993 - val_loss: 18175.8613 - val_accuracy: 0.0667 - 78ms/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "22/22 - 0s - loss: 82290.2812 - accuracy: 0.0993 - val_loss: 18175.8359 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "22/22 - 0s - loss: 82290.2422 - accuracy: 0.0993 - val_loss: 18175.8086 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "22/22 - 0s - loss: 82290.2188 - accuracy: 0.0993 - val_loss: 18175.7832 - val_accuracy: 0.0667 - 87ms/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "22/22 - 0s - loss: 82290.1953 - accuracy: 0.0993 - val_loss: 18175.7578 - val_accuracy: 0.0667 - 81ms/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "22/22 - 0s - loss: 82290.1719 - accuracy: 0.0993 - val_loss: 18175.7305 - val_accuracy: 0.0667 - 82ms/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "22/22 - 0s - loss: 82290.1562 - accuracy: 0.0993 - val_loss: 18175.7031 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "22/22 - 0s - loss: 82290.1094 - accuracy: 0.0993 - val_loss: 18175.6777 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "22/22 - 0s - loss: 82290.0781 - accuracy: 0.0993 - val_loss: 18175.6523 - val_accuracy: 0.0667 - 80ms/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "22/22 - 0s - loss: 82290.0547 - accuracy: 0.0993 - val_loss: 18175.6270 - val_accuracy: 0.0667 - 91ms/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "22/22 - 0s - loss: 82290.0391 - accuracy: 0.0993 - val_loss: 18175.5996 - val_accuracy: 0.0667 - 100ms/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "22/22 - 0s - loss: 82290.0078 - accuracy: 0.0993 - val_loss: 18175.5742 - val_accuracy: 0.0667 - 87ms/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "22/22 - 0s - loss: 82289.9766 - accuracy: 0.0993 - val_loss: 18175.5488 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "22/22 - 0s - loss: 82289.9453 - accuracy: 0.0993 - val_loss: 18175.5215 - val_accuracy: 0.0667 - 86ms/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "22/22 - 0s - loss: 82289.9219 - accuracy: 0.0993 - val_loss: 18175.4961 - val_accuracy: 0.0667 - 84ms/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "22/22 - 0s - loss: 82289.8906 - accuracy: 0.0993 - val_loss: 18175.4707 - val_accuracy: 0.0667 - 98ms/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "22/22 - 0s - loss: 82289.8828 - accuracy: 0.0993 - val_loss: 18175.4434 - val_accuracy: 0.0667 - 81ms/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "22/22 - 0s - loss: 82289.8438 - accuracy: 0.0993 - val_loss: 18175.4180 - val_accuracy: 0.0667 - 77ms/epoch - 3ms/step\n",
            "Epoch 200/200\n",
            "22/22 - 0s - loss: 82289.8125 - accuracy: 0.0993 - val_loss: 18175.3926 - val_accuracy: 0.0667 - 83ms/epoch - 4ms/step\n",
            "[[8.46832377e-02 1.60000000e+01 8.00000000e+00 2.00000000e+01\n",
            "  1.00000000e+02 8.00000000e+00 3.20000000e+01]]\n",
            "l1 16\n",
            "epochs 100\n",
            "20\n",
            "0.08468323771720933\n",
            "Epoch 1/100\n",
            "70/70 - 1s - loss: 104126.0938 - accuracy: 0.2869 - val_loss: 26305.8086 - val_accuracy: 0.6462 - 719ms/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "70/70 - 0s - loss: 75624.8906 - accuracy: 0.5438 - val_loss: 25711.2520 - val_accuracy: 0.6462 - 205ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "70/70 - 0s - loss: 75538.1719 - accuracy: 0.6040 - val_loss: 25709.6133 - val_accuracy: 0.6462 - 193ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "70/70 - 0s - loss: 75523.6016 - accuracy: 0.5933 - val_loss: 25752.7109 - val_accuracy: 0.6462 - 197ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "70/70 - 0s - loss: 75537.5000 - accuracy: 0.5825 - val_loss: 25725.6777 - val_accuracy: 0.6462 - 200ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "70/70 - 0s - loss: 75512.2422 - accuracy: 0.6062 - val_loss: 25770.4082 - val_accuracy: 0.6462 - 198ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "70/70 - 0s - loss: 75533.5156 - accuracy: 0.5768 - val_loss: 25758.6465 - val_accuracy: 0.6462 - 213ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "70/70 - 0s - loss: 75534.8438 - accuracy: 0.6069 - val_loss: 25738.0352 - val_accuracy: 0.6462 - 192ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "70/70 - 0s - loss: 75572.3828 - accuracy: 0.5631 - val_loss: 25680.9629 - val_accuracy: 0.6462 - 193ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "70/70 - 0s - loss: 75511.7500 - accuracy: 0.5940 - val_loss: 25651.0840 - val_accuracy: 0.6462 - 198ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "70/70 - 0s - loss: 75510.7969 - accuracy: 0.5904 - val_loss: 25706.5078 - val_accuracy: 0.6462 - 208ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "70/70 - 0s - loss: 75508.4531 - accuracy: 0.5890 - val_loss: 25674.5547 - val_accuracy: 0.6462 - 225ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "70/70 - 0s - loss: 75490.4141 - accuracy: 0.6055 - val_loss: 25668.9395 - val_accuracy: 0.6462 - 196ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "70/70 - 0s - loss: 75493.0938 - accuracy: 0.5753 - val_loss: 25646.9023 - val_accuracy: 0.6462 - 194ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "70/70 - 0s - loss: 75498.2812 - accuracy: 0.6076 - val_loss: 25640.4043 - val_accuracy: 0.6462 - 197ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "70/70 - 0s - loss: 75485.3047 - accuracy: 0.5703 - val_loss: 25653.1855 - val_accuracy: 0.6462 - 199ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "70/70 - 0s - loss: 75504.5391 - accuracy: 0.6069 - val_loss: 25663.7246 - val_accuracy: 0.6462 - 200ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "70/70 - 0s - loss: 75497.2266 - accuracy: 0.5653 - val_loss: 25637.7305 - val_accuracy: 0.6462 - 196ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "70/70 - 0s - loss: 75472.3594 - accuracy: 0.5933 - val_loss: 25662.9199 - val_accuracy: 0.6462 - 190ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "70/70 - 0s - loss: 75517.5156 - accuracy: 0.5882 - val_loss: 25679.4336 - val_accuracy: 0.6462 - 195ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "70/70 - 0s - loss: 75473.0156 - accuracy: 0.6069 - val_loss: 25659.2812 - val_accuracy: 0.6462 - 201ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "70/70 - 0s - loss: 75458.0234 - accuracy: 0.6062 - val_loss: 25650.7969 - val_accuracy: 0.6462 - 208ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "70/70 - 0s - loss: 75459.6719 - accuracy: 0.6055 - val_loss: 25699.8086 - val_accuracy: 0.6462 - 189ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "70/70 - 0s - loss: 75454.0625 - accuracy: 0.6055 - val_loss: 25667.5508 - val_accuracy: 0.6462 - 187ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "70/70 - 0s - loss: 75440.1406 - accuracy: 0.6055 - val_loss: 25657.3809 - val_accuracy: 0.6462 - 195ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "70/70 - 0s - loss: 75424.3984 - accuracy: 0.6062 - val_loss: 25644.3418 - val_accuracy: 0.6462 - 188ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "70/70 - 0s - loss: 75429.3047 - accuracy: 0.5925 - val_loss: 25657.3848 - val_accuracy: 0.6462 - 203ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "70/70 - 0s - loss: 75406.7969 - accuracy: 0.6062 - val_loss: 25633.9785 - val_accuracy: 0.6462 - 197ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "70/70 - 0s - loss: 75425.9375 - accuracy: 0.6062 - val_loss: 25646.7422 - val_accuracy: 0.6462 - 204ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "70/70 - 0s - loss: 75365.8438 - accuracy: 0.6062 - val_loss: 25712.7344 - val_accuracy: 0.6462 - 189ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "70/70 - 0s - loss: 75425.5391 - accuracy: 0.5660 - val_loss: 25651.5000 - val_accuracy: 0.6462 - 185ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "70/70 - 0s - loss: 75395.0859 - accuracy: 0.6062 - val_loss: 25588.0078 - val_accuracy: 0.6462 - 206ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "70/70 - 0s - loss: 75369.6016 - accuracy: 0.6062 - val_loss: 25627.5918 - val_accuracy: 0.6462 - 200ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "70/70 - 0s - loss: 75356.8438 - accuracy: 0.6062 - val_loss: 25594.9180 - val_accuracy: 0.6462 - 180ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "70/70 - 0s - loss: 75316.7500 - accuracy: 0.6062 - val_loss: 25623.4609 - val_accuracy: 0.6462 - 194ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "70/70 - 0s - loss: 75304.6797 - accuracy: 0.6062 - val_loss: 25568.4004 - val_accuracy: 0.6462 - 186ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "70/70 - 0s - loss: 75336.9062 - accuracy: 0.6062 - val_loss: 25572.3164 - val_accuracy: 0.6462 - 203ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "70/70 - 0s - loss: 75295.8828 - accuracy: 0.6062 - val_loss: 25674.0840 - val_accuracy: 0.6462 - 183ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "70/70 - 0s - loss: 75315.9922 - accuracy: 0.6062 - val_loss: 25567.7363 - val_accuracy: 0.6462 - 187ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "70/70 - 0s - loss: 75263.3438 - accuracy: 0.6062 - val_loss: 25614.7578 - val_accuracy: 0.6462 - 186ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "70/70 - 0s - loss: 75270.7578 - accuracy: 0.6062 - val_loss: 25710.0371 - val_accuracy: 0.6462 - 198ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "70/70 - 0s - loss: 75254.7578 - accuracy: 0.6062 - val_loss: 25668.6738 - val_accuracy: 0.6462 - 198ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "70/70 - 0s - loss: 75253.0938 - accuracy: 0.6047 - val_loss: 25620.1328 - val_accuracy: 0.6462 - 199ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "70/70 - 0s - loss: 75213.1328 - accuracy: 0.6062 - val_loss: 25585.4844 - val_accuracy: 0.6462 - 180ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "70/70 - 0s - loss: 75276.4375 - accuracy: 0.5947 - val_loss: 25532.6504 - val_accuracy: 0.6462 - 189ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "70/70 - 0s - loss: 75219.6016 - accuracy: 0.6062 - val_loss: 25731.7988 - val_accuracy: 0.6462 - 194ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "70/70 - 0s - loss: 75219.9141 - accuracy: 0.6011 - val_loss: 25513.2617 - val_accuracy: 0.6462 - 197ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "70/70 - 0s - loss: 75185.1562 - accuracy: 0.6062 - val_loss: 25577.9590 - val_accuracy: 0.6462 - 205ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "70/70 - 0s - loss: 75161.0859 - accuracy: 0.6062 - val_loss: 25603.2422 - val_accuracy: 0.6462 - 191ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "70/70 - 0s - loss: 75154.3750 - accuracy: 0.6062 - val_loss: 25513.0156 - val_accuracy: 0.6462 - 189ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "70/70 - 0s - loss: 75159.8516 - accuracy: 0.6062 - val_loss: 25515.7285 - val_accuracy: 0.6462 - 191ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "70/70 - 0s - loss: 75145.3984 - accuracy: 0.6062 - val_loss: 25544.3770 - val_accuracy: 0.6462 - 201ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "70/70 - 0s - loss: 75138.0859 - accuracy: 0.6062 - val_loss: 25561.9219 - val_accuracy: 0.6462 - 195ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "70/70 - 0s - loss: 75171.2188 - accuracy: 0.6062 - val_loss: 25509.8066 - val_accuracy: 0.6462 - 194ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "70/70 - 0s - loss: 75135.9453 - accuracy: 0.6062 - val_loss: 25531.3047 - val_accuracy: 0.6462 - 188ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "70/70 - 0s - loss: 75162.5625 - accuracy: 0.6062 - val_loss: 25526.3418 - val_accuracy: 0.6462 - 199ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "70/70 - 0s - loss: 75192.7891 - accuracy: 0.6062 - val_loss: 25675.5723 - val_accuracy: 0.6462 - 215ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "70/70 - 0s - loss: 75166.7891 - accuracy: 0.6062 - val_loss: 25563.1484 - val_accuracy: 0.6462 - 207ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "70/70 - 0s - loss: 75187.9688 - accuracy: 0.6062 - val_loss: 25561.5762 - val_accuracy: 0.6462 - 185ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "70/70 - 0s - loss: 75144.6953 - accuracy: 0.6062 - val_loss: 25516.8320 - val_accuracy: 0.6462 - 197ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "70/70 - 0s - loss: 75131.5781 - accuracy: 0.6062 - val_loss: 25482.1504 - val_accuracy: 0.6462 - 199ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "70/70 - 0s - loss: 75103.8828 - accuracy: 0.6062 - val_loss: 25486.0137 - val_accuracy: 0.6462 - 207ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "70/70 - 0s - loss: 75130.7812 - accuracy: 0.6062 - val_loss: 25526.4219 - val_accuracy: 0.6462 - 205ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "70/70 - 0s - loss: 75111.1484 - accuracy: 0.6062 - val_loss: 25508.1855 - val_accuracy: 0.6462 - 191ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "70/70 - 0s - loss: 75124.3594 - accuracy: 0.6062 - val_loss: 25635.8848 - val_accuracy: 0.6462 - 195ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "70/70 - 0s - loss: 75136.7422 - accuracy: 0.6062 - val_loss: 25512.3613 - val_accuracy: 0.6462 - 189ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "70/70 - 0s - loss: 75118.1328 - accuracy: 0.6062 - val_loss: 25482.6621 - val_accuracy: 0.6462 - 219ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "70/70 - 0s - loss: 75082.0781 - accuracy: 0.6062 - val_loss: 25524.1543 - val_accuracy: 0.6462 - 199ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "70/70 - 0s - loss: 75086.0469 - accuracy: 0.6062 - val_loss: 25510.6426 - val_accuracy: 0.6462 - 194ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "70/70 - 0s - loss: 75088.0781 - accuracy: 0.6062 - val_loss: 25524.0117 - val_accuracy: 0.6462 - 198ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "70/70 - 0s - loss: 75169.6953 - accuracy: 0.6062 - val_loss: 25520.1895 - val_accuracy: 0.6462 - 189ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "70/70 - 0s - loss: 75075.0547 - accuracy: 0.6062 - val_loss: 25514.5566 - val_accuracy: 0.6462 - 202ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "70/70 - 0s - loss: 75086.7188 - accuracy: 0.6062 - val_loss: 25638.6211 - val_accuracy: 0.6462 - 185ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "70/70 - 0s - loss: 75106.3672 - accuracy: 0.6062 - val_loss: 25483.1074 - val_accuracy: 0.6462 - 189ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "70/70 - 0s - loss: 75092.7500 - accuracy: 0.6062 - val_loss: 25597.4297 - val_accuracy: 0.6462 - 191ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "70/70 - 0s - loss: 75100.7422 - accuracy: 0.6062 - val_loss: 25543.8535 - val_accuracy: 0.6462 - 198ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "70/70 - 0s - loss: 75128.0234 - accuracy: 0.6062 - val_loss: 25493.8086 - val_accuracy: 0.6462 - 210ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "70/70 - 0s - loss: 75143.8281 - accuracy: 0.6062 - val_loss: 25527.7969 - val_accuracy: 0.6462 - 187ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "70/70 - 0s - loss: 75100.9297 - accuracy: 0.6062 - val_loss: 25506.1387 - val_accuracy: 0.6462 - 198ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "70/70 - 0s - loss: 75065.6016 - accuracy: 0.6062 - val_loss: 25485.8574 - val_accuracy: 0.6462 - 206ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "70/70 - 0s - loss: 75097.5703 - accuracy: 0.6062 - val_loss: 25475.3965 - val_accuracy: 0.6462 - 191ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "70/70 - 0s - loss: 75096.3125 - accuracy: 0.6062 - val_loss: 25555.4883 - val_accuracy: 0.6462 - 205ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "70/70 - 0s - loss: 75094.8203 - accuracy: 0.6062 - val_loss: 25510.7285 - val_accuracy: 0.6462 - 192ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "70/70 - 0s - loss: 75134.7812 - accuracy: 0.6062 - val_loss: 25622.2578 - val_accuracy: 0.6462 - 185ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "70/70 - 0s - loss: 75105.7656 - accuracy: 0.6062 - val_loss: 25537.7402 - val_accuracy: 0.6462 - 191ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "70/70 - 0s - loss: 75164.9453 - accuracy: 0.6026 - val_loss: 25530.4004 - val_accuracy: 0.6462 - 196ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "70/70 - 0s - loss: 75165.3984 - accuracy: 0.6062 - val_loss: 25531.7109 - val_accuracy: 0.6462 - 203ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "70/70 - 0s - loss: 75189.5312 - accuracy: 0.6062 - val_loss: 25710.2949 - val_accuracy: 0.6462 - 190ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "70/70 - 0s - loss: 75086.9766 - accuracy: 0.6062 - val_loss: 25749.8809 - val_accuracy: 0.6462 - 192ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "70/70 - 0s - loss: 75074.7656 - accuracy: 0.6062 - val_loss: 25497.2461 - val_accuracy: 0.6462 - 196ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "70/70 - 0s - loss: 75100.2422 - accuracy: 0.6062 - val_loss: 25577.7930 - val_accuracy: 0.6462 - 195ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "70/70 - 0s - loss: 75081.6094 - accuracy: 0.6062 - val_loss: 25573.7715 - val_accuracy: 0.6462 - 203ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "70/70 - 0s - loss: 75070.2500 - accuracy: 0.6062 - val_loss: 25559.9766 - val_accuracy: 0.6462 - 202ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "70/70 - 0s - loss: 75056.6406 - accuracy: 0.6062 - val_loss: 25528.6777 - val_accuracy: 0.6462 - 187ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "70/70 - 0s - loss: 75081.6562 - accuracy: 0.6062 - val_loss: 25535.8652 - val_accuracy: 0.6462 - 195ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "70/70 - 0s - loss: 75077.2031 - accuracy: 0.6062 - val_loss: 25524.7500 - val_accuracy: 0.6462 - 194ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "70/70 - 0s - loss: 75055.3594 - accuracy: 0.6062 - val_loss: 25497.0840 - val_accuracy: 0.6462 - 201ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "70/70 - 0s - loss: 75108.7422 - accuracy: 0.6062 - val_loss: 25487.0879 - val_accuracy: 0.6462 - 187ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "70/70 - 0s - loss: 75074.8672 - accuracy: 0.6062 - val_loss: 25546.1816 - val_accuracy: 0.6462 - 191ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "70/70 - 0s - loss: 75096.6328 - accuracy: 0.6062 - val_loss: 25627.5117 - val_accuracy: 0.6462 - 186ms/epoch - 3ms/step\n",
            "[[6.36489766e-02 8.00000000e+00 8.00000000e+00 2.00000000e+01\n",
            "  1.00000000e+02 1.60000000e+01 1.60000000e+01]]\n",
            "l1 8\n",
            "epochs 100\n",
            "20\n",
            "0.06364897661796547\n",
            "Epoch 1/100\n",
            "72/72 - 1s - loss: 75757.1562 - accuracy: 0.4607 - val_loss: 27598.6387 - val_accuracy: 0.6531 - 700ms/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "72/72 - 0s - loss: 74172.3672 - accuracy: 0.5750 - val_loss: 27656.9844 - val_accuracy: 0.6633 - 190ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "72/72 - 0s - loss: 74116.2891 - accuracy: 0.5750 - val_loss: 27655.3887 - val_accuracy: 0.6633 - 211ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "72/72 - 0s - loss: 74247.7109 - accuracy: 0.5617 - val_loss: 27598.6016 - val_accuracy: 0.6633 - 190ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "72/72 - 0s - loss: 74128.2109 - accuracy: 0.5596 - val_loss: 27799.3359 - val_accuracy: 0.6633 - 193ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "72/72 - 0s - loss: 74222.7266 - accuracy: 0.5435 - val_loss: 27750.9648 - val_accuracy: 0.6633 - 208ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "72/72 - 0s - loss: 74116.6172 - accuracy: 0.5168 - val_loss: 27586.7930 - val_accuracy: 0.6633 - 199ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "72/72 - 0s - loss: 74075.8984 - accuracy: 0.5912 - val_loss: 27611.7988 - val_accuracy: 0.6633 - 204ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "72/72 - 0s - loss: 74057.3047 - accuracy: 0.5870 - val_loss: 27560.1895 - val_accuracy: 0.6633 - 199ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "72/72 - 0s - loss: 74046.4922 - accuracy: 0.5778 - val_loss: 27594.2168 - val_accuracy: 0.6633 - 197ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "72/72 - 0s - loss: 74101.7578 - accuracy: 0.5182 - val_loss: 27671.4219 - val_accuracy: 0.3878 - 204ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "72/72 - 0s - loss: 74108.5312 - accuracy: 0.5961 - val_loss: 27585.0078 - val_accuracy: 0.6633 - 197ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "72/72 - 0s - loss: 74022.5859 - accuracy: 0.5631 - val_loss: 27592.6387 - val_accuracy: 0.6633 - 195ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "72/72 - 0s - loss: 74013.0469 - accuracy: 0.5708 - val_loss: 27628.8477 - val_accuracy: 0.6633 - 184ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "72/72 - 0s - loss: 74043.9766 - accuracy: 0.5982 - val_loss: 27625.6758 - val_accuracy: 0.6633 - 203ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "72/72 - 0s - loss: 74043.2344 - accuracy: 0.5912 - val_loss: 27570.5156 - val_accuracy: 0.6633 - 187ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "72/72 - 0s - loss: 74031.9688 - accuracy: 0.5589 - val_loss: 27727.8223 - val_accuracy: 0.3163 - 197ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "72/72 - 0s - loss: 74000.5703 - accuracy: 0.5785 - val_loss: 27728.1445 - val_accuracy: 0.6633 - 221ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "72/72 - 0s - loss: 74015.0547 - accuracy: 0.5926 - val_loss: 27714.0781 - val_accuracy: 0.6633 - 192ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "72/72 - 0s - loss: 74034.4141 - accuracy: 0.5863 - val_loss: 27564.6992 - val_accuracy: 0.6633 - 203ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "72/72 - 0s - loss: 74017.6875 - accuracy: 0.5820 - val_loss: 27734.1387 - val_accuracy: 0.6633 - 193ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "72/72 - 0s - loss: 74108.0859 - accuracy: 0.5989 - val_loss: 27583.5762 - val_accuracy: 0.6633 - 187ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "72/72 - 0s - loss: 73969.0078 - accuracy: 0.6066 - val_loss: 27580.1660 - val_accuracy: 0.6633 - 188ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "72/72 - 0s - loss: 73957.3594 - accuracy: 0.5603 - val_loss: 27617.2910 - val_accuracy: 0.6633 - 190ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "72/72 - 0s - loss: 73983.6719 - accuracy: 0.5968 - val_loss: 27595.4336 - val_accuracy: 0.6633 - 201ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "72/72 - 0s - loss: 73940.1016 - accuracy: 0.5919 - val_loss: 27683.2812 - val_accuracy: 0.6429 - 199ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "72/72 - 0s - loss: 73954.2656 - accuracy: 0.5813 - val_loss: 28154.9082 - val_accuracy: 0.6633 - 189ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "72/72 - 0s - loss: 74588.5625 - accuracy: 0.4818 - val_loss: 27593.3320 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "72/72 - 0s - loss: 74059.4922 - accuracy: 0.5743 - val_loss: 27635.5234 - val_accuracy: 0.4898 - 187ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "72/72 - 0s - loss: 73993.6953 - accuracy: 0.5827 - val_loss: 27574.7852 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "72/72 - 0s - loss: 73978.0859 - accuracy: 0.5722 - val_loss: 27670.1094 - val_accuracy: 0.6633 - 189ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "72/72 - 0s - loss: 73962.4609 - accuracy: 0.5245 - val_loss: 27591.4473 - val_accuracy: 0.6633 - 198ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "72/72 - 0s - loss: 73994.3828 - accuracy: 0.5554 - val_loss: 27722.7852 - val_accuracy: 0.6633 - 195ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "72/72 - 0s - loss: 73921.4609 - accuracy: 0.5961 - val_loss: 27576.3652 - val_accuracy: 0.6633 - 190ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "72/72 - 0s - loss: 74002.8984 - accuracy: 0.5898 - val_loss: 27666.9336 - val_accuracy: 0.6327 - 197ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "72/72 - 0s - loss: 73937.3203 - accuracy: 0.6045 - val_loss: 27673.6230 - val_accuracy: 0.6633 - 192ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "72/72 - 0s - loss: 73914.7188 - accuracy: 0.5926 - val_loss: 27591.4590 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "72/72 - 0s - loss: 73945.4453 - accuracy: 0.6003 - val_loss: 27773.2012 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "72/72 - 0s - loss: 73922.1094 - accuracy: 0.6017 - val_loss: 27562.5723 - val_accuracy: 0.6633 - 184ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "72/72 - 0s - loss: 73940.8750 - accuracy: 0.5975 - val_loss: 27574.6328 - val_accuracy: 0.6633 - 197ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "72/72 - 0s - loss: 73895.7109 - accuracy: 0.6038 - val_loss: 27618.4277 - val_accuracy: 0.6633 - 192ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "72/72 - 0s - loss: 73900.7891 - accuracy: 0.5933 - val_loss: 27824.2246 - val_accuracy: 0.6633 - 203ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "72/72 - 0s - loss: 74245.7109 - accuracy: 0.5771 - val_loss: 27621.8691 - val_accuracy: 0.6020 - 208ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "72/72 - 0s - loss: 73922.7578 - accuracy: 0.5259 - val_loss: 27561.2852 - val_accuracy: 0.6633 - 196ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "72/72 - 0s - loss: 73890.4531 - accuracy: 0.5996 - val_loss: 27707.2559 - val_accuracy: 0.3163 - 199ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "72/72 - 0s - loss: 73909.9453 - accuracy: 0.5589 - val_loss: 27605.7305 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "72/72 - 0s - loss: 73886.0625 - accuracy: 0.5449 - val_loss: 27872.1113 - val_accuracy: 0.6633 - 191ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "72/72 - 0s - loss: 73871.2812 - accuracy: 0.6031 - val_loss: 27727.5469 - val_accuracy: 0.6633 - 201ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "72/72 - 0s - loss: 73898.4766 - accuracy: 0.5982 - val_loss: 27598.9004 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "72/72 - 0s - loss: 73897.6250 - accuracy: 0.5610 - val_loss: 27599.0605 - val_accuracy: 0.6633 - 192ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "72/72 - 0s - loss: 73905.5625 - accuracy: 0.5919 - val_loss: 27714.3242 - val_accuracy: 0.4898 - 193ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "72/72 - 0s - loss: 73889.6719 - accuracy: 0.5750 - val_loss: 27666.2656 - val_accuracy: 0.6633 - 194ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "72/72 - 0s - loss: 73917.3516 - accuracy: 0.5778 - val_loss: 27619.2012 - val_accuracy: 0.6633 - 202ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "72/72 - 0s - loss: 73883.2734 - accuracy: 0.6059 - val_loss: 27587.7559 - val_accuracy: 0.6633 - 208ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "72/72 - 0s - loss: 73934.6875 - accuracy: 0.5750 - val_loss: 27565.5137 - val_accuracy: 0.6633 - 192ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "72/72 - 0s - loss: 73854.1172 - accuracy: 0.5645 - val_loss: 27566.8574 - val_accuracy: 0.6633 - 207ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "72/72 - 0s - loss: 73844.4219 - accuracy: 0.5884 - val_loss: 27587.7090 - val_accuracy: 0.6633 - 189ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "72/72 - 0s - loss: 73860.1016 - accuracy: 0.6045 - val_loss: 27604.9434 - val_accuracy: 0.6633 - 209ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "72/72 - 0s - loss: 73908.1172 - accuracy: 0.5694 - val_loss: 27606.0781 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "72/72 - 0s - loss: 73838.4141 - accuracy: 0.5933 - val_loss: 27662.9141 - val_accuracy: 0.6327 - 197ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "72/72 - 0s - loss: 73882.8750 - accuracy: 0.5736 - val_loss: 27617.6426 - val_accuracy: 0.6633 - 199ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "72/72 - 0s - loss: 73854.5156 - accuracy: 0.5750 - val_loss: 27594.6973 - val_accuracy: 0.6633 - 196ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "72/72 - 0s - loss: 73868.6406 - accuracy: 0.5715 - val_loss: 27565.7031 - val_accuracy: 0.6633 - 197ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "72/72 - 0s - loss: 73894.6094 - accuracy: 0.5743 - val_loss: 27600.3672 - val_accuracy: 0.6633 - 191ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "72/72 - 0s - loss: 73939.9766 - accuracy: 0.5982 - val_loss: 27542.5645 - val_accuracy: 0.6633 - 207ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "72/72 - 0s - loss: 73820.2500 - accuracy: 0.6066 - val_loss: 27621.5059 - val_accuracy: 0.4184 - 204ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "72/72 - 0s - loss: 73870.3438 - accuracy: 0.5764 - val_loss: 27608.2480 - val_accuracy: 0.4694 - 210ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "72/72 - 0s - loss: 73896.2734 - accuracy: 0.5386 - val_loss: 27657.2090 - val_accuracy: 0.6633 - 207ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "72/72 - 0s - loss: 73824.4609 - accuracy: 0.6031 - val_loss: 27594.1582 - val_accuracy: 0.6633 - 193ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "72/72 - 0s - loss: 73891.0938 - accuracy: 0.5708 - val_loss: 27561.2852 - val_accuracy: 0.6633 - 192ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "72/72 - 0s - loss: 73856.8438 - accuracy: 0.5666 - val_loss: 27574.7188 - val_accuracy: 0.6633 - 199ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "72/72 - 0s - loss: 73856.6094 - accuracy: 0.5954 - val_loss: 27564.9512 - val_accuracy: 0.6633 - 193ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "72/72 - 0s - loss: 73877.8047 - accuracy: 0.5652 - val_loss: 27574.4648 - val_accuracy: 0.6633 - 213ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "72/72 - 0s - loss: 73847.1094 - accuracy: 0.6045 - val_loss: 27588.1250 - val_accuracy: 0.6633 - 199ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "72/72 - 0s - loss: 73871.9688 - accuracy: 0.6017 - val_loss: 27587.2598 - val_accuracy: 0.6633 - 198ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "72/72 - 0s - loss: 73806.7188 - accuracy: 0.6010 - val_loss: 27675.6426 - val_accuracy: 0.2857 - 209ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "72/72 - 0s - loss: 73853.2812 - accuracy: 0.5561 - val_loss: 27561.9902 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "72/72 - 0s - loss: 73831.7734 - accuracy: 0.5982 - val_loss: 27618.6445 - val_accuracy: 0.6633 - 215ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "72/72 - 0s - loss: 73828.1328 - accuracy: 0.5919 - val_loss: 27606.2891 - val_accuracy: 0.6633 - 193ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "72/72 - 0s - loss: 73825.4531 - accuracy: 0.6059 - val_loss: 27558.6172 - val_accuracy: 0.6633 - 210ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "72/72 - 0s - loss: 73858.4375 - accuracy: 0.5771 - val_loss: 27616.9766 - val_accuracy: 0.6633 - 188ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "72/72 - 0s - loss: 73852.6484 - accuracy: 0.5561 - val_loss: 27554.4180 - val_accuracy: 0.6633 - 200ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "72/72 - 0s - loss: 73837.4375 - accuracy: 0.5961 - val_loss: 27564.4141 - val_accuracy: 0.6633 - 226ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "72/72 - 0s - loss: 73860.7656 - accuracy: 0.5933 - val_loss: 27574.3359 - val_accuracy: 0.6633 - 202ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "72/72 - 0s - loss: 73822.8516 - accuracy: 0.6059 - val_loss: 27621.5059 - val_accuracy: 0.6633 - 191ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "72/72 - 0s - loss: 73815.7734 - accuracy: 0.5813 - val_loss: 27557.1914 - val_accuracy: 0.6633 - 199ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "72/72 - 0s - loss: 73809.7031 - accuracy: 0.5975 - val_loss: 27579.0352 - val_accuracy: 0.6633 - 205ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "72/72 - 0s - loss: 73841.6719 - accuracy: 0.5687 - val_loss: 27560.8691 - val_accuracy: 0.6633 - 217ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "72/72 - 0s - loss: 73858.8750 - accuracy: 0.5989 - val_loss: 27645.6426 - val_accuracy: 0.6633 - 196ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "72/72 - 0s - loss: 73865.4766 - accuracy: 0.5757 - val_loss: 27586.1328 - val_accuracy: 0.6633 - 193ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "72/72 - 0s - loss: 73876.5547 - accuracy: 0.5954 - val_loss: 27628.4082 - val_accuracy: 0.3265 - 206ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "72/72 - 0s - loss: 73870.5938 - accuracy: 0.5820 - val_loss: 27655.9609 - val_accuracy: 0.6633 - 193ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "72/72 - 0s - loss: 73865.8438 - accuracy: 0.5905 - val_loss: 27623.8027 - val_accuracy: 0.6633 - 215ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "72/72 - 0s - loss: 73853.7734 - accuracy: 0.5842 - val_loss: 27569.4531 - val_accuracy: 0.6633 - 207ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "72/72 - 0s - loss: 73794.5547 - accuracy: 0.6059 - val_loss: 27570.3027 - val_accuracy: 0.6633 - 209ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "72/72 - 0s - loss: 73914.1875 - accuracy: 0.6031 - val_loss: 27677.3359 - val_accuracy: 0.6633 - 203ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "72/72 - 0s - loss: 73838.2812 - accuracy: 0.5764 - val_loss: 27538.8281 - val_accuracy: 0.6633 - 207ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "72/72 - 0s - loss: 73816.1484 - accuracy: 0.5849 - val_loss: 27547.0723 - val_accuracy: 0.6633 - 199ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "72/72 - 0s - loss: 73803.3906 - accuracy: 0.6059 - val_loss: 27538.2891 - val_accuracy: 0.6633 - 201ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "72/72 - 0s - loss: 73837.9219 - accuracy: 0.6052 - val_loss: 27584.2520 - val_accuracy: 0.6633 - 197ms/epoch - 3ms/step\n",
            "[[  0.   8. 128.  40. 250.   8.  64.]]\n",
            "l1 8\n",
            "epochs 250\n",
            "40\n",
            "0.0\n",
            "Epoch 1/250\n",
            "39/39 - 0s - loss: 72282.8984 - accuracy: 0.5171 - 478ms/epoch - 12ms/step\n",
            "Epoch 2/250\n",
            "39/39 - 0s - loss: 71213.0625 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 3/250\n",
            "39/39 - 0s - loss: 71212.2969 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 4/250\n",
            "39/39 - 0s - loss: 71210.1562 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 5/250\n",
            "39/39 - 0s - loss: 71203.5859 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 6/250\n",
            "39/39 - 0s - loss: 71221.2422 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 7/250\n",
            "39/39 - 0s - loss: 71208.4062 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 8/250\n",
            "39/39 - 0s - loss: 71194.7344 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 9/250\n",
            "39/39 - 0s - loss: 71202.5078 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 10/250\n",
            "39/39 - 0s - loss: 71185.6562 - accuracy: 0.6096 - 102ms/epoch - 3ms/step\n",
            "Epoch 11/250\n",
            "39/39 - 0s - loss: 71186.0859 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 12/250\n",
            "39/39 - 0s - loss: 71159.7656 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 13/250\n",
            "39/39 - 0s - loss: 71197.7344 - accuracy: 0.6096 - 107ms/epoch - 3ms/step\n",
            "Epoch 14/250\n",
            "39/39 - 0s - loss: 71161.3203 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 15/250\n",
            "39/39 - 0s - loss: 71163.9375 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 16/250\n",
            "39/39 - 0s - loss: 71136.2891 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 17/250\n",
            "39/39 - 0s - loss: 71130.7891 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 18/250\n",
            "39/39 - 0s - loss: 71081.7969 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 19/250\n",
            "39/39 - 0s - loss: 71084.4375 - accuracy: 0.6102 - 105ms/epoch - 3ms/step\n",
            "Epoch 20/250\n",
            "39/39 - 0s - loss: 71065.6953 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 21/250\n",
            "39/39 - 0s - loss: 71062.2266 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 22/250\n",
            "39/39 - 0s - loss: 71051.4219 - accuracy: 0.5951 - 90ms/epoch - 2ms/step\n",
            "Epoch 23/250\n",
            "39/39 - 0s - loss: 71041.0156 - accuracy: 0.6089 - 106ms/epoch - 3ms/step\n",
            "Epoch 24/250\n",
            "39/39 - 0s - loss: 71367.4297 - accuracy: 0.5827 - 95ms/epoch - 2ms/step\n",
            "Epoch 25/250\n",
            "39/39 - 0s - loss: 71200.8984 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 26/250\n",
            "39/39 - 0s - loss: 71089.2734 - accuracy: 0.6096 - 102ms/epoch - 3ms/step\n",
            "Epoch 27/250\n",
            "39/39 - 0s - loss: 71061.5938 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 28/250\n",
            "39/39 - 0s - loss: 71011.5156 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 29/250\n",
            "39/39 - 0s - loss: 71003.0156 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 30/250\n",
            "39/39 - 0s - loss: 71054.9844 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 31/250\n",
            "39/39 - 0s - loss: 70978.1719 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 32/250\n",
            "39/39 - 0s - loss: 71093.3906 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 33/250\n",
            "39/39 - 0s - loss: 71186.3438 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 34/250\n",
            "39/39 - 0s - loss: 70963.3203 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 35/250\n",
            "39/39 - 0s - loss: 71031.1328 - accuracy: 0.6096 - 101ms/epoch - 3ms/step\n",
            "Epoch 36/250\n",
            "39/39 - 0s - loss: 70995.9453 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 37/250\n",
            "39/39 - 0s - loss: 71077.7031 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 38/250\n",
            "39/39 - 0s - loss: 71026.6094 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 39/250\n",
            "39/39 - 0s - loss: 70950.8906 - accuracy: 0.6096 - 99ms/epoch - 3ms/step\n",
            "Epoch 40/250\n",
            "39/39 - 0s - loss: 70971.3047 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 41/250\n",
            "39/39 - 0s - loss: 70962.3906 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 42/250\n",
            "39/39 - 0s - loss: 70946.9766 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 43/250\n",
            "39/39 - 0s - loss: 70940.7266 - accuracy: 0.6096 - 106ms/epoch - 3ms/step\n",
            "Epoch 44/250\n",
            "39/39 - 0s - loss: 70926.9922 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 45/250\n",
            "39/39 - 0s - loss: 70956.8203 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 46/250\n",
            "39/39 - 0s - loss: 70969.3203 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 47/250\n",
            "39/39 - 0s - loss: 71070.9844 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 48/250\n",
            "39/39 - 0s - loss: 71054.7188 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 49/250\n",
            "39/39 - 0s - loss: 71226.4375 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 50/250\n",
            "39/39 - 0s - loss: 71253.3516 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 51/250\n",
            "39/39 - 0s - loss: 71046.3281 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 52/250\n",
            "39/39 - 0s - loss: 70930.9062 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 53/250\n",
            "39/39 - 0s - loss: 71069.6172 - accuracy: 0.6096 - 101ms/epoch - 3ms/step\n",
            "Epoch 54/250\n",
            "39/39 - 0s - loss: 70944.5312 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 55/250\n",
            "39/39 - 0s - loss: 71117.4297 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 56/250\n",
            "39/39 - 0s - loss: 71121.4453 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 57/250\n",
            "39/39 - 0s - loss: 70947.9141 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 58/250\n",
            "39/39 - 0s - loss: 70935.2812 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 59/250\n",
            "39/39 - 0s - loss: 70962.9141 - accuracy: 0.6096 - 105ms/epoch - 3ms/step\n",
            "Epoch 60/250\n",
            "39/39 - 0s - loss: 70966.5547 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 61/250\n",
            "39/39 - 0s - loss: 70992.2891 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 62/250\n",
            "39/39 - 0s - loss: 70942.5547 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 63/250\n",
            "39/39 - 0s - loss: 70976.9062 - accuracy: 0.6096 - 103ms/epoch - 3ms/step\n",
            "Epoch 64/250\n",
            "39/39 - 0s - loss: 70953.4297 - accuracy: 0.6096 - 108ms/epoch - 3ms/step\n",
            "Epoch 65/250\n",
            "39/39 - 0s - loss: 70930.5156 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 66/250\n",
            "39/39 - 0s - loss: 70963.8125 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 67/250\n",
            "39/39 - 0s - loss: 70935.9141 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 68/250\n",
            "39/39 - 0s - loss: 71175.5156 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 69/250\n",
            "39/39 - 0s - loss: 71142.4297 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 70/250\n",
            "39/39 - 0s - loss: 71041.5547 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 71/250\n",
            "39/39 - 0s - loss: 70934.7734 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 72/250\n",
            "39/39 - 0s - loss: 70941.9922 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 73/250\n",
            "39/39 - 0s - loss: 71091.7812 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 74/250\n",
            "39/39 - 0s - loss: 70971.6562 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 75/250\n",
            "39/39 - 0s - loss: 70933.8047 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 76/250\n",
            "39/39 - 0s - loss: 70932.4062 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 77/250\n",
            "39/39 - 0s - loss: 70991.7422 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 78/250\n",
            "39/39 - 0s - loss: 70967.2812 - accuracy: 0.6096 - 88ms/epoch - 2ms/step\n",
            "Epoch 79/250\n",
            "39/39 - 0s - loss: 70983.4766 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 80/250\n",
            "39/39 - 0s - loss: 70979.8672 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 81/250\n",
            "39/39 - 0s - loss: 71007.4609 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 82/250\n",
            "39/39 - 0s - loss: 70950.6250 - accuracy: 0.6096 - 103ms/epoch - 3ms/step\n",
            "Epoch 83/250\n",
            "39/39 - 0s - loss: 70938.7734 - accuracy: 0.6096 - 99ms/epoch - 3ms/step\n",
            "Epoch 84/250\n",
            "39/39 - 0s - loss: 70930.5156 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 85/250\n",
            "39/39 - 0s - loss: 71362.3828 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 86/250\n",
            "39/39 - 0s - loss: 71377.4297 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 87/250\n",
            "39/39 - 0s - loss: 71356.5469 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 88/250\n",
            "39/39 - 0s - loss: 71339.7812 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 89/250\n",
            "39/39 - 0s - loss: 71311.8750 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 90/250\n",
            "39/39 - 0s - loss: 71297.8828 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 91/250\n",
            "39/39 - 0s - loss: 71278.1406 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 92/250\n",
            "39/39 - 0s - loss: 71252.5312 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 93/250\n",
            "39/39 - 0s - loss: 71191.0312 - accuracy: 0.6096 - 99ms/epoch - 3ms/step\n",
            "Epoch 94/250\n",
            "39/39 - 0s - loss: 71129.1484 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 95/250\n",
            "39/39 - 0s - loss: 71177.5625 - accuracy: 0.6096 - 87ms/epoch - 2ms/step\n",
            "Epoch 96/250\n",
            "39/39 - 0s - loss: 71314.6484 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 97/250\n",
            "39/39 - 0s - loss: 71304.3906 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 98/250\n",
            "39/39 - 0s - loss: 71295.6094 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 99/250\n",
            "39/39 - 0s - loss: 71287.9141 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 100/250\n",
            "39/39 - 0s - loss: 71276.1250 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 101/250\n",
            "39/39 - 0s - loss: 71263.8047 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 102/250\n",
            "39/39 - 0s - loss: 71258.2500 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 103/250\n",
            "39/39 - 0s - loss: 71248.3047 - accuracy: 0.6096 - 99ms/epoch - 3ms/step\n",
            "Epoch 104/250\n",
            "39/39 - 0s - loss: 71243.9219 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 105/250\n",
            "39/39 - 0s - loss: 71234.4531 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 106/250\n",
            "39/39 - 0s - loss: 71225.6719 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 107/250\n",
            "39/39 - 0s - loss: 71219.4766 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 108/250\n",
            "39/39 - 0s - loss: 71212.2188 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 109/250\n",
            "39/39 - 0s - loss: 71207.0469 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 110/250\n",
            "39/39 - 0s - loss: 71195.6328 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 111/250\n",
            "39/39 - 0s - loss: 71187.6094 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 112/250\n",
            "39/39 - 0s - loss: 71177.8281 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 113/250\n",
            "39/39 - 0s - loss: 71173.8594 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 114/250\n",
            "39/39 - 0s - loss: 71162.0078 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 115/250\n",
            "39/39 - 0s - loss: 71171.9688 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 116/250\n",
            "39/39 - 0s - loss: 71150.7891 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 117/250\n",
            "39/39 - 0s - loss: 71150.8203 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 118/250\n",
            "39/39 - 0s - loss: 71133.1094 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 119/250\n",
            "39/39 - 0s - loss: 71127.2812 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 120/250\n",
            "39/39 - 0s - loss: 71130.8906 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 121/250\n",
            "39/39 - 0s - loss: 71123.2344 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 122/250\n",
            "39/39 - 0s - loss: 71117.4297 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 123/250\n",
            "39/39 - 0s - loss: 71115.0312 - accuracy: 0.6096 - 105ms/epoch - 3ms/step\n",
            "Epoch 124/250\n",
            "39/39 - 0s - loss: 71109.3047 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 125/250\n",
            "39/39 - 0s - loss: 71118.0703 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 126/250\n",
            "39/39 - 0s - loss: 71095.1094 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 127/250\n",
            "39/39 - 0s - loss: 71112.1172 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 128/250\n",
            "39/39 - 0s - loss: 71086.7422 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 129/250\n",
            "39/39 - 0s - loss: 71085.5078 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 130/250\n",
            "39/39 - 0s - loss: 71078.6094 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 131/250\n",
            "39/39 - 0s - loss: 71085.7812 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 132/250\n",
            "39/39 - 0s - loss: 71083.0625 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 133/250\n",
            "39/39 - 0s - loss: 71079.3203 - accuracy: 0.6096 - 102ms/epoch - 3ms/step\n",
            "Epoch 134/250\n",
            "39/39 - 0s - loss: 71076.3125 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 135/250\n",
            "39/39 - 0s - loss: 71076.5859 - accuracy: 0.6096 - 103ms/epoch - 3ms/step\n",
            "Epoch 136/250\n",
            "39/39 - 0s - loss: 71065.6719 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 137/250\n",
            "39/39 - 0s - loss: 71075.1406 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 138/250\n",
            "39/39 - 0s - loss: 71075.5312 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 139/250\n",
            "39/39 - 0s - loss: 71076.6172 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 140/250\n",
            "39/39 - 0s - loss: 71073.5078 - accuracy: 0.6096 - 101ms/epoch - 3ms/step\n",
            "Epoch 141/250\n",
            "39/39 - 0s - loss: 71071.9141 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 142/250\n",
            "39/39 - 0s - loss: 71062.5234 - accuracy: 0.6096 - 104ms/epoch - 3ms/step\n",
            "Epoch 143/250\n",
            "39/39 - 0s - loss: 71068.1797 - accuracy: 0.6096 - 103ms/epoch - 3ms/step\n",
            "Epoch 144/250\n",
            "39/39 - 0s - loss: 71061.2969 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 145/250\n",
            "39/39 - 0s - loss: 71062.7422 - accuracy: 0.6096 - 99ms/epoch - 3ms/step\n",
            "Epoch 146/250\n",
            "39/39 - 0s - loss: 71051.4766 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 147/250\n",
            "39/39 - 0s - loss: 71059.4453 - accuracy: 0.6096 - 90ms/epoch - 2ms/step\n",
            "Epoch 148/250\n",
            "39/39 - 0s - loss: 71052.7891 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 149/250\n",
            "39/39 - 0s - loss: 71068.4062 - accuracy: 0.6096 - 103ms/epoch - 3ms/step\n",
            "Epoch 150/250\n",
            "39/39 - 0s - loss: 71056.3594 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 151/250\n",
            "39/39 - 0s - loss: 71064.7578 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 152/250\n",
            "39/39 - 0s - loss: 71057.1094 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 153/250\n",
            "39/39 - 0s - loss: 71055.8984 - accuracy: 0.6096 - 111ms/epoch - 3ms/step\n",
            "Epoch 154/250\n",
            "39/39 - 0s - loss: 71040.9219 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 155/250\n",
            "39/39 - 0s - loss: 71038.8828 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 156/250\n",
            "39/39 - 0s - loss: 71042.5234 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 157/250\n",
            "39/39 - 0s - loss: 71070.7734 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 158/250\n",
            "39/39 - 0s - loss: 71031.4766 - accuracy: 0.6096 - 99ms/epoch - 3ms/step\n",
            "Epoch 159/250\n",
            "39/39 - 0s - loss: 71036.7422 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 160/250\n",
            "39/39 - 0s - loss: 71030.4609 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 161/250\n",
            "39/39 - 0s - loss: 71032.5547 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 162/250\n",
            "39/39 - 0s - loss: 71032.9688 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 163/250\n",
            "39/39 - 0s - loss: 71059.0547 - accuracy: 0.6096 - 102ms/epoch - 3ms/step\n",
            "Epoch 164/250\n",
            "39/39 - 0s - loss: 71056.6406 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 165/250\n",
            "39/39 - 0s - loss: 71065.7578 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 166/250\n",
            "39/39 - 0s - loss: 71041.7188 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 167/250\n",
            "39/39 - 0s - loss: 71050.0625 - accuracy: 0.6096 - 101ms/epoch - 3ms/step\n",
            "Epoch 168/250\n",
            "39/39 - 0s - loss: 71066.5234 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 169/250\n",
            "39/39 - 0s - loss: 71030.7109 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 170/250\n",
            "39/39 - 0s - loss: 71039.9062 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 171/250\n",
            "39/39 - 0s - loss: 71039.0469 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 172/250\n",
            "39/39 - 0s - loss: 71037.6719 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 173/250\n",
            "39/39 - 0s - loss: 71008.9297 - accuracy: 0.6096 - 102ms/epoch - 3ms/step\n",
            "Epoch 174/250\n",
            "39/39 - 0s - loss: 71013.3516 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 175/250\n",
            "39/39 - 0s - loss: 71010.8594 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 176/250\n",
            "39/39 - 0s - loss: 71028.2188 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 177/250\n",
            "39/39 - 0s - loss: 71060.4531 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 178/250\n",
            "39/39 - 0s - loss: 71072.1094 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 179/250\n",
            "39/39 - 0s - loss: 71056.7891 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 180/250\n",
            "39/39 - 0s - loss: 71058.6016 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 181/250\n",
            "39/39 - 0s - loss: 71046.8438 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 182/250\n",
            "39/39 - 0s - loss: 71047.1953 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 183/250\n",
            "39/39 - 0s - loss: 71047.0859 - accuracy: 0.6096 - 105ms/epoch - 3ms/step\n",
            "Epoch 184/250\n",
            "39/39 - 0s - loss: 71041.0703 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 185/250\n",
            "39/39 - 0s - loss: 71050.5000 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 186/250\n",
            "39/39 - 0s - loss: 71038.4141 - accuracy: 0.6096 - 87ms/epoch - 2ms/step\n",
            "Epoch 187/250\n",
            "39/39 - 0s - loss: 71032.2344 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 188/250\n",
            "39/39 - 0s - loss: 71045.3516 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 189/250\n",
            "39/39 - 0s - loss: 71033.6641 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 190/250\n",
            "39/39 - 0s - loss: 71039.6797 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 191/250\n",
            "39/39 - 0s - loss: 71052.5703 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 192/250\n",
            "39/39 - 0s - loss: 71028.7500 - accuracy: 0.6096 - 101ms/epoch - 3ms/step\n",
            "Epoch 193/250\n",
            "39/39 - 0s - loss: 71025.8672 - accuracy: 0.6096 - 107ms/epoch - 3ms/step\n",
            "Epoch 194/250\n",
            "39/39 - 0s - loss: 71052.8984 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 195/250\n",
            "39/39 - 0s - loss: 71034.0547 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 196/250\n",
            "39/39 - 0s - loss: 71041.2188 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 197/250\n",
            "39/39 - 0s - loss: 71018.7891 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 198/250\n",
            "39/39 - 0s - loss: 71029.5938 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 199/250\n",
            "39/39 - 0s - loss: 71029.2891 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 200/250\n",
            "39/39 - 0s - loss: 71033.1953 - accuracy: 0.6096 - 98ms/epoch - 3ms/step\n",
            "Epoch 201/250\n",
            "39/39 - 0s - loss: 71023.2266 - accuracy: 0.6096 - 101ms/epoch - 3ms/step\n",
            "Epoch 202/250\n",
            "39/39 - 0s - loss: 71033.8125 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 203/250\n",
            "39/39 - 0s - loss: 71042.4844 - accuracy: 0.6096 - 103ms/epoch - 3ms/step\n",
            "Epoch 204/250\n",
            "39/39 - 0s - loss: 71016.1172 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 205/250\n",
            "39/39 - 0s - loss: 71076.8750 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 206/250\n",
            "39/39 - 0s - loss: 71041.8984 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 207/250\n",
            "39/39 - 0s - loss: 71080.2812 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 208/250\n",
            "39/39 - 0s - loss: 71110.3828 - accuracy: 0.6096 - 88ms/epoch - 2ms/step\n",
            "Epoch 209/250\n",
            "39/39 - 0s - loss: 71085.8359 - accuracy: 0.6096 - 104ms/epoch - 3ms/step\n",
            "Epoch 210/250\n",
            "39/39 - 0s - loss: 71071.6328 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 211/250\n",
            "39/39 - 0s - loss: 71069.9141 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 212/250\n",
            "39/39 - 0s - loss: 71068.7266 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 213/250\n",
            "39/39 - 0s - loss: 71045.1562 - accuracy: 0.6096 - 101ms/epoch - 3ms/step\n",
            "Epoch 214/250\n",
            "39/39 - 0s - loss: 71049.2891 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 215/250\n",
            "39/39 - 0s - loss: 71032.7422 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 216/250\n",
            "39/39 - 0s - loss: 71035.3516 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 217/250\n",
            "39/39 - 0s - loss: 71038.7891 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 218/250\n",
            "39/39 - 0s - loss: 71026.8047 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 219/250\n",
            "39/39 - 0s - loss: 71029.5625 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 220/250\n",
            "39/39 - 0s - loss: 71036.0938 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 221/250\n",
            "39/39 - 0s - loss: 71037.6875 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 222/250\n",
            "39/39 - 0s - loss: 71047.1875 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 223/250\n",
            "39/39 - 0s - loss: 71027.5625 - accuracy: 0.6096 - 107ms/epoch - 3ms/step\n",
            "Epoch 224/250\n",
            "39/39 - 0s - loss: 71038.0312 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 225/250\n",
            "39/39 - 0s - loss: 71029.2812 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 226/250\n",
            "39/39 - 0s - loss: 71029.2656 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 227/250\n",
            "39/39 - 0s - loss: 71039.2812 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 228/250\n",
            "39/39 - 0s - loss: 71029.6875 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 229/250\n",
            "39/39 - 0s - loss: 71026.7500 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 230/250\n",
            "39/39 - 0s - loss: 71023.1562 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 231/250\n",
            "39/39 - 0s - loss: 71038.4844 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 232/250\n",
            "39/39 - 0s - loss: 71033.6875 - accuracy: 0.6096 - 94ms/epoch - 2ms/step\n",
            "Epoch 233/250\n",
            "39/39 - 0s - loss: 71030.8438 - accuracy: 0.6096 - 100ms/epoch - 3ms/step\n",
            "Epoch 234/250\n",
            "39/39 - 0s - loss: 71052.4766 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 235/250\n",
            "39/39 - 0s - loss: 71032.2656 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 236/250\n",
            "39/39 - 0s - loss: 71035.9453 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 237/250\n",
            "39/39 - 0s - loss: 71028.0391 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 238/250\n",
            "39/39 - 0s - loss: 71025.7812 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 239/250\n",
            "39/39 - 0s - loss: 71029.4766 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 240/250\n",
            "39/39 - 0s - loss: 71029.4453 - accuracy: 0.6096 - 89ms/epoch - 2ms/step\n",
            "Epoch 241/250\n",
            "39/39 - 0s - loss: 71019.9375 - accuracy: 0.6096 - 91ms/epoch - 2ms/step\n",
            "Epoch 242/250\n",
            "39/39 - 0s - loss: 71027.5078 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "Epoch 243/250\n",
            "39/39 - 0s - loss: 71021.8438 - accuracy: 0.6096 - 112ms/epoch - 3ms/step\n",
            "Epoch 244/250\n",
            "39/39 - 0s - loss: 71014.6016 - accuracy: 0.6096 - 99ms/epoch - 3ms/step\n",
            "Epoch 245/250\n",
            "39/39 - 0s - loss: 71066.1094 - accuracy: 0.6096 - 93ms/epoch - 2ms/step\n",
            "Epoch 246/250\n",
            "39/39 - 0s - loss: 71046.0547 - accuracy: 0.6096 - 92ms/epoch - 2ms/step\n",
            "Epoch 247/250\n",
            "39/39 - 0s - loss: 71026.2031 - accuracy: 0.6096 - 96ms/epoch - 2ms/step\n",
            "Epoch 248/250\n",
            "39/39 - 0s - loss: 71022.5469 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 249/250\n",
            "39/39 - 0s - loss: 71032.3672 - accuracy: 0.6096 - 95ms/epoch - 2ms/step\n",
            "Epoch 250/250\n",
            "39/39 - 0s - loss: 71026.1172 - accuracy: 0.6096 - 97ms/epoch - 2ms/step\n",
            "[[  0.3   8.  128.   60.  250.    8.  128. ]]\n",
            "l1 8\n",
            "epochs 250\n",
            "60\n",
            "0.3\n",
            "Epoch 1/250\n",
            "18/18 - 1s - loss: 93063.4531 - accuracy: 0.3621 - val_loss: 24438.3926 - val_accuracy: 0.6179 - 590ms/epoch - 33ms/step\n",
            "Epoch 2/250\n",
            "18/18 - 0s - loss: 91820.6953 - accuracy: 0.6023 - val_loss: 24436.8008 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 3/250\n",
            "18/18 - 0s - loss: 91815.5625 - accuracy: 0.6023 - val_loss: 24435.9922 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 4/250\n",
            "18/18 - 0s - loss: 91812.8984 - accuracy: 0.6023 - val_loss: 24435.1035 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 5/250\n",
            "18/18 - 0s - loss: 91810.0000 - accuracy: 0.6023 - val_loss: 24434.1270 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 6/250\n",
            "18/18 - 0s - loss: 91805.7422 - accuracy: 0.6023 - val_loss: 24432.9746 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 7/250\n",
            "18/18 - 0s - loss: 91712.9531 - accuracy: 0.6023 - val_loss: 24060.4961 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 8/250\n",
            "18/18 - 0s - loss: 91468.3984 - accuracy: 0.6041 - val_loss: 24068.8477 - val_accuracy: 0.6201 - 96ms/epoch - 5ms/step\n",
            "Epoch 9/250\n",
            "18/18 - 0s - loss: 91511.8594 - accuracy: 0.6041 - val_loss: 24174.9492 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 10/250\n",
            "18/18 - 0s - loss: 91511.5391 - accuracy: 0.6041 - val_loss: 24009.6895 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 11/250\n",
            "18/18 - 0s - loss: 91456.7266 - accuracy: 0.6041 - val_loss: 23986.8730 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 12/250\n",
            "18/18 - 0s - loss: 91419.3281 - accuracy: 0.6041 - val_loss: 23984.3770 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 13/250\n",
            "18/18 - 0s - loss: 91418.7422 - accuracy: 0.6041 - val_loss: 23995.6074 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 14/250\n",
            "18/18 - 0s - loss: 91395.4922 - accuracy: 0.6041 - val_loss: 23960.9434 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 15/250\n",
            "18/18 - 0s - loss: 91401.6953 - accuracy: 0.6041 - val_loss: 23971.1738 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 16/250\n",
            "18/18 - 0s - loss: 91355.7422 - accuracy: 0.6041 - val_loss: 24086.4492 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 17/250\n",
            "18/18 - 0s - loss: 91500.1797 - accuracy: 0.6051 - val_loss: 23933.6719 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 18/250\n",
            "18/18 - 0s - loss: 91362.8672 - accuracy: 0.6051 - val_loss: 23925.6484 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 19/250\n",
            "18/18 - 0s - loss: 91332.6953 - accuracy: 0.6051 - val_loss: 23915.0859 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 20/250\n",
            "18/18 - 0s - loss: 91340.8594 - accuracy: 0.6051 - val_loss: 23896.7930 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 21/250\n",
            "18/18 - 0s - loss: 91359.6953 - accuracy: 0.6051 - val_loss: 23953.0879 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 22/250\n",
            "18/18 - 0s - loss: 91303.4453 - accuracy: 0.6051 - val_loss: 24150.1777 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 23/250\n",
            "18/18 - 0s - loss: 91297.2031 - accuracy: 0.6051 - val_loss: 23945.0938 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 24/250\n",
            "18/18 - 0s - loss: 91271.1562 - accuracy: 0.6051 - val_loss: 23846.7305 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 25/250\n",
            "18/18 - 0s - loss: 91233.1562 - accuracy: 0.6051 - val_loss: 23899.6973 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 26/250\n",
            "18/18 - 0s - loss: 91235.6719 - accuracy: 0.6051 - val_loss: 23818.7812 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 27/250\n",
            "18/18 - 0s - loss: 91220.5469 - accuracy: 0.6060 - val_loss: 23902.0039 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 28/250\n",
            "18/18 - 0s - loss: 91174.9922 - accuracy: 0.6051 - val_loss: 23764.0078 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 29/250\n",
            "18/18 - 0s - loss: 91228.6172 - accuracy: 0.6051 - val_loss: 23789.3516 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 30/250\n",
            "18/18 - 0s - loss: 91219.6328 - accuracy: 0.6051 - val_loss: 23777.6504 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 31/250\n",
            "18/18 - 0s - loss: 91188.5547 - accuracy: 0.6051 - val_loss: 23793.5195 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 32/250\n",
            "18/18 - 0s - loss: 91158.8203 - accuracy: 0.6051 - val_loss: 23866.5742 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 33/250\n",
            "18/18 - 0s - loss: 91166.4531 - accuracy: 0.6051 - val_loss: 23821.6680 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 34/250\n",
            "18/18 - 0s - loss: 91187.7188 - accuracy: 0.6051 - val_loss: 23809.6367 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 35/250\n",
            "18/18 - 0s - loss: 91082.4375 - accuracy: 0.6051 - val_loss: 24066.9004 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 36/250\n",
            "18/18 - 0s - loss: 91173.2656 - accuracy: 0.6051 - val_loss: 24013.9297 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 37/250\n",
            "18/18 - 0s - loss: 91105.4688 - accuracy: 0.6051 - val_loss: 23847.4219 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 38/250\n",
            "18/18 - 0s - loss: 91160.0938 - accuracy: 0.6051 - val_loss: 24171.1660 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 39/250\n",
            "18/18 - 0s - loss: 91166.9766 - accuracy: 0.6051 - val_loss: 23823.9043 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 40/250\n",
            "18/18 - 0s - loss: 91109.3984 - accuracy: 0.6051 - val_loss: 23816.9980 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 41/250\n",
            "18/18 - 0s - loss: 91101.6484 - accuracy: 0.6051 - val_loss: 23800.9707 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 42/250\n",
            "18/18 - 0s - loss: 91182.3516 - accuracy: 0.6051 - val_loss: 23818.9648 - val_accuracy: 0.6201 - 126ms/epoch - 7ms/step\n",
            "Epoch 43/250\n",
            "18/18 - 0s - loss: 91127.9141 - accuracy: 0.6051 - val_loss: 23817.8438 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 44/250\n",
            "18/18 - 0s - loss: 91130.7344 - accuracy: 0.6051 - val_loss: 23845.9336 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 45/250\n",
            "18/18 - 0s - loss: 91181.5078 - accuracy: 0.6051 - val_loss: 23832.3086 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 46/250\n",
            "18/18 - 0s - loss: 91092.5078 - accuracy: 0.6051 - val_loss: 23842.7578 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 47/250\n",
            "18/18 - 0s - loss: 91094.2266 - accuracy: 0.6051 - val_loss: 23853.2754 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 48/250\n",
            "18/18 - 0s - loss: 91152.0000 - accuracy: 0.6051 - val_loss: 23839.4844 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 49/250\n",
            "18/18 - 0s - loss: 91143.7891 - accuracy: 0.6051 - val_loss: 23894.1543 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 50/250\n",
            "18/18 - 0s - loss: 91129.3750 - accuracy: 0.6051 - val_loss: 23841.2734 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 51/250\n",
            "18/18 - 0s - loss: 91117.1484 - accuracy: 0.6051 - val_loss: 23849.3301 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 52/250\n",
            "18/18 - 0s - loss: 91128.8281 - accuracy: 0.6051 - val_loss: 23870.8945 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 53/250\n",
            "18/18 - 0s - loss: 91094.8750 - accuracy: 0.6051 - val_loss: 23839.4785 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 54/250\n",
            "18/18 - 0s - loss: 91097.3203 - accuracy: 0.6051 - val_loss: 23848.7812 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 55/250\n",
            "18/18 - 0s - loss: 91090.8750 - accuracy: 0.6051 - val_loss: 23865.3730 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 56/250\n",
            "18/18 - 0s - loss: 91132.3281 - accuracy: 0.6051 - val_loss: 23830.1465 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 57/250\n",
            "18/18 - 0s - loss: 91100.3672 - accuracy: 0.6051 - val_loss: 23903.6777 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 58/250\n",
            "18/18 - 0s - loss: 91099.8047 - accuracy: 0.6051 - val_loss: 23899.6465 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 59/250\n",
            "18/18 - 0s - loss: 91083.7891 - accuracy: 0.6051 - val_loss: 23831.8145 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 60/250\n",
            "18/18 - 0s - loss: 91114.6016 - accuracy: 0.6051 - val_loss: 23856.6504 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 61/250\n",
            "18/18 - 0s - loss: 91086.1797 - accuracy: 0.6051 - val_loss: 23852.2578 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 62/250\n",
            "18/18 - 0s - loss: 91103.6328 - accuracy: 0.6051 - val_loss: 23866.8828 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 63/250\n",
            "18/18 - 0s - loss: 91089.4062 - accuracy: 0.6051 - val_loss: 23825.8359 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 64/250\n",
            "18/18 - 0s - loss: 91090.1484 - accuracy: 0.6051 - val_loss: 23847.1191 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 65/250\n",
            "18/18 - 0s - loss: 91094.8203 - accuracy: 0.6051 - val_loss: 23836.3105 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 66/250\n",
            "18/18 - 0s - loss: 91060.4609 - accuracy: 0.6051 - val_loss: 23818.1777 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 67/250\n",
            "18/18 - 0s - loss: 91057.8516 - accuracy: 0.6051 - val_loss: 23801.0742 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 68/250\n",
            "18/18 - 0s - loss: 91130.5703 - accuracy: 0.6051 - val_loss: 23850.8320 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 69/250\n",
            "18/18 - 0s - loss: 91121.0469 - accuracy: 0.6051 - val_loss: 23815.7578 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 70/250\n",
            "18/18 - 0s - loss: 91069.1016 - accuracy: 0.6051 - val_loss: 23811.6250 - val_accuracy: 0.6201 - 127ms/epoch - 7ms/step\n",
            "Epoch 71/250\n",
            "18/18 - 0s - loss: 91077.7578 - accuracy: 0.6051 - val_loss: 23808.4922 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 72/250\n",
            "18/18 - 0s - loss: 91065.4141 - accuracy: 0.6051 - val_loss: 23988.6719 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 73/250\n",
            "18/18 - 0s - loss: 91077.5156 - accuracy: 0.6051 - val_loss: 23799.4512 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 74/250\n",
            "18/18 - 0s - loss: 91081.7344 - accuracy: 0.6051 - val_loss: 23866.3594 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 75/250\n",
            "18/18 - 0s - loss: 91081.7812 - accuracy: 0.6051 - val_loss: 23807.5312 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 76/250\n",
            "18/18 - 0s - loss: 91094.9531 - accuracy: 0.6051 - val_loss: 23842.8203 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 77/250\n",
            "18/18 - 0s - loss: 91054.9609 - accuracy: 0.6051 - val_loss: 23802.4609 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 78/250\n",
            "18/18 - 0s - loss: 91076.8281 - accuracy: 0.6051 - val_loss: 23870.3945 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 79/250\n",
            "18/18 - 0s - loss: 91060.7578 - accuracy: 0.6051 - val_loss: 23804.2930 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 80/250\n",
            "18/18 - 0s - loss: 91061.4375 - accuracy: 0.6051 - val_loss: 23810.1191 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 81/250\n",
            "18/18 - 0s - loss: 91056.4766 - accuracy: 0.6051 - val_loss: 23787.6074 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 82/250\n",
            "18/18 - 0s - loss: 91077.4922 - accuracy: 0.6051 - val_loss: 23791.3848 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 83/250\n",
            "18/18 - 0s - loss: 91073.3906 - accuracy: 0.6051 - val_loss: 23787.3711 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 84/250\n",
            "18/18 - 0s - loss: 91091.7109 - accuracy: 0.6051 - val_loss: 23804.4883 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 85/250\n",
            "18/18 - 0s - loss: 91078.7422 - accuracy: 0.6051 - val_loss: 23800.9082 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 86/250\n",
            "18/18 - 0s - loss: 91125.6016 - accuracy: 0.6051 - val_loss: 23799.9023 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 87/250\n",
            "18/18 - 0s - loss: 91098.1250 - accuracy: 0.6051 - val_loss: 23802.5859 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 88/250\n",
            "18/18 - 0s - loss: 91121.3359 - accuracy: 0.6051 - val_loss: 23824.3184 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 89/250\n",
            "18/18 - 0s - loss: 91068.2422 - accuracy: 0.6051 - val_loss: 23948.9941 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 90/250\n",
            "18/18 - 0s - loss: 91122.8516 - accuracy: 0.6051 - val_loss: 23816.8496 - val_accuracy: 0.6201 - 72ms/epoch - 4ms/step\n",
            "Epoch 91/250\n",
            "18/18 - 0s - loss: 91076.6250 - accuracy: 0.6051 - val_loss: 23827.8750 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 92/250\n",
            "18/18 - 0s - loss: 91081.1328 - accuracy: 0.6051 - val_loss: 23815.9102 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 93/250\n",
            "18/18 - 0s - loss: 91082.4062 - accuracy: 0.6051 - val_loss: 23790.2227 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 94/250\n",
            "18/18 - 0s - loss: 91066.0391 - accuracy: 0.6051 - val_loss: 23814.9551 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 95/250\n",
            "18/18 - 0s - loss: 91103.8125 - accuracy: 0.6051 - val_loss: 23812.8125 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 96/250\n",
            "18/18 - 0s - loss: 91084.8359 - accuracy: 0.6051 - val_loss: 23797.3750 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 97/250\n",
            "18/18 - 0s - loss: 91039.8594 - accuracy: 0.6051 - val_loss: 24036.9004 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 98/250\n",
            "18/18 - 0s - loss: 91142.2656 - accuracy: 0.6051 - val_loss: 23893.5723 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 99/250\n",
            "18/18 - 0s - loss: 91161.5625 - accuracy: 0.6051 - val_loss: 23971.6250 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 100/250\n",
            "18/18 - 0s - loss: 91092.5000 - accuracy: 0.6051 - val_loss: 23916.6348 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 101/250\n",
            "18/18 - 0s - loss: 91083.9219 - accuracy: 0.6051 - val_loss: 23835.1914 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 102/250\n",
            "18/18 - 0s - loss: 91081.1172 - accuracy: 0.6051 - val_loss: 23823.5195 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 103/250\n",
            "18/18 - 0s - loss: 91090.3359 - accuracy: 0.6051 - val_loss: 23817.2168 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 104/250\n",
            "18/18 - 0s - loss: 91057.2266 - accuracy: 0.6051 - val_loss: 23841.5234 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 105/250\n",
            "18/18 - 0s - loss: 91070.0312 - accuracy: 0.6051 - val_loss: 23814.5195 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 106/250\n",
            "18/18 - 0s - loss: 91054.9141 - accuracy: 0.6051 - val_loss: 23805.4609 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 107/250\n",
            "18/18 - 0s - loss: 91059.2969 - accuracy: 0.6051 - val_loss: 23814.8145 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 108/250\n",
            "18/18 - 0s - loss: 91054.6172 - accuracy: 0.6051 - val_loss: 23834.8750 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 109/250\n",
            "18/18 - 0s - loss: 91071.8750 - accuracy: 0.6051 - val_loss: 23798.4004 - val_accuracy: 0.6201 - 97ms/epoch - 5ms/step\n",
            "Epoch 110/250\n",
            "18/18 - 0s - loss: 91094.6797 - accuracy: 0.6051 - val_loss: 23896.6914 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 111/250\n",
            "18/18 - 0s - loss: 91060.4531 - accuracy: 0.6051 - val_loss: 23864.7461 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 112/250\n",
            "18/18 - 0s - loss: 91052.8984 - accuracy: 0.6051 - val_loss: 23792.7305 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 113/250\n",
            "18/18 - 0s - loss: 91052.7109 - accuracy: 0.6051 - val_loss: 23786.8184 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 114/250\n",
            "18/18 - 0s - loss: 91069.7578 - accuracy: 0.6051 - val_loss: 23806.0957 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 115/250\n",
            "18/18 - 0s - loss: 91062.3828 - accuracy: 0.6051 - val_loss: 23807.4102 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 116/250\n",
            "18/18 - 0s - loss: 91076.0391 - accuracy: 0.6051 - val_loss: 23806.3633 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 117/250\n",
            "18/18 - 0s - loss: 91062.8359 - accuracy: 0.6051 - val_loss: 23804.2891 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 118/250\n",
            "18/18 - 0s - loss: 91033.4062 - accuracy: 0.6051 - val_loss: 23915.2246 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 119/250\n",
            "18/18 - 0s - loss: 91084.3125 - accuracy: 0.6051 - val_loss: 23866.0605 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 120/250\n",
            "18/18 - 0s - loss: 91048.0703 - accuracy: 0.6051 - val_loss: 23831.2637 - val_accuracy: 0.6201 - 74ms/epoch - 4ms/step\n",
            "Epoch 121/250\n",
            "18/18 - 0s - loss: 91058.3906 - accuracy: 0.6051 - val_loss: 23790.2480 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 122/250\n",
            "18/18 - 0s - loss: 91064.7734 - accuracy: 0.6051 - val_loss: 23884.0605 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 123/250\n",
            "18/18 - 0s - loss: 91054.0391 - accuracy: 0.6051 - val_loss: 23800.7344 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 124/250\n",
            "18/18 - 0s - loss: 91036.8203 - accuracy: 0.6051 - val_loss: 23844.5039 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 125/250\n",
            "18/18 - 0s - loss: 91030.2500 - accuracy: 0.6051 - val_loss: 23793.6973 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 126/250\n",
            "18/18 - 0s - loss: 91030.0625 - accuracy: 0.6051 - val_loss: 23803.1172 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 127/250\n",
            "18/18 - 0s - loss: 91034.2734 - accuracy: 0.6051 - val_loss: 23776.0859 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 128/250\n",
            "18/18 - 0s - loss: 91042.3203 - accuracy: 0.6051 - val_loss: 23773.4805 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 129/250\n",
            "18/18 - 0s - loss: 91017.9062 - accuracy: 0.6051 - val_loss: 23784.1484 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 130/250\n",
            "18/18 - 0s - loss: 91036.6641 - accuracy: 0.6051 - val_loss: 23773.1973 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 131/250\n",
            "18/18 - 0s - loss: 91065.6562 - accuracy: 0.6051 - val_loss: 23791.2148 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 132/250\n",
            "18/18 - 0s - loss: 91042.9844 - accuracy: 0.6051 - val_loss: 23799.2656 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 133/250\n",
            "18/18 - 0s - loss: 91082.9922 - accuracy: 0.6051 - val_loss: 23799.0312 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 134/250\n",
            "18/18 - 0s - loss: 91043.1719 - accuracy: 0.6051 - val_loss: 23835.8770 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 135/250\n",
            "18/18 - 0s - loss: 91052.5781 - accuracy: 0.6051 - val_loss: 23784.0312 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 136/250\n",
            "18/18 - 0s - loss: 91121.3516 - accuracy: 0.5750 - val_loss: 23877.0488 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 137/250\n",
            "18/18 - 0s - loss: 91074.5234 - accuracy: 0.6051 - val_loss: 23808.5684 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 138/250\n",
            "18/18 - 0s - loss: 91070.4688 - accuracy: 0.6051 - val_loss: 23839.7812 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 139/250\n",
            "18/18 - 0s - loss: 91046.9688 - accuracy: 0.6051 - val_loss: 23844.0391 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 140/250\n",
            "18/18 - 0s - loss: 91041.0938 - accuracy: 0.6051 - val_loss: 23800.5742 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 141/250\n",
            "18/18 - 0s - loss: 91029.1250 - accuracy: 0.6051 - val_loss: 23824.6035 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 142/250\n",
            "18/18 - 0s - loss: 91098.5156 - accuracy: 0.5553 - val_loss: 23792.7188 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 143/250\n",
            "18/18 - 0s - loss: 91053.2422 - accuracy: 0.6051 - val_loss: 23821.1992 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 144/250\n",
            "18/18 - 0s - loss: 91109.4531 - accuracy: 0.5854 - val_loss: 23795.1270 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 145/250\n",
            "18/18 - 0s - loss: 91025.4531 - accuracy: 0.6051 - val_loss: 23805.9316 - val_accuracy: 0.6201 - 97ms/epoch - 5ms/step\n",
            "Epoch 146/250\n",
            "18/18 - 0s - loss: 91052.3750 - accuracy: 0.6051 - val_loss: 23865.5020 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 147/250\n",
            "18/18 - 0s - loss: 91053.9766 - accuracy: 0.6051 - val_loss: 23803.1191 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 148/250\n",
            "18/18 - 0s - loss: 91041.0938 - accuracy: 0.6051 - val_loss: 23816.3066 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 149/250\n",
            "18/18 - 0s - loss: 91050.1562 - accuracy: 0.6060 - val_loss: 23791.2422 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 150/250\n",
            "18/18 - 0s - loss: 91043.0469 - accuracy: 0.6060 - val_loss: 23791.7285 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 151/250\n",
            "18/18 - 0s - loss: 91018.3047 - accuracy: 0.6051 - val_loss: 23810.3125 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 152/250\n",
            "18/18 - 0s - loss: 91029.8125 - accuracy: 0.6051 - val_loss: 23787.4277 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 153/250\n",
            "18/18 - 0s - loss: 91134.6328 - accuracy: 0.6023 - val_loss: 23872.4746 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 154/250\n",
            "18/18 - 0s - loss: 91088.6094 - accuracy: 0.6013 - val_loss: 23821.0039 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 155/250\n",
            "18/18 - 0s - loss: 91043.8203 - accuracy: 0.6051 - val_loss: 23801.1699 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 156/250\n",
            "18/18 - 0s - loss: 91033.3906 - accuracy: 0.6051 - val_loss: 23794.0000 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 157/250\n",
            "18/18 - 0s - loss: 91043.6406 - accuracy: 0.6051 - val_loss: 23790.8887 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 158/250\n",
            "18/18 - 0s - loss: 91018.3359 - accuracy: 0.6051 - val_loss: 23782.3066 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 159/250\n",
            "18/18 - 0s - loss: 91033.5391 - accuracy: 0.6051 - val_loss: 23784.3281 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 160/250\n",
            "18/18 - 0s - loss: 91033.8125 - accuracy: 0.6060 - val_loss: 23779.0938 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 161/250\n",
            "18/18 - 0s - loss: 91029.8125 - accuracy: 0.6060 - val_loss: 23818.5586 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 162/250\n",
            "18/18 - 0s - loss: 91029.7734 - accuracy: 0.6060 - val_loss: 23805.2520 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 163/250\n",
            "18/18 - 0s - loss: 91028.1172 - accuracy: 0.6051 - val_loss: 23786.1523 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 164/250\n",
            "18/18 - 0s - loss: 91031.0391 - accuracy: 0.6051 - val_loss: 23811.4199 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 165/250\n",
            "18/18 - 0s - loss: 91176.5547 - accuracy: 0.4709 - val_loss: 23889.3906 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 166/250\n",
            "18/18 - 0s - loss: 91089.1562 - accuracy: 0.6060 - val_loss: 23822.6465 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 167/250\n",
            "18/18 - 0s - loss: 91036.7891 - accuracy: 0.6060 - val_loss: 23785.5781 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 168/250\n",
            "18/18 - 0s - loss: 91026.1797 - accuracy: 0.6060 - val_loss: 23835.8965 - val_accuracy: 0.6201 - 100ms/epoch - 6ms/step\n",
            "Epoch 169/250\n",
            "18/18 - 0s - loss: 91074.6641 - accuracy: 0.5994 - val_loss: 23795.8535 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 170/250\n",
            "18/18 - 0s - loss: 91033.7109 - accuracy: 0.6060 - val_loss: 23800.1230 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 171/250\n",
            "18/18 - 0s - loss: 91044.4453 - accuracy: 0.6051 - val_loss: 23777.7773 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 172/250\n",
            "18/18 - 0s - loss: 91038.3203 - accuracy: 0.6060 - val_loss: 23872.1133 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 173/250\n",
            "18/18 - 0s - loss: 91063.9219 - accuracy: 0.6051 - val_loss: 24009.0234 - val_accuracy: 0.4694 - 77ms/epoch - 4ms/step\n",
            "Epoch 174/250\n",
            "18/18 - 0s - loss: 91086.8359 - accuracy: 0.5947 - val_loss: 23795.6113 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 175/250\n",
            "18/18 - 0s - loss: 91015.9062 - accuracy: 0.6051 - val_loss: 23783.4512 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 176/250\n",
            "18/18 - 0s - loss: 91036.8203 - accuracy: 0.6051 - val_loss: 23784.9590 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 177/250\n",
            "18/18 - 0s - loss: 91066.3203 - accuracy: 0.6051 - val_loss: 23796.1641 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 178/250\n",
            "18/18 - 0s - loss: 91030.0859 - accuracy: 0.6051 - val_loss: 23791.1035 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 179/250\n",
            "18/18 - 0s - loss: 91014.3516 - accuracy: 0.6060 - val_loss: 23782.6895 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 180/250\n",
            "18/18 - 0s - loss: 91024.7500 - accuracy: 0.6051 - val_loss: 23800.0371 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 181/250\n",
            "18/18 - 0s - loss: 91042.4609 - accuracy: 0.6069 - val_loss: 23768.7793 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 182/250\n",
            "18/18 - 0s - loss: 91035.1406 - accuracy: 0.6051 - val_loss: 23785.2773 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 183/250\n",
            "18/18 - 0s - loss: 91030.1250 - accuracy: 0.6051 - val_loss: 23797.1621 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 184/250\n",
            "18/18 - 0s - loss: 91033.3281 - accuracy: 0.6023 - val_loss: 23789.4590 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 185/250\n",
            "18/18 - 0s - loss: 91041.1016 - accuracy: 0.6079 - val_loss: 23778.6484 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 186/250\n",
            "18/18 - 0s - loss: 91086.3594 - accuracy: 0.5488 - val_loss: 23777.9219 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 187/250\n",
            "18/18 - 0s - loss: 91060.0391 - accuracy: 0.5694 - val_loss: 24027.6855 - val_accuracy: 0.4039 - 84ms/epoch - 5ms/step\n",
            "Epoch 188/250\n",
            "18/18 - 0s - loss: 91048.0000 - accuracy: 0.5929 - val_loss: 23814.3691 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 189/250\n",
            "18/18 - 0s - loss: 91036.5859 - accuracy: 0.6060 - val_loss: 23789.2285 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 190/250\n",
            "18/18 - 0s - loss: 91010.7031 - accuracy: 0.6060 - val_loss: 23824.0117 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 191/250\n",
            "18/18 - 0s - loss: 91028.1172 - accuracy: 0.6060 - val_loss: 23786.3457 - val_accuracy: 0.6201 - 98ms/epoch - 5ms/step\n",
            "Epoch 192/250\n",
            "18/18 - 0s - loss: 91008.6172 - accuracy: 0.6060 - val_loss: 23779.2051 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 193/250\n",
            "18/18 - 0s - loss: 91029.1406 - accuracy: 0.6051 - val_loss: 23782.4805 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 194/250\n",
            "18/18 - 0s - loss: 91092.6875 - accuracy: 0.6023 - val_loss: 23788.0371 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 195/250\n",
            "18/18 - 0s - loss: 91104.7266 - accuracy: 0.5872 - val_loss: 23951.6934 - val_accuracy: 0.5742 - 89ms/epoch - 5ms/step\n",
            "Epoch 196/250\n",
            "18/18 - 0s - loss: 91067.4766 - accuracy: 0.6032 - val_loss: 23849.4688 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 197/250\n",
            "18/18 - 0s - loss: 91101.8594 - accuracy: 0.6023 - val_loss: 23785.3164 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 198/250\n",
            "18/18 - 0s - loss: 91020.5547 - accuracy: 0.6060 - val_loss: 23793.7969 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 199/250\n",
            "18/18 - 0s - loss: 91018.5078 - accuracy: 0.6060 - val_loss: 23778.3477 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 200/250\n",
            "18/18 - 0s - loss: 91037.6172 - accuracy: 0.6060 - val_loss: 23788.9609 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 201/250\n",
            "18/18 - 0s - loss: 91037.1562 - accuracy: 0.6060 - val_loss: 23795.5039 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 202/250\n",
            "18/18 - 0s - loss: 91044.0547 - accuracy: 0.6060 - val_loss: 23806.6504 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 203/250\n",
            "18/18 - 0s - loss: 91058.6016 - accuracy: 0.6098 - val_loss: 23912.9785 - val_accuracy: 0.6179 - 91ms/epoch - 5ms/step\n",
            "Epoch 204/250\n",
            "18/18 - 0s - loss: 91043.2031 - accuracy: 0.6051 - val_loss: 23864.0410 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 205/250\n",
            "18/18 - 0s - loss: 91070.2891 - accuracy: 0.6060 - val_loss: 23874.0449 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 206/250\n",
            "18/18 - 0s - loss: 91050.7422 - accuracy: 0.6051 - val_loss: 23809.0039 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 207/250\n",
            "18/18 - 0s - loss: 91032.5703 - accuracy: 0.6060 - val_loss: 23843.6172 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 208/250\n",
            "18/18 - 0s - loss: 91039.2031 - accuracy: 0.6060 - val_loss: 23794.0215 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 209/250\n",
            "18/18 - 0s - loss: 91019.8125 - accuracy: 0.6051 - val_loss: 23798.2598 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 210/250\n",
            "18/18 - 0s - loss: 91067.9453 - accuracy: 0.6051 - val_loss: 23797.0625 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 211/250\n",
            "18/18 - 0s - loss: 91047.2812 - accuracy: 0.6069 - val_loss: 23839.1484 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 212/250\n",
            "18/18 - 0s - loss: 91025.1406 - accuracy: 0.6060 - val_loss: 23813.7168 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 213/250\n",
            "18/18 - 0s - loss: 91050.9609 - accuracy: 0.6069 - val_loss: 23813.6035 - val_accuracy: 0.6201 - 125ms/epoch - 7ms/step\n",
            "Epoch 214/250\n",
            "18/18 - 0s - loss: 91048.8672 - accuracy: 0.6060 - val_loss: 23849.0664 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 215/250\n",
            "18/18 - 0s - loss: 91083.8828 - accuracy: 0.6088 - val_loss: 23805.7539 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 216/250\n",
            "18/18 - 0s - loss: 91029.8359 - accuracy: 0.6051 - val_loss: 23872.4141 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 217/250\n",
            "18/18 - 0s - loss: 91044.1719 - accuracy: 0.6041 - val_loss: 23791.5391 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 218/250\n",
            "18/18 - 0s - loss: 91028.2734 - accuracy: 0.6060 - val_loss: 23779.6836 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 219/250\n",
            "18/18 - 0s - loss: 91058.3047 - accuracy: 0.6060 - val_loss: 23847.6328 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 220/250\n",
            "18/18 - 0s - loss: 91110.0156 - accuracy: 0.5966 - val_loss: 23919.8379 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 221/250\n",
            "18/18 - 0s - loss: 91032.5781 - accuracy: 0.6060 - val_loss: 23807.7578 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 222/250\n",
            "18/18 - 0s - loss: 91024.6484 - accuracy: 0.6060 - val_loss: 23799.4492 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 223/250\n",
            "18/18 - 0s - loss: 91032.2969 - accuracy: 0.6060 - val_loss: 23793.9121 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 224/250\n",
            "18/18 - 0s - loss: 91014.9688 - accuracy: 0.6060 - val_loss: 23802.7051 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 225/250\n",
            "18/18 - 0s - loss: 91008.0234 - accuracy: 0.6060 - val_loss: 23787.8262 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 226/250\n",
            "18/18 - 0s - loss: 91150.3516 - accuracy: 0.5976 - val_loss: 23795.0352 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 227/250\n",
            "18/18 - 0s - loss: 91082.6250 - accuracy: 0.5994 - val_loss: 23878.5176 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 228/250\n",
            "18/18 - 0s - loss: 91038.2656 - accuracy: 0.6060 - val_loss: 23813.6172 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 229/250\n",
            "18/18 - 0s - loss: 91019.3203 - accuracy: 0.6060 - val_loss: 23794.8672 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 230/250\n",
            "18/18 - 0s - loss: 91036.6719 - accuracy: 0.6051 - val_loss: 23796.3398 - val_accuracy: 0.6201 - 74ms/epoch - 4ms/step\n",
            "Epoch 231/250\n",
            "18/18 - 0s - loss: 91032.1484 - accuracy: 0.6060 - val_loss: 23832.0879 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 232/250\n",
            "18/18 - 0s - loss: 91020.6719 - accuracy: 0.6041 - val_loss: 23779.9180 - val_accuracy: 0.6201 - 73ms/epoch - 4ms/step\n",
            "Epoch 233/250\n",
            "18/18 - 0s - loss: 91025.3594 - accuracy: 0.6060 - val_loss: 23777.4023 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 234/250\n",
            "18/18 - 0s - loss: 91016.5391 - accuracy: 0.6060 - val_loss: 23772.0703 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 235/250\n",
            "18/18 - 0s - loss: 91034.3203 - accuracy: 0.6069 - val_loss: 23808.8926 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 236/250\n",
            "18/18 - 0s - loss: 91039.4141 - accuracy: 0.6098 - val_loss: 23837.9492 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 237/250\n",
            "18/18 - 0s - loss: 91033.2344 - accuracy: 0.6060 - val_loss: 23782.6602 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 238/250\n",
            "18/18 - 0s - loss: 91012.5547 - accuracy: 0.6051 - val_loss: 23773.0449 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 239/250\n",
            "18/18 - 0s - loss: 91060.8906 - accuracy: 0.6051 - val_loss: 23783.2227 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 240/250\n",
            "18/18 - 0s - loss: 91112.4062 - accuracy: 0.5797 - val_loss: 23796.7344 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 241/250\n",
            "18/18 - 0s - loss: 91044.2734 - accuracy: 0.5994 - val_loss: 23807.4277 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 242/250\n",
            "18/18 - 0s - loss: 91061.5469 - accuracy: 0.6069 - val_loss: 23796.1328 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 243/250\n",
            "18/18 - 0s - loss: 91058.4531 - accuracy: 0.6088 - val_loss: 23794.4316 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 244/250\n",
            "18/18 - 0s - loss: 91030.8750 - accuracy: 0.6060 - val_loss: 23861.5410 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 245/250\n",
            "18/18 - 0s - loss: 91022.9375 - accuracy: 0.6069 - val_loss: 23794.7520 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 246/250\n",
            "18/18 - 0s - loss: 91048.3516 - accuracy: 0.6060 - val_loss: 23802.7109 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 247/250\n",
            "18/18 - 0s - loss: 91030.8984 - accuracy: 0.6060 - val_loss: 23785.9004 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 248/250\n",
            "18/18 - 0s - loss: 91011.4062 - accuracy: 0.6060 - val_loss: 23778.5547 - val_accuracy: 0.6201 - 96ms/epoch - 5ms/step\n",
            "Epoch 249/250\n",
            "18/18 - 0s - loss: 91012.6797 - accuracy: 0.6069 - val_loss: 23827.7070 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 250/250\n",
            "18/18 - 0s - loss: 91093.2109 - accuracy: 0.5844 - val_loss: 23785.7637 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "[[  0.3   8.  128.   20.  250.   64.  128. ]]\n",
            "l1 8\n",
            "epochs 250\n",
            "20\n",
            "0.3\n",
            "Epoch 1/250\n",
            "54/54 - 1s - loss: 95274.3984 - accuracy: 0.4400 - val_loss: 25320.9844 - val_accuracy: 0.3013 - 699ms/epoch - 13ms/step\n",
            "Epoch 2/250\n",
            "54/54 - 0s - loss: 92764.1641 - accuracy: 0.4465 - val_loss: 24676.4766 - val_accuracy: 0.2686 - 184ms/epoch - 3ms/step\n",
            "Epoch 3/250\n",
            "54/54 - 0s - loss: 92766.5234 - accuracy: 0.3940 - val_loss: 24480.6797 - val_accuracy: 0.2707 - 205ms/epoch - 4ms/step\n",
            "Epoch 4/250\n",
            "54/54 - 0s - loss: 92366.7031 - accuracy: 0.4841 - val_loss: 25087.2656 - val_accuracy: 0.3013 - 193ms/epoch - 4ms/step\n",
            "Epoch 5/250\n",
            "54/54 - 0s - loss: 92180.2188 - accuracy: 0.3996 - val_loss: 24112.2773 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 6/250\n",
            "54/54 - 0s - loss: 92014.8984 - accuracy: 0.4953 - val_loss: 24950.2656 - val_accuracy: 0.3013 - 208ms/epoch - 4ms/step\n",
            "Epoch 7/250\n",
            "54/54 - 0s - loss: 92236.1406 - accuracy: 0.4887 - val_loss: 24397.1113 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 8/250\n",
            "54/54 - 0s - loss: 91923.6641 - accuracy: 0.4765 - val_loss: 24566.3730 - val_accuracy: 0.2817 - 209ms/epoch - 4ms/step\n",
            "Epoch 9/250\n",
            "54/54 - 0s - loss: 91914.5312 - accuracy: 0.4690 - val_loss: 24182.3828 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 10/250\n",
            "54/54 - 0s - loss: 91706.9219 - accuracy: 0.5347 - val_loss: 24252.2051 - val_accuracy: 0.3035 - 191ms/epoch - 4ms/step\n",
            "Epoch 11/250\n",
            "54/54 - 0s - loss: 91659.1953 - accuracy: 0.5225 - val_loss: 24167.8164 - val_accuracy: 0.2948 - 213ms/epoch - 4ms/step\n",
            "Epoch 12/250\n",
            "54/54 - 0s - loss: 91585.1250 - accuracy: 0.5610 - val_loss: 24169.4453 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 13/250\n",
            "54/54 - 0s - loss: 91758.0156 - accuracy: 0.4878 - val_loss: 23993.0684 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 14/250\n",
            "54/54 - 0s - loss: 91715.7578 - accuracy: 0.5272 - val_loss: 24046.6895 - val_accuracy: 0.6179 - 217ms/epoch - 4ms/step\n",
            "Epoch 15/250\n",
            "54/54 - 0s - loss: 91590.4219 - accuracy: 0.5685 - val_loss: 24141.2402 - val_accuracy: 0.6201 - 215ms/epoch - 4ms/step\n",
            "Epoch 16/250\n",
            "54/54 - 0s - loss: 91626.1094 - accuracy: 0.5113 - val_loss: 23957.9648 - val_accuracy: 0.6201 - 193ms/epoch - 4ms/step\n",
            "Epoch 17/250\n",
            "54/54 - 0s - loss: 91751.8438 - accuracy: 0.5103 - val_loss: 24136.5723 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 18/250\n",
            "54/54 - 0s - loss: 91621.0938 - accuracy: 0.5141 - val_loss: 24117.7520 - val_accuracy: 0.6201 - 216ms/epoch - 4ms/step\n",
            "Epoch 19/250\n",
            "54/54 - 0s - loss: 91481.2578 - accuracy: 0.6041 - val_loss: 24626.4668 - val_accuracy: 0.3079 - 186ms/epoch - 3ms/step\n",
            "Epoch 20/250\n",
            "54/54 - 0s - loss: 91635.8203 - accuracy: 0.4803 - val_loss: 24041.9590 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 21/250\n",
            "54/54 - 0s - loss: 91612.6641 - accuracy: 0.5131 - val_loss: 24179.0664 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 22/250\n",
            "54/54 - 0s - loss: 91491.9375 - accuracy: 0.5675 - val_loss: 23973.9023 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 23/250\n",
            "54/54 - 0s - loss: 91420.1641 - accuracy: 0.5807 - val_loss: 23975.8887 - val_accuracy: 0.6201 - 193ms/epoch - 4ms/step\n",
            "Epoch 24/250\n",
            "54/54 - 0s - loss: 91422.1641 - accuracy: 0.6051 - val_loss: 23956.3027 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 25/250\n",
            "54/54 - 0s - loss: 91497.4375 - accuracy: 0.5469 - val_loss: 23984.6562 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 26/250\n",
            "54/54 - 0s - loss: 91442.7891 - accuracy: 0.5910 - val_loss: 23973.1426 - val_accuracy: 0.6201 - 220ms/epoch - 4ms/step\n",
            "Epoch 27/250\n",
            "54/54 - 0s - loss: 91415.2656 - accuracy: 0.5985 - val_loss: 24018.0371 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 28/250\n",
            "54/54 - 0s - loss: 91399.4766 - accuracy: 0.6051 - val_loss: 23947.0605 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 29/250\n",
            "54/54 - 0s - loss: 91412.8594 - accuracy: 0.6004 - val_loss: 23989.9883 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 30/250\n",
            "54/54 - 0s - loss: 91376.1797 - accuracy: 0.5985 - val_loss: 23913.5137 - val_accuracy: 0.6201 - 217ms/epoch - 4ms/step\n",
            "Epoch 31/250\n",
            "54/54 - 0s - loss: 91376.1484 - accuracy: 0.6051 - val_loss: 23972.3262 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 32/250\n",
            "54/54 - 0s - loss: 91385.7188 - accuracy: 0.6051 - val_loss: 23993.4551 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 33/250\n",
            "54/54 - 0s - loss: 91359.4844 - accuracy: 0.6041 - val_loss: 23996.8320 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 34/250\n",
            "54/54 - 0s - loss: 91312.1719 - accuracy: 0.6051 - val_loss: 23995.0527 - val_accuracy: 0.6201 - 194ms/epoch - 4ms/step\n",
            "Epoch 35/250\n",
            "54/54 - 0s - loss: 91294.6094 - accuracy: 0.6051 - val_loss: 23941.9180 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 36/250\n",
            "54/54 - 0s - loss: 91311.7188 - accuracy: 0.6051 - val_loss: 23891.2305 - val_accuracy: 0.6201 - 180ms/epoch - 3ms/step\n",
            "Epoch 37/250\n",
            "54/54 - 0s - loss: 91322.2656 - accuracy: 0.6051 - val_loss: 23990.3184 - val_accuracy: 0.6201 - 178ms/epoch - 3ms/step\n",
            "Epoch 38/250\n",
            "54/54 - 0s - loss: 91205.1094 - accuracy: 0.6051 - val_loss: 23835.9121 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 39/250\n",
            "54/54 - 0s - loss: 91217.1953 - accuracy: 0.6051 - val_loss: 23867.5254 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 40/250\n",
            "54/54 - 0s - loss: 91278.1562 - accuracy: 0.5638 - val_loss: 23968.6504 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 41/250\n",
            "54/54 - 0s - loss: 91284.3438 - accuracy: 0.6051 - val_loss: 23936.5000 - val_accuracy: 0.6201 - 178ms/epoch - 3ms/step\n",
            "Epoch 42/250\n",
            "54/54 - 0s - loss: 91257.8438 - accuracy: 0.6051 - val_loss: 24308.3223 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 43/250\n",
            "54/54 - 0s - loss: 91266.9297 - accuracy: 0.6051 - val_loss: 23838.4336 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 44/250\n",
            "54/54 - 0s - loss: 91226.6953 - accuracy: 0.5994 - val_loss: 24100.2852 - val_accuracy: 0.6201 - 194ms/epoch - 4ms/step\n",
            "Epoch 45/250\n",
            "54/54 - 0s - loss: 91262.8594 - accuracy: 0.6051 - val_loss: 23911.1328 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 46/250\n",
            "54/54 - 0s - loss: 91267.3594 - accuracy: 0.6051 - val_loss: 23943.4492 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 47/250\n",
            "54/54 - 0s - loss: 91180.1250 - accuracy: 0.6051 - val_loss: 23788.9609 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 48/250\n",
            "54/54 - 0s - loss: 91232.2031 - accuracy: 0.6051 - val_loss: 23848.5996 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 49/250\n",
            "54/54 - 0s - loss: 91196.0781 - accuracy: 0.6051 - val_loss: 24007.5547 - val_accuracy: 0.6201 - 222ms/epoch - 4ms/step\n",
            "Epoch 50/250\n",
            "54/54 - 0s - loss: 91203.9531 - accuracy: 0.6051 - val_loss: 23945.9121 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 51/250\n",
            "54/54 - 0s - loss: 91255.2500 - accuracy: 0.6051 - val_loss: 24074.5762 - val_accuracy: 0.6201 - 189ms/epoch - 4ms/step\n",
            "Epoch 52/250\n",
            "54/54 - 0s - loss: 91290.3359 - accuracy: 0.6051 - val_loss: 24345.9297 - val_accuracy: 0.6201 - 180ms/epoch - 3ms/step\n",
            "Epoch 53/250\n",
            "54/54 - 0s - loss: 91306.2188 - accuracy: 0.6051 - val_loss: 23975.1836 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 54/250\n",
            "54/54 - 0s - loss: 91359.8906 - accuracy: 0.5947 - val_loss: 23967.0020 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 55/250\n",
            "54/54 - 0s - loss: 91242.3359 - accuracy: 0.6051 - val_loss: 23961.8301 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 56/250\n",
            "54/54 - 0s - loss: 91330.3438 - accuracy: 0.5947 - val_loss: 24346.1406 - val_accuracy: 0.6201 - 200ms/epoch - 4ms/step\n",
            "Epoch 57/250\n",
            "54/54 - 0s - loss: 91280.5938 - accuracy: 0.6051 - val_loss: 23928.7852 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 58/250\n",
            "54/54 - 0s - loss: 91245.2734 - accuracy: 0.6051 - val_loss: 23945.6719 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 59/250\n",
            "54/54 - 0s - loss: 91250.0312 - accuracy: 0.6051 - val_loss: 24366.0508 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 60/250\n",
            "54/54 - 0s - loss: 91344.9375 - accuracy: 0.6051 - val_loss: 23936.5605 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 61/250\n",
            "54/54 - 0s - loss: 91213.8984 - accuracy: 0.6051 - val_loss: 23925.3164 - val_accuracy: 0.6201 - 219ms/epoch - 4ms/step\n",
            "Epoch 62/250\n",
            "54/54 - 0s - loss: 91233.0156 - accuracy: 0.6032 - val_loss: 23922.6035 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 63/250\n",
            "54/54 - 0s - loss: 91221.7266 - accuracy: 0.6051 - val_loss: 23924.9336 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 64/250\n",
            "54/54 - 0s - loss: 91186.8203 - accuracy: 0.6051 - val_loss: 23866.9297 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 65/250\n",
            "54/54 - 0s - loss: 91435.0156 - accuracy: 0.6051 - val_loss: 24339.2578 - val_accuracy: 0.6201 - 192ms/epoch - 4ms/step\n",
            "Epoch 66/250\n",
            "54/54 - 0s - loss: 91387.9922 - accuracy: 0.6051 - val_loss: 24243.7383 - val_accuracy: 0.6201 - 214ms/epoch - 4ms/step\n",
            "Epoch 67/250\n",
            "54/54 - 0s - loss: 94293.5000 - accuracy: 0.5197 - val_loss: 24039.9141 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 68/250\n",
            "54/54 - 0s - loss: 91295.1328 - accuracy: 0.6051 - val_loss: 24026.1719 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 69/250\n",
            "54/54 - 0s - loss: 91259.6719 - accuracy: 0.5938 - val_loss: 23947.9395 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 70/250\n",
            "54/54 - 0s - loss: 91288.1797 - accuracy: 0.6051 - val_loss: 24013.4062 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 71/250\n",
            "54/54 - 0s - loss: 91248.1406 - accuracy: 0.6051 - val_loss: 23959.4062 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 72/250\n",
            "54/54 - 0s - loss: 91231.0781 - accuracy: 0.6051 - val_loss: 23911.7539 - val_accuracy: 0.6201 - 194ms/epoch - 4ms/step\n",
            "Epoch 73/250\n",
            "54/54 - 0s - loss: 91154.2812 - accuracy: 0.6051 - val_loss: 23885.3320 - val_accuracy: 0.6201 - 195ms/epoch - 4ms/step\n",
            "Epoch 74/250\n",
            "54/54 - 0s - loss: 91168.0000 - accuracy: 0.6051 - val_loss: 24125.0449 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 75/250\n",
            "54/54 - 0s - loss: 91197.3516 - accuracy: 0.6051 - val_loss: 23917.2617 - val_accuracy: 0.6201 - 201ms/epoch - 4ms/step\n",
            "Epoch 76/250\n",
            "54/54 - 0s - loss: 92722.5312 - accuracy: 0.5253 - val_loss: 23880.2949 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 77/250\n",
            "54/54 - 0s - loss: 91200.1250 - accuracy: 0.5788 - val_loss: 24153.8770 - val_accuracy: 0.1157 - 226ms/epoch - 4ms/step\n",
            "Epoch 78/250\n",
            "54/54 - 0s - loss: 91228.4375 - accuracy: 0.5919 - val_loss: 23840.4395 - val_accuracy: 0.6201 - 197ms/epoch - 4ms/step\n",
            "Epoch 79/250\n",
            "54/54 - 0s - loss: 91182.3438 - accuracy: 0.6051 - val_loss: 23914.9336 - val_accuracy: 0.6201 - 201ms/epoch - 4ms/step\n",
            "Epoch 80/250\n",
            "54/54 - 0s - loss: 91100.3516 - accuracy: 0.6051 - val_loss: 24045.6895 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 81/250\n",
            "54/54 - 0s - loss: 91193.2266 - accuracy: 0.6051 - val_loss: 23947.5879 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 82/250\n",
            "54/54 - 0s - loss: 91186.0234 - accuracy: 0.6051 - val_loss: 23790.9512 - val_accuracy: 0.6201 - 192ms/epoch - 4ms/step\n",
            "Epoch 83/250\n",
            "54/54 - 0s - loss: 91158.8750 - accuracy: 0.6051 - val_loss: 23937.8535 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 84/250\n",
            "54/54 - 0s - loss: 91199.4297 - accuracy: 0.6051 - val_loss: 23914.0859 - val_accuracy: 0.6201 - 219ms/epoch - 4ms/step\n",
            "Epoch 85/250\n",
            "54/54 - 0s - loss: 91146.7422 - accuracy: 0.6051 - val_loss: 23996.6074 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 86/250\n",
            "54/54 - 0s - loss: 91200.0938 - accuracy: 0.6051 - val_loss: 23925.3496 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 87/250\n",
            "54/54 - 0s - loss: 91206.7578 - accuracy: 0.6051 - val_loss: 23989.1094 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 88/250\n",
            "54/54 - 0s - loss: 91172.1641 - accuracy: 0.6051 - val_loss: 23757.0059 - val_accuracy: 0.6201 - 197ms/epoch - 4ms/step\n",
            "Epoch 89/250\n",
            "54/54 - 0s - loss: 91183.6484 - accuracy: 0.6051 - val_loss: 23777.4941 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 90/250\n",
            "54/54 - 0s - loss: 91111.3906 - accuracy: 0.6051 - val_loss: 23869.9688 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 91/250\n",
            "54/54 - 0s - loss: 91138.6016 - accuracy: 0.6051 - val_loss: 23833.4766 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 92/250\n",
            "54/54 - 0s - loss: 91169.4688 - accuracy: 0.6051 - val_loss: 23888.7715 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 93/250\n",
            "54/54 - 0s - loss: 91159.3438 - accuracy: 0.6051 - val_loss: 23923.3281 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 94/250\n",
            "54/54 - 0s - loss: 91181.4531 - accuracy: 0.6051 - val_loss: 23838.6602 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 95/250\n",
            "54/54 - 0s - loss: 91141.2031 - accuracy: 0.6051 - val_loss: 23826.0977 - val_accuracy: 0.6201 - 177ms/epoch - 3ms/step\n",
            "Epoch 96/250\n",
            "54/54 - 0s - loss: 91283.7266 - accuracy: 0.6032 - val_loss: 24191.5762 - val_accuracy: 0.6201 - 177ms/epoch - 3ms/step\n",
            "Epoch 97/250\n",
            "54/54 - 0s - loss: 91255.1406 - accuracy: 0.6051 - val_loss: 23895.7480 - val_accuracy: 0.6201 - 193ms/epoch - 4ms/step\n",
            "Epoch 98/250\n",
            "54/54 - 0s - loss: 91171.6875 - accuracy: 0.6051 - val_loss: 23941.6621 - val_accuracy: 0.6201 - 216ms/epoch - 4ms/step\n",
            "Epoch 99/250\n",
            "54/54 - 0s - loss: 91196.3359 - accuracy: 0.6051 - val_loss: 23867.8516 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 100/250\n",
            "54/54 - 0s - loss: 91140.8906 - accuracy: 0.6051 - val_loss: 23873.3516 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 101/250\n",
            "54/54 - 0s - loss: 91206.9375 - accuracy: 0.6051 - val_loss: 23863.3730 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 102/250\n",
            "54/54 - 0s - loss: 91137.3672 - accuracy: 0.6051 - val_loss: 23858.8672 - val_accuracy: 0.6201 - 216ms/epoch - 4ms/step\n",
            "Epoch 103/250\n",
            "54/54 - 0s - loss: 91380.7969 - accuracy: 0.6051 - val_loss: 24332.3008 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 104/250\n",
            "54/54 - 0s - loss: 91372.3750 - accuracy: 0.6051 - val_loss: 23852.5762 - val_accuracy: 0.6201 - 199ms/epoch - 4ms/step\n",
            "Epoch 105/250\n",
            "54/54 - 0s - loss: 91109.3438 - accuracy: 0.6051 - val_loss: 24064.8203 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 106/250\n",
            "54/54 - 0s - loss: 91108.2969 - accuracy: 0.6051 - val_loss: 23894.1270 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 107/250\n",
            "54/54 - 0s - loss: 91165.2578 - accuracy: 0.6051 - val_loss: 23872.9277 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 108/250\n",
            "54/54 - 0s - loss: 91121.6797 - accuracy: 0.6051 - val_loss: 23872.7715 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 109/250\n",
            "54/54 - 0s - loss: 91125.6719 - accuracy: 0.6051 - val_loss: 23868.8145 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 110/250\n",
            "54/54 - 0s - loss: 91186.4922 - accuracy: 0.6051 - val_loss: 23851.9043 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 111/250\n",
            "54/54 - 0s - loss: 91155.7734 - accuracy: 0.6051 - val_loss: 23898.1406 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 112/250\n",
            "54/54 - 0s - loss: 91148.2578 - accuracy: 0.6051 - val_loss: 23837.7051 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 113/250\n",
            "54/54 - 0s - loss: 91188.4844 - accuracy: 0.6051 - val_loss: 23846.8770 - val_accuracy: 0.6201 - 219ms/epoch - 4ms/step\n",
            "Epoch 114/250\n",
            "54/54 - 0s - loss: 91152.2266 - accuracy: 0.6051 - val_loss: 23795.2012 - val_accuracy: 0.6201 - 187ms/epoch - 3ms/step\n",
            "Epoch 115/250\n",
            "54/54 - 0s - loss: 91265.7422 - accuracy: 0.6051 - val_loss: 23849.7168 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 116/250\n",
            "54/54 - 0s - loss: 91106.8828 - accuracy: 0.6051 - val_loss: 23833.7812 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 117/250\n",
            "54/54 - 0s - loss: 91122.4219 - accuracy: 0.6051 - val_loss: 23903.8535 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 118/250\n",
            "54/54 - 0s - loss: 91173.5156 - accuracy: 0.6051 - val_loss: 24141.7168 - val_accuracy: 0.6201 - 230ms/epoch - 4ms/step\n",
            "Epoch 119/250\n",
            "54/54 - 0s - loss: 91218.4922 - accuracy: 0.6051 - val_loss: 24090.1836 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 120/250\n",
            "54/54 - 0s - loss: 91459.4453 - accuracy: 0.6023 - val_loss: 24262.7266 - val_accuracy: 0.6201 - 219ms/epoch - 4ms/step\n",
            "Epoch 121/250\n",
            "54/54 - 0s - loss: 91436.8672 - accuracy: 0.6051 - val_loss: 24202.8320 - val_accuracy: 0.6201 - 199ms/epoch - 4ms/step\n",
            "Epoch 122/250\n",
            "54/54 - 0s - loss: 91252.8359 - accuracy: 0.6051 - val_loss: 24151.6289 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 123/250\n",
            "54/54 - 0s - loss: 91340.2266 - accuracy: 0.6051 - val_loss: 24081.6035 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 124/250\n",
            "54/54 - 0s - loss: 91147.4375 - accuracy: 0.6051 - val_loss: 23867.5762 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 125/250\n",
            "54/54 - 0s - loss: 91249.5391 - accuracy: 0.6051 - val_loss: 24147.6973 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 126/250\n",
            "54/54 - 0s - loss: 91210.6719 - accuracy: 0.6051 - val_loss: 23995.5801 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 127/250\n",
            "54/54 - 0s - loss: 91273.8125 - accuracy: 0.6051 - val_loss: 24126.5078 - val_accuracy: 0.6201 - 223ms/epoch - 4ms/step\n",
            "Epoch 128/250\n",
            "54/54 - 0s - loss: 91307.0938 - accuracy: 0.6051 - val_loss: 24113.6270 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 129/250\n",
            "54/54 - 0s - loss: 91265.1016 - accuracy: 0.6051 - val_loss: 24092.0391 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 130/250\n",
            "54/54 - 0s - loss: 91286.9297 - accuracy: 0.6051 - val_loss: 23890.5684 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 131/250\n",
            "54/54 - 0s - loss: 91229.1641 - accuracy: 0.6051 - val_loss: 24065.9688 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 132/250\n",
            "54/54 - 0s - loss: 91233.4297 - accuracy: 0.6051 - val_loss: 24076.1406 - val_accuracy: 0.6201 - 201ms/epoch - 4ms/step\n",
            "Epoch 133/250\n",
            "54/54 - 0s - loss: 91288.8594 - accuracy: 0.6051 - val_loss: 24059.7949 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 134/250\n",
            "54/54 - 0s - loss: 91250.0391 - accuracy: 0.6051 - val_loss: 24057.2188 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 135/250\n",
            "54/54 - 0s - loss: 91202.5312 - accuracy: 0.6051 - val_loss: 24036.5762 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 136/250\n",
            "54/54 - 0s - loss: 91216.2891 - accuracy: 0.6051 - val_loss: 24041.6152 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 137/250\n",
            "54/54 - 0s - loss: 91285.0156 - accuracy: 0.6051 - val_loss: 24046.6113 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 138/250\n",
            "54/54 - 0s - loss: 91444.0000 - accuracy: 0.6051 - val_loss: 24040.8496 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 139/250\n",
            "54/54 - 0s - loss: 91246.7500 - accuracy: 0.6051 - val_loss: 24018.7227 - val_accuracy: 0.6201 - 175ms/epoch - 3ms/step\n",
            "Epoch 140/250\n",
            "54/54 - 0s - loss: 91252.6875 - accuracy: 0.6051 - val_loss: 24015.0391 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 141/250\n",
            "54/54 - 0s - loss: 91237.5156 - accuracy: 0.6051 - val_loss: 24024.7070 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 142/250\n",
            "54/54 - 0s - loss: 91240.2891 - accuracy: 0.6051 - val_loss: 24006.4023 - val_accuracy: 0.6201 - 187ms/epoch - 3ms/step\n",
            "Epoch 143/250\n",
            "54/54 - 0s - loss: 91179.7734 - accuracy: 0.6051 - val_loss: 23896.2480 - val_accuracy: 0.6201 - 189ms/epoch - 4ms/step\n",
            "Epoch 144/250\n",
            "54/54 - 0s - loss: 91128.8984 - accuracy: 0.6051 - val_loss: 24030.5684 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 145/250\n",
            "54/54 - 0s - loss: 91235.1484 - accuracy: 0.6051 - val_loss: 24020.3516 - val_accuracy: 0.6201 - 216ms/epoch - 4ms/step\n",
            "Epoch 146/250\n",
            "54/54 - 0s - loss: 91237.2031 - accuracy: 0.6051 - val_loss: 23960.2070 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 147/250\n",
            "54/54 - 0s - loss: 91166.0156 - accuracy: 0.6051 - val_loss: 23995.6895 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 148/250\n",
            "54/54 - 0s - loss: 91115.8281 - accuracy: 0.6051 - val_loss: 23919.7637 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 149/250\n",
            "54/54 - 0s - loss: 91102.9922 - accuracy: 0.6051 - val_loss: 23842.4883 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 150/250\n",
            "54/54 - 0s - loss: 91256.1875 - accuracy: 0.6051 - val_loss: 23954.5820 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 151/250\n",
            "54/54 - 0s - loss: 91230.9922 - accuracy: 0.6051 - val_loss: 23986.4824 - val_accuracy: 0.6201 - 214ms/epoch - 4ms/step\n",
            "Epoch 152/250\n",
            "54/54 - 0s - loss: 91208.9297 - accuracy: 0.6051 - val_loss: 23999.1660 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 153/250\n",
            "54/54 - 0s - loss: 91163.8438 - accuracy: 0.6051 - val_loss: 24020.1973 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 154/250\n",
            "54/54 - 0s - loss: 91226.4297 - accuracy: 0.6051 - val_loss: 23893.6914 - val_accuracy: 0.6201 - 214ms/epoch - 4ms/step\n",
            "Epoch 155/250\n",
            "54/54 - 0s - loss: 91208.8047 - accuracy: 0.6051 - val_loss: 23896.9844 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 156/250\n",
            "54/54 - 0s - loss: 91190.8281 - accuracy: 0.6051 - val_loss: 23934.1875 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 157/250\n",
            "54/54 - 0s - loss: 91186.2656 - accuracy: 0.6051 - val_loss: 23864.2695 - val_accuracy: 0.6201 - 225ms/epoch - 4ms/step\n",
            "Epoch 158/250\n",
            "54/54 - 0s - loss: 91130.2344 - accuracy: 0.6051 - val_loss: 24011.2168 - val_accuracy: 0.6201 - 179ms/epoch - 3ms/step\n",
            "Epoch 159/250\n",
            "54/54 - 0s - loss: 91243.8906 - accuracy: 0.6051 - val_loss: 24017.5605 - val_accuracy: 0.6201 - 180ms/epoch - 3ms/step\n",
            "Epoch 160/250\n",
            "54/54 - 0s - loss: 91183.5312 - accuracy: 0.6051 - val_loss: 23850.9766 - val_accuracy: 0.6201 - 196ms/epoch - 4ms/step\n",
            "Epoch 161/250\n",
            "54/54 - 0s - loss: 91568.2969 - accuracy: 0.5816 - val_loss: 23978.9590 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 162/250\n",
            "54/54 - 0s - loss: 91218.3203 - accuracy: 0.6051 - val_loss: 23752.4180 - val_accuracy: 0.6201 - 191ms/epoch - 4ms/step\n",
            "Epoch 163/250\n",
            "54/54 - 0s - loss: 91166.5000 - accuracy: 0.6060 - val_loss: 23919.7715 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 164/250\n",
            "54/54 - 0s - loss: 91207.5938 - accuracy: 0.6051 - val_loss: 24010.8359 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 165/250\n",
            "54/54 - 0s - loss: 91218.3438 - accuracy: 0.6051 - val_loss: 23722.3379 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 166/250\n",
            "54/54 - 0s - loss: 91120.7734 - accuracy: 0.6051 - val_loss: 23801.8164 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 167/250\n",
            "54/54 - 0s - loss: 91180.0859 - accuracy: 0.6051 - val_loss: 24001.2891 - val_accuracy: 0.6201 - 200ms/epoch - 4ms/step\n",
            "Epoch 168/250\n",
            "54/54 - 0s - loss: 91243.0781 - accuracy: 0.6051 - val_loss: 23975.0820 - val_accuracy: 0.6201 - 179ms/epoch - 3ms/step\n",
            "Epoch 169/250\n",
            "54/54 - 0s - loss: 91149.3359 - accuracy: 0.6051 - val_loss: 24017.9297 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 170/250\n",
            "54/54 - 0s - loss: 91220.8828 - accuracy: 0.6051 - val_loss: 24013.0156 - val_accuracy: 0.6201 - 225ms/epoch - 4ms/step\n",
            "Epoch 171/250\n",
            "54/54 - 0s - loss: 91206.2656 - accuracy: 0.6051 - val_loss: 23848.5664 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 172/250\n",
            "54/54 - 0s - loss: 91203.1641 - accuracy: 0.6051 - val_loss: 24002.6035 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 173/250\n",
            "54/54 - 0s - loss: 91234.6797 - accuracy: 0.6051 - val_loss: 24021.0391 - val_accuracy: 0.6201 - 214ms/epoch - 4ms/step\n",
            "Epoch 174/250\n",
            "54/54 - 0s - loss: 91219.4922 - accuracy: 0.6051 - val_loss: 23998.7695 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 175/250\n",
            "54/54 - 0s - loss: 91271.3750 - accuracy: 0.6051 - val_loss: 23783.0723 - val_accuracy: 0.6201 - 224ms/epoch - 4ms/step\n",
            "Epoch 176/250\n",
            "54/54 - 0s - loss: 91236.2109 - accuracy: 0.6051 - val_loss: 23993.0293 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 177/250\n",
            "54/54 - 0s - loss: 91216.5469 - accuracy: 0.6051 - val_loss: 23984.8496 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 178/250\n",
            "54/54 - 0s - loss: 91127.7891 - accuracy: 0.6051 - val_loss: 23746.3340 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 179/250\n",
            "54/54 - 0s - loss: 91095.7734 - accuracy: 0.6051 - val_loss: 23990.4102 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 180/250\n",
            "54/54 - 0s - loss: 91149.4688 - accuracy: 0.6051 - val_loss: 24001.8711 - val_accuracy: 0.6201 - 178ms/epoch - 3ms/step\n",
            "Epoch 181/250\n",
            "54/54 - 0s - loss: 91134.7734 - accuracy: 0.6051 - val_loss: 23868.7207 - val_accuracy: 0.6201 - 172ms/epoch - 3ms/step\n",
            "Epoch 182/250\n",
            "54/54 - 0s - loss: 91133.9922 - accuracy: 0.6051 - val_loss: 23907.8359 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 183/250\n",
            "54/54 - 0s - loss: 91193.6406 - accuracy: 0.6051 - val_loss: 24008.4883 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 184/250\n",
            "54/54 - 0s - loss: 91199.8203 - accuracy: 0.6051 - val_loss: 24006.4863 - val_accuracy: 0.6201 - 227ms/epoch - 4ms/step\n",
            "Epoch 185/250\n",
            "54/54 - 0s - loss: 91166.1641 - accuracy: 0.6051 - val_loss: 23982.3750 - val_accuracy: 0.6201 - 196ms/epoch - 4ms/step\n",
            "Epoch 186/250\n",
            "54/54 - 0s - loss: 91219.2734 - accuracy: 0.6051 - val_loss: 24016.6680 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 187/250\n",
            "54/54 - 0s - loss: 91210.8750 - accuracy: 0.6051 - val_loss: 24014.4453 - val_accuracy: 0.6201 - 219ms/epoch - 4ms/step\n",
            "Epoch 188/250\n",
            "54/54 - 0s - loss: 91179.2812 - accuracy: 0.6051 - val_loss: 24005.0586 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 189/250\n",
            "54/54 - 0s - loss: 91245.3203 - accuracy: 0.6051 - val_loss: 24010.8105 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 190/250\n",
            "54/54 - 0s - loss: 91289.0859 - accuracy: 0.6051 - val_loss: 23923.1035 - val_accuracy: 0.6201 - 217ms/epoch - 4ms/step\n",
            "Epoch 191/250\n",
            "54/54 - 0s - loss: 91311.3125 - accuracy: 0.6051 - val_loss: 23938.7383 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 192/250\n",
            "54/54 - 0s - loss: 91146.4375 - accuracy: 0.6051 - val_loss: 23965.0488 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 193/250\n",
            "54/54 - 0s - loss: 91368.4766 - accuracy: 0.6051 - val_loss: 24031.3379 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 194/250\n",
            "54/54 - 0s - loss: 91252.8672 - accuracy: 0.6051 - val_loss: 24020.9492 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 195/250\n",
            "54/54 - 0s - loss: 91232.9531 - accuracy: 0.6051 - val_loss: 24024.0234 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 196/250\n",
            "54/54 - 0s - loss: 91202.9531 - accuracy: 0.6032 - val_loss: 24020.6172 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 197/250\n",
            "54/54 - 0s - loss: 91206.4922 - accuracy: 0.6051 - val_loss: 24005.6055 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 198/250\n",
            "54/54 - 0s - loss: 91170.6641 - accuracy: 0.6051 - val_loss: 23935.0371 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 199/250\n",
            "54/54 - 0s - loss: 91199.3516 - accuracy: 0.6051 - val_loss: 23826.1914 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 200/250\n",
            "54/54 - 0s - loss: 91215.3203 - accuracy: 0.6051 - val_loss: 23947.5391 - val_accuracy: 0.6201 - 199ms/epoch - 4ms/step\n",
            "Epoch 201/250\n",
            "54/54 - 0s - loss: 91153.6094 - accuracy: 0.6051 - val_loss: 23707.5723 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 202/250\n",
            "54/54 - 0s - loss: 91135.1250 - accuracy: 0.6051 - val_loss: 23827.3711 - val_accuracy: 0.6201 - 220ms/epoch - 4ms/step\n",
            "Epoch 203/250\n",
            "54/54 - 0s - loss: 91234.1406 - accuracy: 0.5929 - val_loss: 23948.9043 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 204/250\n",
            "54/54 - 0s - loss: 91116.2891 - accuracy: 0.6060 - val_loss: 23876.2461 - val_accuracy: 0.6201 - 187ms/epoch - 3ms/step\n",
            "Epoch 205/250\n",
            "54/54 - 0s - loss: 91150.7969 - accuracy: 0.6051 - val_loss: 24012.4609 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 206/250\n",
            "54/54 - 0s - loss: 91195.6875 - accuracy: 0.6051 - val_loss: 23917.1055 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 207/250\n",
            "54/54 - 0s - loss: 91139.6797 - accuracy: 0.6051 - val_loss: 24016.3066 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 208/250\n",
            "54/54 - 0s - loss: 91124.4062 - accuracy: 0.6051 - val_loss: 23891.4453 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 209/250\n",
            "54/54 - 0s - loss: 91159.0859 - accuracy: 0.6051 - val_loss: 24013.4863 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 210/250\n",
            "54/54 - 0s - loss: 91204.3750 - accuracy: 0.6051 - val_loss: 23996.1914 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 211/250\n",
            "54/54 - 0s - loss: 91157.9531 - accuracy: 0.6051 - val_loss: 23754.6250 - val_accuracy: 0.6201 - 215ms/epoch - 4ms/step\n",
            "Epoch 212/250\n",
            "54/54 - 0s - loss: 91184.2109 - accuracy: 0.6051 - val_loss: 23983.8945 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 213/250\n",
            "54/54 - 0s - loss: 91167.8203 - accuracy: 0.6051 - val_loss: 23823.0684 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 214/250\n",
            "54/54 - 0s - loss: 91141.1719 - accuracy: 0.6051 - val_loss: 23860.7598 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 215/250\n",
            "54/54 - 0s - loss: 91143.2891 - accuracy: 0.6051 - val_loss: 23913.1934 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 216/250\n",
            "54/54 - 0s - loss: 91139.9922 - accuracy: 0.6051 - val_loss: 23812.9570 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 217/250\n",
            "54/54 - 0s - loss: 91206.9922 - accuracy: 0.6051 - val_loss: 23995.3105 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 218/250\n",
            "54/54 - 0s - loss: 91201.8750 - accuracy: 0.6051 - val_loss: 24021.6777 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 219/250\n",
            "54/54 - 0s - loss: 91270.3984 - accuracy: 0.6051 - val_loss: 24019.0547 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 220/250\n",
            "54/54 - 0s - loss: 91266.6328 - accuracy: 0.6051 - val_loss: 24005.7930 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 221/250\n",
            "54/54 - 0s - loss: 91194.3828 - accuracy: 0.6051 - val_loss: 23824.5137 - val_accuracy: 0.6201 - 196ms/epoch - 4ms/step\n",
            "Epoch 222/250\n",
            "54/54 - 0s - loss: 91086.9062 - accuracy: 0.6051 - val_loss: 23812.6855 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 223/250\n",
            "54/54 - 0s - loss: 91161.4453 - accuracy: 0.6051 - val_loss: 23787.0723 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 224/250\n",
            "54/54 - 0s - loss: 91224.8984 - accuracy: 0.6051 - val_loss: 23906.7070 - val_accuracy: 0.6201 - 219ms/epoch - 4ms/step\n",
            "Epoch 225/250\n",
            "54/54 - 0s - loss: 91198.0938 - accuracy: 0.6051 - val_loss: 24022.9043 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 226/250\n",
            "54/54 - 0s - loss: 91321.3438 - accuracy: 0.6051 - val_loss: 24016.9863 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 227/250\n",
            "54/54 - 0s - loss: 91251.3359 - accuracy: 0.6051 - val_loss: 24002.4375 - val_accuracy: 0.6201 - 189ms/epoch - 4ms/step\n",
            "Epoch 228/250\n",
            "54/54 - 0s - loss: 91230.4297 - accuracy: 0.6051 - val_loss: 23992.3887 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 229/250\n",
            "54/54 - 0s - loss: 91179.9297 - accuracy: 0.6051 - val_loss: 23769.0293 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 230/250\n",
            "54/54 - 0s - loss: 91101.1094 - accuracy: 0.6051 - val_loss: 23793.5684 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 231/250\n",
            "54/54 - 0s - loss: 91132.4688 - accuracy: 0.6051 - val_loss: 23902.6250 - val_accuracy: 0.6201 - 201ms/epoch - 4ms/step\n",
            "Epoch 232/250\n",
            "54/54 - 0s - loss: 91137.9609 - accuracy: 0.6051 - val_loss: 23828.2988 - val_accuracy: 0.6201 - 193ms/epoch - 4ms/step\n",
            "Epoch 233/250\n",
            "54/54 - 0s - loss: 91099.8125 - accuracy: 0.6051 - val_loss: 23751.8184 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 234/250\n",
            "54/54 - 0s - loss: 91079.7891 - accuracy: 0.6051 - val_loss: 23907.3965 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 235/250\n",
            "54/54 - 0s - loss: 91077.4922 - accuracy: 0.6051 - val_loss: 23757.1602 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 236/250\n",
            "54/54 - 0s - loss: 91057.6875 - accuracy: 0.6051 - val_loss: 23753.8066 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 237/250\n",
            "54/54 - 0s - loss: 91247.4453 - accuracy: 0.6051 - val_loss: 23986.0898 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 238/250\n",
            "54/54 - 0s - loss: 91096.4219 - accuracy: 0.6051 - val_loss: 24008.7773 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 239/250\n",
            "54/54 - 0s - loss: 91253.1562 - accuracy: 0.6051 - val_loss: 24035.8672 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 240/250\n",
            "54/54 - 0s - loss: 91268.5156 - accuracy: 0.6051 - val_loss: 24025.7793 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 241/250\n",
            "54/54 - 0s - loss: 91195.5469 - accuracy: 0.6051 - val_loss: 24014.4062 - val_accuracy: 0.6201 - 180ms/epoch - 3ms/step\n",
            "Epoch 242/250\n",
            "54/54 - 0s - loss: 91268.7344 - accuracy: 0.6051 - val_loss: 24010.9238 - val_accuracy: 0.6201 - 194ms/epoch - 4ms/step\n",
            "Epoch 243/250\n",
            "54/54 - 0s - loss: 91153.0938 - accuracy: 0.6051 - val_loss: 24024.9453 - val_accuracy: 0.6201 - 187ms/epoch - 3ms/step\n",
            "Epoch 244/250\n",
            "54/54 - 0s - loss: 91178.1016 - accuracy: 0.6051 - val_loss: 23827.4336 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 245/250\n",
            "54/54 - 0s - loss: 91101.2266 - accuracy: 0.6051 - val_loss: 23978.3164 - val_accuracy: 0.6201 - 201ms/epoch - 4ms/step\n",
            "Epoch 246/250\n",
            "54/54 - 0s - loss: 91132.0625 - accuracy: 0.6051 - val_loss: 23715.0781 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 247/250\n",
            "54/54 - 0s - loss: 91150.6484 - accuracy: 0.6051 - val_loss: 24022.0430 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 248/250\n",
            "54/54 - 0s - loss: 91091.4531 - accuracy: 0.6051 - val_loss: 23730.3867 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 249/250\n",
            "54/54 - 0s - loss: 91145.2812 - accuracy: 0.6051 - val_loss: 23999.2617 - val_accuracy: 0.6201 - 175ms/epoch - 3ms/step\n",
            "Epoch 250/250\n",
            "54/54 - 0s - loss: 91244.7422 - accuracy: 0.6051 - val_loss: 23995.7168 - val_accuracy: 0.6201 - 173ms/epoch - 3ms/step\n",
            "[[  0.  64. 128.  60. 250.   8. 128.]]\n",
            "l1 64\n",
            "epochs 250\n",
            "60\n",
            "0.0\n",
            "Epoch 1/250\n",
            "26/26 - 1s - loss: 72317.9219 - accuracy: 0.5604 - 793ms/epoch - 31ms/step\n",
            "Epoch 2/250\n",
            "26/26 - 0s - loss: 71565.7109 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 3/250\n",
            "26/26 - 0s - loss: 71564.6016 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 4/250\n",
            "26/26 - 0s - loss: 71563.3281 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 5/250\n",
            "26/26 - 0s - loss: 71561.8359 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 6/250\n",
            "26/26 - 0s - loss: 71560.0703 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 7/250\n",
            "26/26 - 0s - loss: 71558.0391 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 8/250\n",
            "26/26 - 0s - loss: 71555.7188 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 9/250\n",
            "26/26 - 0s - loss: 71553.1484 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 10/250\n",
            "26/26 - 0s - loss: 71550.3516 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 11/250\n",
            "26/26 - 0s - loss: 71547.3047 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 12/250\n",
            "26/26 - 0s - loss: 71544.0703 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 13/250\n",
            "26/26 - 0s - loss: 71540.6328 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 14/250\n",
            "26/26 - 0s - loss: 71537.0000 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 15/250\n",
            "26/26 - 0s - loss: 71533.1719 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 16/250\n",
            "26/26 - 0s - loss: 71529.2109 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 17/250\n",
            "26/26 - 0s - loss: 71525.1250 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 18/250\n",
            "26/26 - 0s - loss: 71520.8984 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 19/250\n",
            "26/26 - 0s - loss: 71516.5781 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 20/250\n",
            "26/26 - 0s - loss: 71512.1328 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 21/250\n",
            "26/26 - 0s - loss: 71507.5391 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 22/250\n",
            "26/26 - 0s - loss: 71502.8750 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 23/250\n",
            "26/26 - 0s - loss: 71498.0859 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 24/250\n",
            "26/26 - 0s - loss: 71493.1562 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 25/250\n",
            "26/26 - 0s - loss: 71488.1953 - accuracy: 0.6096 - 78ms/epoch - 3ms/step\n",
            "Epoch 26/250\n",
            "26/26 - 0s - loss: 71483.1172 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 27/250\n",
            "26/26 - 0s - loss: 71478.0000 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 28/250\n",
            "26/26 - 0s - loss: 71472.7969 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 29/250\n",
            "26/26 - 0s - loss: 71467.6875 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 30/250\n",
            "26/26 - 0s - loss: 71462.5781 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 31/250\n",
            "26/26 - 0s - loss: 71457.5312 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 32/250\n",
            "26/26 - 0s - loss: 71452.5078 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 33/250\n",
            "26/26 - 0s - loss: 71447.5469 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 34/250\n",
            "26/26 - 0s - loss: 71442.6562 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 35/250\n",
            "26/26 - 0s - loss: 71437.7031 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 36/250\n",
            "26/26 - 0s - loss: 71432.8594 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 37/250\n",
            "26/26 - 0s - loss: 71428.1172 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 38/250\n",
            "26/26 - 0s - loss: 71423.5000 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 39/250\n",
            "26/26 - 0s - loss: 71418.9453 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 40/250\n",
            "26/26 - 0s - loss: 71414.3906 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 41/250\n",
            "26/26 - 0s - loss: 71409.9844 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 42/250\n",
            "26/26 - 0s - loss: 71405.6094 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 43/250\n",
            "26/26 - 0s - loss: 71401.3672 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 44/250\n",
            "26/26 - 0s - loss: 71397.1094 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 45/250\n",
            "26/26 - 0s - loss: 71392.8516 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 46/250\n",
            "26/26 - 0s - loss: 71388.7266 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 47/250\n",
            "26/26 - 0s - loss: 71384.5703 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 48/250\n",
            "26/26 - 0s - loss: 71380.5391 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 49/250\n",
            "26/26 - 0s - loss: 71376.5078 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 50/250\n",
            "26/26 - 0s - loss: 71372.5547 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 51/250\n",
            "26/26 - 0s - loss: 71368.7578 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 52/250\n",
            "26/26 - 0s - loss: 71364.9062 - accuracy: 0.6096 - 80ms/epoch - 3ms/step\n",
            "Epoch 53/250\n",
            "26/26 - 0s - loss: 71361.1250 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 54/250\n",
            "26/26 - 0s - loss: 71357.4375 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 55/250\n",
            "26/26 - 0s - loss: 71353.8828 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 56/250\n",
            "26/26 - 0s - loss: 71350.3281 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 57/250\n",
            "26/26 - 0s - loss: 71346.9219 - accuracy: 0.6096 - 62ms/epoch - 2ms/step\n",
            "Epoch 58/250\n",
            "26/26 - 0s - loss: 71343.5312 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 59/250\n",
            "26/26 - 0s - loss: 71340.1172 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 60/250\n",
            "26/26 - 0s - loss: 71336.7891 - accuracy: 0.6096 - 62ms/epoch - 2ms/step\n",
            "Epoch 61/250\n",
            "26/26 - 0s - loss: 71333.4297 - accuracy: 0.6096 - 75ms/epoch - 3ms/step\n",
            "Epoch 62/250\n",
            "26/26 - 0s - loss: 71329.9922 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 63/250\n",
            "26/26 - 0s - loss: 71326.6641 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 64/250\n",
            "26/26 - 0s - loss: 71323.3516 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 65/250\n",
            "26/26 - 0s - loss: 71320.0938 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 66/250\n",
            "26/26 - 0s - loss: 71316.8750 - accuracy: 0.6096 - 78ms/epoch - 3ms/step\n",
            "Epoch 67/250\n",
            "26/26 - 0s - loss: 71313.7422 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 68/250\n",
            "26/26 - 0s - loss: 71310.6172 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 69/250\n",
            "26/26 - 0s - loss: 71307.5938 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 70/250\n",
            "26/26 - 0s - loss: 71304.5547 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 71/250\n",
            "26/26 - 0s - loss: 71301.6016 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 72/250\n",
            "26/26 - 0s - loss: 71298.6641 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 73/250\n",
            "26/26 - 0s - loss: 71295.7891 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 74/250\n",
            "26/26 - 0s - loss: 71292.8203 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 75/250\n",
            "26/26 - 0s - loss: 71290.0156 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 76/250\n",
            "26/26 - 0s - loss: 71287.2734 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 77/250\n",
            "26/26 - 0s - loss: 71284.6484 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 78/250\n",
            "26/26 - 0s - loss: 71281.9922 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 79/250\n",
            "26/26 - 0s - loss: 71279.4297 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 80/250\n",
            "26/26 - 0s - loss: 71276.8750 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 81/250\n",
            "26/26 - 0s - loss: 71274.3047 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 82/250\n",
            "26/26 - 0s - loss: 71271.8203 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 83/250\n",
            "26/26 - 0s - loss: 71269.3516 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 84/250\n",
            "26/26 - 0s - loss: 71266.9453 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 85/250\n",
            "26/26 - 0s - loss: 71264.6641 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 86/250\n",
            "26/26 - 0s - loss: 71262.4141 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 87/250\n",
            "26/26 - 0s - loss: 71260.2578 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 88/250\n",
            "26/26 - 0s - loss: 71258.0859 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 89/250\n",
            "26/26 - 0s - loss: 71255.9141 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 90/250\n",
            "26/26 - 0s - loss: 71253.9375 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 91/250\n",
            "26/26 - 0s - loss: 71252.0859 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 92/250\n",
            "26/26 - 0s - loss: 71250.2500 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 93/250\n",
            "26/26 - 0s - loss: 71248.5469 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 94/250\n",
            "26/26 - 0s - loss: 71246.7734 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 95/250\n",
            "26/26 - 0s - loss: 71245.1172 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 96/250\n",
            "26/26 - 0s - loss: 71243.5312 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 97/250\n",
            "26/26 - 0s - loss: 71241.9453 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 98/250\n",
            "26/26 - 0s - loss: 71240.4766 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 99/250\n",
            "26/26 - 0s - loss: 71239.0078 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 100/250\n",
            "26/26 - 0s - loss: 71237.5391 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 101/250\n",
            "26/26 - 0s - loss: 71236.1250 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 102/250\n",
            "26/26 - 0s - loss: 71234.8359 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 103/250\n",
            "26/26 - 0s - loss: 71233.4609 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 104/250\n",
            "26/26 - 0s - loss: 71232.2031 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 105/250\n",
            "26/26 - 0s - loss: 71231.0703 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 106/250\n",
            "26/26 - 0s - loss: 71230.0000 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 107/250\n",
            "26/26 - 0s - loss: 71228.9609 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 108/250\n",
            "26/26 - 0s - loss: 71227.9297 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 109/250\n",
            "26/26 - 0s - loss: 71226.9219 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 110/250\n",
            "26/26 - 0s - loss: 71225.9766 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 111/250\n",
            "26/26 - 0s - loss: 71225.0000 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 112/250\n",
            "26/26 - 0s - loss: 71224.0781 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 113/250\n",
            "26/26 - 0s - loss: 71223.2031 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 114/250\n",
            "26/26 - 0s - loss: 71222.3125 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 115/250\n",
            "26/26 - 0s - loss: 71221.4453 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 116/250\n",
            "26/26 - 0s - loss: 71220.6953 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 117/250\n",
            "26/26 - 0s - loss: 71219.9531 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 118/250\n",
            "26/26 - 0s - loss: 71219.2344 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 119/250\n",
            "26/26 - 0s - loss: 71218.5703 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 120/250\n",
            "26/26 - 0s - loss: 71217.8125 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 121/250\n",
            "26/26 - 0s - loss: 71217.0938 - accuracy: 0.6096 - 74ms/epoch - 3ms/step\n",
            "Epoch 122/250\n",
            "26/26 - 0s - loss: 71216.4688 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 123/250\n",
            "26/26 - 0s - loss: 71215.8750 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 124/250\n",
            "26/26 - 0s - loss: 71215.3047 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 125/250\n",
            "26/26 - 0s - loss: 71214.6875 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 126/250\n",
            "26/26 - 0s - loss: 71214.1484 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 127/250\n",
            "26/26 - 0s - loss: 71213.5781 - accuracy: 0.6096 - 74ms/epoch - 3ms/step\n",
            "Epoch 128/250\n",
            "26/26 - 0s - loss: 71213.1406 - accuracy: 0.6096 - 75ms/epoch - 3ms/step\n",
            "Epoch 129/250\n",
            "26/26 - 0s - loss: 71212.7188 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 130/250\n",
            "26/26 - 0s - loss: 71212.3281 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 131/250\n",
            "26/26 - 0s - loss: 71211.9766 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 132/250\n",
            "26/26 - 0s - loss: 71211.5781 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 133/250\n",
            "26/26 - 0s - loss: 71211.2734 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 134/250\n",
            "26/26 - 0s - loss: 71210.9219 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 135/250\n",
            "26/26 - 0s - loss: 71210.6250 - accuracy: 0.6096 - 74ms/epoch - 3ms/step\n",
            "Epoch 136/250\n",
            "26/26 - 0s - loss: 71210.3359 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 137/250\n",
            "26/26 - 0s - loss: 71210.0703 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 138/250\n",
            "26/26 - 0s - loss: 71209.8359 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 139/250\n",
            "26/26 - 0s - loss: 71209.6484 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 140/250\n",
            "26/26 - 0s - loss: 71209.4609 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 141/250\n",
            "26/26 - 0s - loss: 71209.3281 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 142/250\n",
            "26/26 - 0s - loss: 71209.1484 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 143/250\n",
            "26/26 - 0s - loss: 71209.0234 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 144/250\n",
            "26/26 - 0s - loss: 71208.8750 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 145/250\n",
            "26/26 - 0s - loss: 71208.7422 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 146/250\n",
            "26/26 - 0s - loss: 71208.6953 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 147/250\n",
            "26/26 - 0s - loss: 71208.5859 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 148/250\n",
            "26/26 - 0s - loss: 71208.4609 - accuracy: 0.6096 - 74ms/epoch - 3ms/step\n",
            "Epoch 149/250\n",
            "26/26 - 0s - loss: 71208.3750 - accuracy: 0.6096 - 61ms/epoch - 2ms/step\n",
            "Epoch 150/250\n",
            "26/26 - 0s - loss: 71208.3047 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 151/250\n",
            "26/26 - 0s - loss: 71208.2656 - accuracy: 0.6096 - 60ms/epoch - 2ms/step\n",
            "Epoch 152/250\n",
            "26/26 - 0s - loss: 71208.2344 - accuracy: 0.6096 - 62ms/epoch - 2ms/step\n",
            "Epoch 153/250\n",
            "26/26 - 0s - loss: 71208.1562 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 154/250\n",
            "26/26 - 0s - loss: 71208.1641 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 155/250\n",
            "26/26 - 0s - loss: 71208.0625 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 156/250\n",
            "26/26 - 0s - loss: 71208.0234 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 157/250\n",
            "26/26 - 0s - loss: 71207.9609 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 158/250\n",
            "26/26 - 0s - loss: 71207.9453 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 159/250\n",
            "26/26 - 0s - loss: 71207.8906 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 160/250\n",
            "26/26 - 0s - loss: 71207.8984 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 161/250\n",
            "26/26 - 0s - loss: 71207.8438 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 162/250\n",
            "26/26 - 0s - loss: 71207.8203 - accuracy: 0.6096 - 74ms/epoch - 3ms/step\n",
            "Epoch 163/250\n",
            "26/26 - 0s - loss: 71207.7656 - accuracy: 0.6096 - 62ms/epoch - 2ms/step\n",
            "Epoch 164/250\n",
            "26/26 - 0s - loss: 71207.7188 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 165/250\n",
            "26/26 - 0s - loss: 71207.7031 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 166/250\n",
            "26/26 - 0s - loss: 71207.6719 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 167/250\n",
            "26/26 - 0s - loss: 71207.6719 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 168/250\n",
            "26/26 - 0s - loss: 71207.6562 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 169/250\n",
            "26/26 - 0s - loss: 71207.6484 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 170/250\n",
            "26/26 - 0s - loss: 71207.6484 - accuracy: 0.6096 - 62ms/epoch - 2ms/step\n",
            "Epoch 171/250\n",
            "26/26 - 0s - loss: 71207.6172 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 172/250\n",
            "26/26 - 0s - loss: 71207.6094 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 173/250\n",
            "26/26 - 0s - loss: 71207.6172 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 174/250\n",
            "26/26 - 0s - loss: 71207.6250 - accuracy: 0.6096 - 62ms/epoch - 2ms/step\n",
            "Epoch 175/250\n",
            "26/26 - 0s - loss: 71207.5938 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 176/250\n",
            "26/26 - 0s - loss: 71207.5781 - accuracy: 0.6096 - 77ms/epoch - 3ms/step\n",
            "Epoch 177/250\n",
            "26/26 - 0s - loss: 71207.6172 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 178/250\n",
            "26/26 - 0s - loss: 71207.5859 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 179/250\n",
            "26/26 - 0s - loss: 71207.5781 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 180/250\n",
            "26/26 - 0s - loss: 71207.5703 - accuracy: 0.6096 - 74ms/epoch - 3ms/step\n",
            "Epoch 181/250\n",
            "26/26 - 0s - loss: 71207.5938 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 182/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 183/250\n",
            "26/26 - 0s - loss: 71207.6094 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 184/250\n",
            "26/26 - 0s - loss: 71207.5547 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 185/250\n",
            "26/26 - 0s - loss: 71207.5547 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 186/250\n",
            "26/26 - 0s - loss: 71207.5781 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 187/250\n",
            "26/26 - 0s - loss: 71207.5547 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 188/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 189/250\n",
            "26/26 - 0s - loss: 71207.5781 - accuracy: 0.6096 - 61ms/epoch - 2ms/step\n",
            "Epoch 190/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 76ms/epoch - 3ms/step\n",
            "Epoch 191/250\n",
            "26/26 - 0s - loss: 71207.5312 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 192/250\n",
            "26/26 - 0s - loss: 71207.5391 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 193/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 194/250\n",
            "26/26 - 0s - loss: 71207.5781 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 195/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 196/250\n",
            "26/26 - 0s - loss: 71207.5312 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 197/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 198/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 199/250\n",
            "26/26 - 0s - loss: 71207.5078 - accuracy: 0.6096 - 62ms/epoch - 2ms/step\n",
            "Epoch 200/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 201/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 202/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 203/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 204/250\n",
            "26/26 - 0s - loss: 71207.5781 - accuracy: 0.6096 - 86ms/epoch - 3ms/step\n",
            "Epoch 205/250\n",
            "26/26 - 0s - loss: 71207.5859 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 206/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 207/250\n",
            "26/26 - 0s - loss: 71207.5312 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 208/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 209/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 63ms/epoch - 2ms/step\n",
            "Epoch 210/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 211/250\n",
            "26/26 - 0s - loss: 71207.5312 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 212/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 213/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 214/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 215/250\n",
            "26/26 - 0s - loss: 71207.5000 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 216/250\n",
            "26/26 - 0s - loss: 71207.5000 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 217/250\n",
            "26/26 - 0s - loss: 71207.4922 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 218/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 219/250\n",
            "26/26 - 0s - loss: 71207.5000 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 220/250\n",
            "26/26 - 0s - loss: 71207.5312 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 221/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 222/250\n",
            "26/26 - 0s - loss: 71207.5391 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "Epoch 223/250\n",
            "26/26 - 0s - loss: 71207.5312 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 224/250\n",
            "26/26 - 0s - loss: 71207.5547 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 225/250\n",
            "26/26 - 0s - loss: 71207.4922 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 226/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 227/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 228/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 229/250\n",
            "26/26 - 0s - loss: 71207.5547 - accuracy: 0.6096 - 65ms/epoch - 2ms/step\n",
            "Epoch 230/250\n",
            "26/26 - 0s - loss: 71207.5391 - accuracy: 0.6096 - 65ms/epoch - 3ms/step\n",
            "Epoch 231/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 232/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 233/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 234/250\n",
            "26/26 - 0s - loss: 71207.4844 - accuracy: 0.6096 - 60ms/epoch - 2ms/step\n",
            "Epoch 235/250\n",
            "26/26 - 0s - loss: 71207.5312 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 236/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 237/250\n",
            "26/26 - 0s - loss: 71207.5391 - accuracy: 0.6096 - 72ms/epoch - 3ms/step\n",
            "Epoch 238/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 239/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 240/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 241/250\n",
            "26/26 - 0s - loss: 71207.5078 - accuracy: 0.6096 - 64ms/epoch - 2ms/step\n",
            "Epoch 242/250\n",
            "26/26 - 0s - loss: 71207.5000 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 243/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 68ms/epoch - 3ms/step\n",
            "Epoch 244/250\n",
            "26/26 - 0s - loss: 71207.5469 - accuracy: 0.6096 - 69ms/epoch - 3ms/step\n",
            "Epoch 245/250\n",
            "26/26 - 0s - loss: 71207.4922 - accuracy: 0.6096 - 73ms/epoch - 3ms/step\n",
            "Epoch 246/250\n",
            "26/26 - 0s - loss: 71207.5156 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 247/250\n",
            "26/26 - 0s - loss: 71207.5234 - accuracy: 0.6096 - 66ms/epoch - 3ms/step\n",
            "Epoch 248/250\n",
            "26/26 - 0s - loss: 71207.5000 - accuracy: 0.6096 - 67ms/epoch - 3ms/step\n",
            "Epoch 249/250\n",
            "26/26 - 0s - loss: 71207.4922 - accuracy: 0.6096 - 70ms/epoch - 3ms/step\n",
            "Epoch 250/250\n",
            "26/26 - 0s - loss: 71207.5000 - accuracy: 0.6096 - 71ms/epoch - 3ms/step\n",
            "[[  0.3   8.  128.   20.  100.    8.  128. ]]\n",
            "l1 8\n",
            "epochs 100\n",
            "20\n",
            "0.3\n",
            "Epoch 1/100\n",
            "54/54 - 1s - loss: 93207.9375 - accuracy: 0.4625 - val_loss: 24031.1641 - val_accuracy: 0.6201 - 738ms/epoch - 14ms/step\n",
            "Epoch 2/100\n",
            "54/54 - 0s - loss: 91556.8125 - accuracy: 0.5938 - val_loss: 24058.6855 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "54/54 - 0s - loss: 91600.8125 - accuracy: 0.5385 - val_loss: 24016.9844 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "54/54 - 0s - loss: 91492.8594 - accuracy: 0.6051 - val_loss: 24009.0566 - val_accuracy: 0.6201 - 192ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "54/54 - 0s - loss: 91466.5625 - accuracy: 0.6051 - val_loss: 23956.8262 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "54/54 - 0s - loss: 91490.5703 - accuracy: 0.6051 - val_loss: 24021.5996 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "54/54 - 0s - loss: 91453.4219 - accuracy: 0.6051 - val_loss: 23963.7188 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "54/54 - 0s - loss: 91423.8281 - accuracy: 0.6051 - val_loss: 24150.3398 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "54/54 - 0s - loss: 91503.9688 - accuracy: 0.6051 - val_loss: 24150.4590 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "54/54 - 0s - loss: 91450.0547 - accuracy: 0.6051 - val_loss: 24019.6484 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "54/54 - 0s - loss: 91421.2344 - accuracy: 0.6051 - val_loss: 23902.3281 - val_accuracy: 0.6201 - 200ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "54/54 - 0s - loss: 91487.3984 - accuracy: 0.6051 - val_loss: 24060.2266 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "54/54 - 0s - loss: 91461.3984 - accuracy: 0.6051 - val_loss: 24130.3066 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "54/54 - 0s - loss: 91447.0469 - accuracy: 0.6051 - val_loss: 24020.8320 - val_accuracy: 0.6201 - 215ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "54/54 - 0s - loss: 91426.5703 - accuracy: 0.6051 - val_loss: 24065.0078 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "54/54 - 0s - loss: 91406.2031 - accuracy: 0.6051 - val_loss: 23995.2402 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "54/54 - 0s - loss: 91364.5000 - accuracy: 0.6051 - val_loss: 24049.4121 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "54/54 - 0s - loss: 91415.4141 - accuracy: 0.6051 - val_loss: 23989.9844 - val_accuracy: 0.6201 - 195ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "54/54 - 0s - loss: 91365.8594 - accuracy: 0.6051 - val_loss: 24018.3184 - val_accuracy: 0.6201 - 222ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "54/54 - 0s - loss: 91430.4531 - accuracy: 0.5966 - val_loss: 23985.6562 - val_accuracy: 0.6201 - 216ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "54/54 - 0s - loss: 91397.0938 - accuracy: 0.6051 - val_loss: 24041.7617 - val_accuracy: 0.6201 - 209ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "54/54 - 0s - loss: 91368.8047 - accuracy: 0.6051 - val_loss: 24013.1719 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "54/54 - 0s - loss: 91296.1328 - accuracy: 0.6051 - val_loss: 24049.3887 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "54/54 - 0s - loss: 91248.3828 - accuracy: 0.6051 - val_loss: 23977.2773 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "54/54 - 0s - loss: 91305.2109 - accuracy: 0.6051 - val_loss: 23992.2520 - val_accuracy: 0.6201 - 192ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "54/54 - 0s - loss: 91364.6641 - accuracy: 0.6051 - val_loss: 23973.4512 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "54/54 - 0s - loss: 91235.0469 - accuracy: 0.6051 - val_loss: 24063.6738 - val_accuracy: 0.6201 - 214ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "54/54 - 0s - loss: 91294.2031 - accuracy: 0.6051 - val_loss: 23970.6367 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "54/54 - 0s - loss: 91313.5312 - accuracy: 0.6051 - val_loss: 23964.4199 - val_accuracy: 0.6201 - 216ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "54/54 - 0s - loss: 91308.8125 - accuracy: 0.6051 - val_loss: 24017.7090 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "54/54 - 0s - loss: 91266.3281 - accuracy: 0.6051 - val_loss: 23842.5723 - val_accuracy: 0.6201 - 197ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "54/54 - 0s - loss: 91394.3594 - accuracy: 0.6051 - val_loss: 23988.8379 - val_accuracy: 0.6201 - 191ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "54/54 - 0s - loss: 91281.3281 - accuracy: 0.6051 - val_loss: 23946.4688 - val_accuracy: 0.6201 - 195ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "54/54 - 0s - loss: 91299.6797 - accuracy: 0.6051 - val_loss: 23964.6465 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "54/54 - 0s - loss: 91366.9531 - accuracy: 0.6051 - val_loss: 23957.9609 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "54/54 - 0s - loss: 91277.6016 - accuracy: 0.6051 - val_loss: 23981.8145 - val_accuracy: 0.6201 - 191ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "54/54 - 0s - loss: 91290.9375 - accuracy: 0.6051 - val_loss: 23982.9941 - val_accuracy: 0.6201 - 206ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "54/54 - 0s - loss: 91330.4609 - accuracy: 0.6051 - val_loss: 23970.9414 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "54/54 - 0s - loss: 91259.3359 - accuracy: 0.6051 - val_loss: 23932.0312 - val_accuracy: 0.6201 - 198ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "54/54 - 0s - loss: 91285.3281 - accuracy: 0.6051 - val_loss: 23986.8535 - val_accuracy: 0.6201 - 189ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "54/54 - 0s - loss: 91276.2734 - accuracy: 0.6051 - val_loss: 23964.2988 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "54/54 - 0s - loss: 91433.8438 - accuracy: 0.6051 - val_loss: 24369.4805 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "54/54 - 0s - loss: 91319.8203 - accuracy: 0.6051 - val_loss: 23905.8691 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "54/54 - 0s - loss: 91291.5469 - accuracy: 0.6041 - val_loss: 23934.2598 - val_accuracy: 0.6201 - 198ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "54/54 - 0s - loss: 91227.9219 - accuracy: 0.6051 - val_loss: 23871.1250 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "54/54 - 0s - loss: 91153.1250 - accuracy: 0.6051 - val_loss: 23902.0176 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "54/54 - 0s - loss: 91287.4609 - accuracy: 0.6051 - val_loss: 23912.1094 - val_accuracy: 0.6201 - 224ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "54/54 - 0s - loss: 91177.7344 - accuracy: 0.6051 - val_loss: 23904.6289 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "54/54 - 0s - loss: 91315.4219 - accuracy: 0.6051 - val_loss: 23914.4668 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "54/54 - 0s - loss: 91223.5156 - accuracy: 0.6051 - val_loss: 23905.4766 - val_accuracy: 0.6201 - 187ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "54/54 - 0s - loss: 91248.1562 - accuracy: 0.6051 - val_loss: 24386.9746 - val_accuracy: 0.6201 - 180ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "54/54 - 0s - loss: 91612.1484 - accuracy: 0.6060 - val_loss: 24373.7383 - val_accuracy: 0.6201 - 197ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "54/54 - 0s - loss: 91566.9141 - accuracy: 0.6051 - val_loss: 24350.6445 - val_accuracy: 0.6201 - 217ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "54/54 - 0s - loss: 91548.6094 - accuracy: 0.6051 - val_loss: 24384.9512 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "54/54 - 0s - loss: 91621.8047 - accuracy: 0.6051 - val_loss: 24349.5195 - val_accuracy: 0.6201 - 185ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "54/54 - 0s - loss: 91297.0703 - accuracy: 0.6051 - val_loss: 23900.3379 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "54/54 - 0s - loss: 91145.5391 - accuracy: 0.6041 - val_loss: 23852.5723 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "54/54 - 0s - loss: 91362.6641 - accuracy: 0.6051 - val_loss: 23876.8086 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "54/54 - 0s - loss: 91132.6641 - accuracy: 0.6051 - val_loss: 23826.6621 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "54/54 - 0s - loss: 91525.5547 - accuracy: 0.6051 - val_loss: 24374.1426 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "54/54 - 0s - loss: 91516.0078 - accuracy: 0.6051 - val_loss: 23882.3027 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "54/54 - 0s - loss: 91186.5469 - accuracy: 0.6051 - val_loss: 24106.1641 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "54/54 - 0s - loss: 91212.9609 - accuracy: 0.6051 - val_loss: 24053.7559 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "54/54 - 0s - loss: 91215.5391 - accuracy: 0.6041 - val_loss: 23985.1973 - val_accuracy: 0.6201 - 227ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "54/54 - 0s - loss: 91192.9453 - accuracy: 0.6060 - val_loss: 23888.0664 - val_accuracy: 0.6201 - 201ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "54/54 - 0s - loss: 91194.9766 - accuracy: 0.6051 - val_loss: 24306.2812 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "54/54 - 0s - loss: 91243.6406 - accuracy: 0.6051 - val_loss: 23859.3828 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "54/54 - 0s - loss: 91181.9141 - accuracy: 0.6060 - val_loss: 23870.8008 - val_accuracy: 0.6201 - 215ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "54/54 - 0s - loss: 91213.7969 - accuracy: 0.6051 - val_loss: 23966.4434 - val_accuracy: 0.6201 - 181ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "54/54 - 0s - loss: 91158.1250 - accuracy: 0.6051 - val_loss: 23852.0566 - val_accuracy: 0.6201 - 204ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "54/54 - 0s - loss: 91245.9688 - accuracy: 0.6051 - val_loss: 23845.7715 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "54/54 - 0s - loss: 91277.0078 - accuracy: 0.6041 - val_loss: 23919.4785 - val_accuracy: 0.6201 - 213ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "54/54 - 0s - loss: 91157.6953 - accuracy: 0.6051 - val_loss: 23839.4785 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "54/54 - 0s - loss: 91217.8438 - accuracy: 0.6051 - val_loss: 24300.0859 - val_accuracy: 0.6201 - 207ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "54/54 - 0s - loss: 91303.7109 - accuracy: 0.6051 - val_loss: 23925.4570 - val_accuracy: 0.6201 - 183ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "54/54 - 0s - loss: 91151.7031 - accuracy: 0.6051 - val_loss: 23871.2402 - val_accuracy: 0.6201 - 220ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "54/54 - 0s - loss: 91175.1797 - accuracy: 0.6051 - val_loss: 23863.4648 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "54/54 - 0s - loss: 91128.8516 - accuracy: 0.6060 - val_loss: 23861.4980 - val_accuracy: 0.6201 - 182ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "54/54 - 0s - loss: 91160.3359 - accuracy: 0.6051 - val_loss: 23915.7754 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "54/54 - 0s - loss: 91335.0781 - accuracy: 0.6051 - val_loss: 23859.6660 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "54/54 - 0s - loss: 91200.6719 - accuracy: 0.6051 - val_loss: 23838.8633 - val_accuracy: 0.6201 - 210ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "54/54 - 0s - loss: 91195.3438 - accuracy: 0.6051 - val_loss: 23820.4883 - val_accuracy: 0.6201 - 189ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "54/54 - 0s - loss: 91120.5078 - accuracy: 0.6051 - val_loss: 23840.3574 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "54/54 - 0s - loss: 91141.7891 - accuracy: 0.6051 - val_loss: 23878.9316 - val_accuracy: 0.6201 - 180ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "54/54 - 0s - loss: 91127.9531 - accuracy: 0.6051 - val_loss: 23813.7168 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "54/54 - 0s - loss: 91209.2109 - accuracy: 0.6051 - val_loss: 23837.9941 - val_accuracy: 0.6201 - 202ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "54/54 - 0s - loss: 91197.3203 - accuracy: 0.6051 - val_loss: 23863.6426 - val_accuracy: 0.6201 - 196ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "54/54 - 0s - loss: 91238.5781 - accuracy: 0.6060 - val_loss: 23843.5254 - val_accuracy: 0.6201 - 211ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "54/54 - 0s - loss: 91130.4141 - accuracy: 0.6051 - val_loss: 23908.1914 - val_accuracy: 0.6201 - 205ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "54/54 - 0s - loss: 91129.7812 - accuracy: 0.6051 - val_loss: 23960.0312 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "54/54 - 0s - loss: 91178.2656 - accuracy: 0.6051 - val_loss: 23860.1094 - val_accuracy: 0.6201 - 208ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "54/54 - 0s - loss: 91192.7578 - accuracy: 0.6051 - val_loss: 23887.7227 - val_accuracy: 0.6201 - 193ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "54/54 - 0s - loss: 91134.6094 - accuracy: 0.6041 - val_loss: 23840.9258 - val_accuracy: 0.6201 - 212ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "54/54 - 0s - loss: 91118.6875 - accuracy: 0.6041 - val_loss: 23976.3516 - val_accuracy: 0.6201 - 188ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "54/54 - 0s - loss: 91152.1250 - accuracy: 0.6051 - val_loss: 23833.3438 - val_accuracy: 0.6201 - 186ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "54/54 - 0s - loss: 91313.9219 - accuracy: 0.6051 - val_loss: 23967.4824 - val_accuracy: 0.6201 - 177ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "54/54 - 0s - loss: 91170.5312 - accuracy: 0.6051 - val_loss: 23854.1074 - val_accuracy: 0.6201 - 220ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "54/54 - 0s - loss: 91132.6719 - accuracy: 0.6051 - val_loss: 23916.6699 - val_accuracy: 0.6201 - 190ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "54/54 - 0s - loss: 91160.1016 - accuracy: 0.6060 - val_loss: 23899.0391 - val_accuracy: 0.6201 - 203ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "54/54 - 0s - loss: 91238.9609 - accuracy: 0.6051 - val_loss: 24176.5410 - val_accuracy: 0.6201 - 184ms/epoch - 3ms/step\n",
            "[[  0.3   8.  128.   60.  250.    8.  128. ]]\n",
            "l1 8\n",
            "epochs 250\n",
            "60\n",
            "0.3\n",
            "Epoch 1/250\n",
            "18/18 - 1s - loss: 92412.7422 - accuracy: 0.4991 - val_loss: 24201.3867 - val_accuracy: 0.6245 - 612ms/epoch - 34ms/step\n",
            "Epoch 2/250\n",
            "18/18 - 0s - loss: 91790.4062 - accuracy: 0.4981 - val_loss: 24101.7773 - val_accuracy: 0.6245 - 83ms/epoch - 5ms/step\n",
            "Epoch 3/250\n",
            "18/18 - 0s - loss: 91645.0000 - accuracy: 0.4981 - val_loss: 24132.1055 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 4/250\n",
            "18/18 - 0s - loss: 91518.5703 - accuracy: 0.6032 - val_loss: 24059.8203 - val_accuracy: 0.6223 - 79ms/epoch - 4ms/step\n",
            "Epoch 5/250\n",
            "18/18 - 0s - loss: 91507.1719 - accuracy: 0.5976 - val_loss: 24048.7773 - val_accuracy: 0.6245 - 93ms/epoch - 5ms/step\n",
            "Epoch 6/250\n",
            "18/18 - 0s - loss: 91476.3125 - accuracy: 0.6051 - val_loss: 23997.0215 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 7/250\n",
            "18/18 - 0s - loss: 91463.4453 - accuracy: 0.6051 - val_loss: 23981.9414 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 8/250\n",
            "18/18 - 0s - loss: 91450.1953 - accuracy: 0.5807 - val_loss: 23984.5312 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 9/250\n",
            "18/18 - 0s - loss: 91436.8203 - accuracy: 0.6051 - val_loss: 24059.5254 - val_accuracy: 0.5066 - 84ms/epoch - 5ms/step\n",
            "Epoch 10/250\n",
            "18/18 - 0s - loss: 91471.4922 - accuracy: 0.5084 - val_loss: 24140.0059 - val_accuracy: 0.3188 - 77ms/epoch - 4ms/step\n",
            "Epoch 11/250\n",
            "18/18 - 0s - loss: 91406.2734 - accuracy: 0.5919 - val_loss: 23955.7188 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 12/250\n",
            "18/18 - 0s - loss: 91378.9297 - accuracy: 0.6051 - val_loss: 23901.6719 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 13/250\n",
            "18/18 - 0s - loss: 91344.6328 - accuracy: 0.6051 - val_loss: 23902.3945 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 14/250\n",
            "18/18 - 0s - loss: 91466.9688 - accuracy: 0.6051 - val_loss: 24020.8359 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 15/250\n",
            "18/18 - 0s - loss: 91455.3125 - accuracy: 0.6051 - val_loss: 24017.6191 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 16/250\n",
            "18/18 - 0s - loss: 91439.8984 - accuracy: 0.6051 - val_loss: 24022.7812 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 17/250\n",
            "18/18 - 0s - loss: 91425.6562 - accuracy: 0.6051 - val_loss: 23987.8496 - val_accuracy: 0.6201 - 96ms/epoch - 5ms/step\n",
            "Epoch 18/250\n",
            "18/18 - 0s - loss: 91410.1562 - accuracy: 0.6051 - val_loss: 23989.4844 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 19/250\n",
            "18/18 - 0s - loss: 91384.5156 - accuracy: 0.6051 - val_loss: 23944.5254 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 20/250\n",
            "18/18 - 0s - loss: 91296.1250 - accuracy: 0.6051 - val_loss: 23785.7910 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 21/250\n",
            "18/18 - 0s - loss: 91326.6719 - accuracy: 0.6051 - val_loss: 23927.9121 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 22/250\n",
            "18/18 - 0s - loss: 91323.6562 - accuracy: 0.6051 - val_loss: 23994.8887 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 23/250\n",
            "18/18 - 0s - loss: 91291.8438 - accuracy: 0.6051 - val_loss: 23903.2656 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 24/250\n",
            "18/18 - 0s - loss: 91252.1094 - accuracy: 0.6051 - val_loss: 23729.8750 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 25/250\n",
            "18/18 - 0s - loss: 91209.6016 - accuracy: 0.6051 - val_loss: 23880.4238 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 26/250\n",
            "18/18 - 0s - loss: 91203.2266 - accuracy: 0.6051 - val_loss: 23899.6484 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 27/250\n",
            "18/18 - 0s - loss: 91246.2188 - accuracy: 0.6051 - val_loss: 23900.0996 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 28/250\n",
            "18/18 - 0s - loss: 91217.7031 - accuracy: 0.6051 - val_loss: 23715.5195 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 29/250\n",
            "18/18 - 0s - loss: 91208.0938 - accuracy: 0.6051 - val_loss: 23753.3633 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 30/250\n",
            "18/18 - 0s - loss: 91176.0781 - accuracy: 0.6051 - val_loss: 23849.4375 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 31/250\n",
            "18/18 - 0s - loss: 91234.5078 - accuracy: 0.6051 - val_loss: 23691.9609 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 32/250\n",
            "18/18 - 0s - loss: 91206.5547 - accuracy: 0.6051 - val_loss: 23723.3672 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 33/250\n",
            "18/18 - 0s - loss: 91175.1406 - accuracy: 0.6051 - val_loss: 23718.8301 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 34/250\n",
            "18/18 - 0s - loss: 91166.2891 - accuracy: 0.6051 - val_loss: 23746.8555 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 35/250\n",
            "18/18 - 0s - loss: 91174.9375 - accuracy: 0.6051 - val_loss: 23786.4414 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 36/250\n",
            "18/18 - 0s - loss: 91142.1953 - accuracy: 0.6051 - val_loss: 23845.2773 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 37/250\n",
            "18/18 - 0s - loss: 91141.7969 - accuracy: 0.6051 - val_loss: 23796.6875 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 38/250\n",
            "18/18 - 0s - loss: 91209.9531 - accuracy: 0.6051 - val_loss: 23955.5312 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 39/250\n",
            "18/18 - 0s - loss: 91203.6953 - accuracy: 0.6051 - val_loss: 23960.0977 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 40/250\n",
            "18/18 - 0s - loss: 91179.7812 - accuracy: 0.6051 - val_loss: 23791.6348 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 41/250\n",
            "18/18 - 0s - loss: 91192.7344 - accuracy: 0.6051 - val_loss: 23778.1934 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 42/250\n",
            "18/18 - 0s - loss: 91130.6953 - accuracy: 0.6051 - val_loss: 23748.7578 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 43/250\n",
            "18/18 - 0s - loss: 91131.1172 - accuracy: 0.6051 - val_loss: 23725.2988 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 44/250\n",
            "18/18 - 0s - loss: 91113.7891 - accuracy: 0.6051 - val_loss: 23745.0332 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 45/250\n",
            "18/18 - 0s - loss: 91156.5156 - accuracy: 0.6051 - val_loss: 23956.5977 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 46/250\n",
            "18/18 - 0s - loss: 91193.4688 - accuracy: 0.6051 - val_loss: 23961.0547 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 47/250\n",
            "18/18 - 0s - loss: 91174.8281 - accuracy: 0.6051 - val_loss: 23922.2793 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 48/250\n",
            "18/18 - 0s - loss: 91155.7734 - accuracy: 0.6051 - val_loss: 23781.6836 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 49/250\n",
            "18/18 - 0s - loss: 91121.5234 - accuracy: 0.6051 - val_loss: 23813.5156 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 50/250\n",
            "18/18 - 0s - loss: 91110.1797 - accuracy: 0.6051 - val_loss: 23755.7207 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 51/250\n",
            "18/18 - 0s - loss: 91184.9766 - accuracy: 0.6051 - val_loss: 23785.0586 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 52/250\n",
            "18/18 - 0s - loss: 91120.7500 - accuracy: 0.6051 - val_loss: 23761.6855 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 53/250\n",
            "18/18 - 0s - loss: 91136.9922 - accuracy: 0.6051 - val_loss: 23772.3008 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 54/250\n",
            "18/18 - 0s - loss: 91104.6641 - accuracy: 0.6051 - val_loss: 23798.3652 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 55/250\n",
            "18/18 - 0s - loss: 91109.5391 - accuracy: 0.6051 - val_loss: 23766.1270 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 56/250\n",
            "18/18 - 0s - loss: 91087.5078 - accuracy: 0.6051 - val_loss: 23769.6992 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 57/250\n",
            "18/18 - 0s - loss: 91099.6328 - accuracy: 0.6051 - val_loss: 23745.0137 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 58/250\n",
            "18/18 - 0s - loss: 91096.2578 - accuracy: 0.6051 - val_loss: 23760.2422 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 59/250\n",
            "18/18 - 0s - loss: 91091.8516 - accuracy: 0.6051 - val_loss: 23892.7930 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 60/250\n",
            "18/18 - 0s - loss: 91179.3438 - accuracy: 0.6041 - val_loss: 23891.2812 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 61/250\n",
            "18/18 - 0s - loss: 91185.8906 - accuracy: 0.6051 - val_loss: 23993.9492 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 62/250\n",
            "18/18 - 0s - loss: 91220.7812 - accuracy: 0.6051 - val_loss: 23982.1094 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 63/250\n",
            "18/18 - 0s - loss: 91241.5781 - accuracy: 0.6051 - val_loss: 23998.4004 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 64/250\n",
            "18/18 - 0s - loss: 91213.5547 - accuracy: 0.6051 - val_loss: 24001.7090 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 65/250\n",
            "18/18 - 0s - loss: 91202.4141 - accuracy: 0.6051 - val_loss: 24039.3945 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 66/250\n",
            "18/18 - 0s - loss: 91161.3906 - accuracy: 0.6051 - val_loss: 23762.1348 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 67/250\n",
            "18/18 - 0s - loss: 91142.7656 - accuracy: 0.6051 - val_loss: 23815.5020 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 68/250\n",
            "18/18 - 0s - loss: 91128.2422 - accuracy: 0.6051 - val_loss: 23891.5625 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 69/250\n",
            "18/18 - 0s - loss: 91144.5156 - accuracy: 0.6051 - val_loss: 23741.2715 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 70/250\n",
            "18/18 - 0s - loss: 91219.2031 - accuracy: 0.6051 - val_loss: 23930.5938 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 71/250\n",
            "18/18 - 0s - loss: 91203.5859 - accuracy: 0.6060 - val_loss: 23932.9082 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 72/250\n",
            "18/18 - 0s - loss: 91208.6094 - accuracy: 0.6051 - val_loss: 23930.3770 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 73/250\n",
            "18/18 - 0s - loss: 91182.5703 - accuracy: 0.6051 - val_loss: 23900.6133 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 74/250\n",
            "18/18 - 0s - loss: 91180.8359 - accuracy: 0.6051 - val_loss: 23918.7598 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 75/250\n",
            "18/18 - 0s - loss: 91153.5781 - accuracy: 0.6051 - val_loss: 23752.2656 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 76/250\n",
            "18/18 - 0s - loss: 91109.1719 - accuracy: 0.6051 - val_loss: 23839.5391 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 77/250\n",
            "18/18 - 0s - loss: 91080.0234 - accuracy: 0.6051 - val_loss: 23735.7031 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 78/250\n",
            "18/18 - 0s - loss: 91100.4609 - accuracy: 0.6051 - val_loss: 23930.8125 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 79/250\n",
            "18/18 - 0s - loss: 91197.6797 - accuracy: 0.6051 - val_loss: 23968.0879 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 80/250\n",
            "18/18 - 0s - loss: 91175.9297 - accuracy: 0.6051 - val_loss: 23987.4844 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 81/250\n",
            "18/18 - 0s - loss: 91165.3906 - accuracy: 0.6051 - val_loss: 23822.4336 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 82/250\n",
            "18/18 - 0s - loss: 91095.3984 - accuracy: 0.6051 - val_loss: 23844.4766 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 83/250\n",
            "18/18 - 0s - loss: 91130.4062 - accuracy: 0.6051 - val_loss: 23833.2285 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 84/250\n",
            "18/18 - 0s - loss: 91125.0469 - accuracy: 0.6051 - val_loss: 23811.1152 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 85/250\n",
            "18/18 - 0s - loss: 91086.6016 - accuracy: 0.6051 - val_loss: 23825.7559 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 86/250\n",
            "18/18 - 0s - loss: 91094.7969 - accuracy: 0.6051 - val_loss: 23766.0039 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 87/250\n",
            "18/18 - 0s - loss: 91069.5312 - accuracy: 0.6051 - val_loss: 23780.0742 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 88/250\n",
            "18/18 - 0s - loss: 91103.9062 - accuracy: 0.6051 - val_loss: 23780.0527 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 89/250\n",
            "18/18 - 0s - loss: 91069.5391 - accuracy: 0.6051 - val_loss: 23751.4883 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 90/250\n",
            "18/18 - 0s - loss: 91093.4531 - accuracy: 0.6051 - val_loss: 23797.2910 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 91/250\n",
            "18/18 - 0s - loss: 91156.8125 - accuracy: 0.6051 - val_loss: 23854.9062 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 92/250\n",
            "18/18 - 0s - loss: 91086.3359 - accuracy: 0.6051 - val_loss: 23891.7383 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 93/250\n",
            "18/18 - 0s - loss: 91094.3984 - accuracy: 0.6051 - val_loss: 23827.5762 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 94/250\n",
            "18/18 - 0s - loss: 91097.1016 - accuracy: 0.6060 - val_loss: 23757.1348 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 95/250\n",
            "18/18 - 0s - loss: 91132.3906 - accuracy: 0.6051 - val_loss: 23745.7637 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 96/250\n",
            "18/18 - 0s - loss: 91081.5312 - accuracy: 0.6051 - val_loss: 23724.1328 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 97/250\n",
            "18/18 - 0s - loss: 91080.0938 - accuracy: 0.6051 - val_loss: 23756.3301 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 98/250\n",
            "18/18 - 0s - loss: 91078.8516 - accuracy: 0.6051 - val_loss: 23844.8203 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 99/250\n",
            "18/18 - 0s - loss: 91078.4375 - accuracy: 0.6051 - val_loss: 23818.3926 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 100/250\n",
            "18/18 - 0s - loss: 91091.9531 - accuracy: 0.6051 - val_loss: 23906.4219 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 101/250\n",
            "18/18 - 0s - loss: 91138.9922 - accuracy: 0.6051 - val_loss: 23894.5527 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 102/250\n",
            "18/18 - 0s - loss: 91089.2188 - accuracy: 0.6051 - val_loss: 23751.9316 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 103/250\n",
            "18/18 - 0s - loss: 91102.0000 - accuracy: 0.6051 - val_loss: 23808.1484 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 104/250\n",
            "18/18 - 0s - loss: 91121.6094 - accuracy: 0.6051 - val_loss: 24006.0898 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 105/250\n",
            "18/18 - 0s - loss: 91120.4844 - accuracy: 0.6051 - val_loss: 23747.4238 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 106/250\n",
            "18/18 - 0s - loss: 91075.8516 - accuracy: 0.6051 - val_loss: 23756.3301 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 107/250\n",
            "18/18 - 0s - loss: 91097.0312 - accuracy: 0.6051 - val_loss: 23760.0449 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 108/250\n",
            "18/18 - 0s - loss: 91077.5625 - accuracy: 0.6051 - val_loss: 23782.4648 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 109/250\n",
            "18/18 - 0s - loss: 91061.6172 - accuracy: 0.6051 - val_loss: 23829.0762 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 110/250\n",
            "18/18 - 0s - loss: 91112.2109 - accuracy: 0.6051 - val_loss: 23778.9648 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 111/250\n",
            "18/18 - 0s - loss: 91095.6797 - accuracy: 0.6051 - val_loss: 23720.3027 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 112/250\n",
            "18/18 - 0s - loss: 91118.7188 - accuracy: 0.6051 - val_loss: 23709.9570 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 113/250\n",
            "18/18 - 0s - loss: 91084.3359 - accuracy: 0.6051 - val_loss: 23739.0820 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 114/250\n",
            "18/18 - 0s - loss: 91091.9531 - accuracy: 0.6051 - val_loss: 23738.8262 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 115/250\n",
            "18/18 - 0s - loss: 91110.4531 - accuracy: 0.6051 - val_loss: 23784.3301 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 116/250\n",
            "18/18 - 0s - loss: 91069.0469 - accuracy: 0.6051 - val_loss: 23772.4844 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 117/250\n",
            "18/18 - 0s - loss: 91075.0156 - accuracy: 0.6051 - val_loss: 23743.1602 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 118/250\n",
            "18/18 - 0s - loss: 91094.1641 - accuracy: 0.6051 - val_loss: 23743.3438 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 119/250\n",
            "18/18 - 0s - loss: 91156.6328 - accuracy: 0.6051 - val_loss: 23723.0801 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 120/250\n",
            "18/18 - 0s - loss: 91097.9375 - accuracy: 0.6051 - val_loss: 23740.1934 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 121/250\n",
            "18/18 - 0s - loss: 91108.9062 - accuracy: 0.6051 - val_loss: 23743.0430 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 122/250\n",
            "18/18 - 0s - loss: 91087.0000 - accuracy: 0.6051 - val_loss: 23828.3008 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 123/250\n",
            "18/18 - 0s - loss: 91142.4375 - accuracy: 0.6051 - val_loss: 23723.3027 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 124/250\n",
            "18/18 - 0s - loss: 91096.4609 - accuracy: 0.6051 - val_loss: 23722.5430 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 125/250\n",
            "18/18 - 0s - loss: 91073.2812 - accuracy: 0.6051 - val_loss: 23723.5977 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 126/250\n",
            "18/18 - 0s - loss: 91088.1328 - accuracy: 0.6051 - val_loss: 23780.5195 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 127/250\n",
            "18/18 - 0s - loss: 91086.9453 - accuracy: 0.6051 - val_loss: 23815.3867 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 128/250\n",
            "18/18 - 0s - loss: 91109.1641 - accuracy: 0.6051 - val_loss: 23897.9707 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 129/250\n",
            "18/18 - 0s - loss: 91107.9844 - accuracy: 0.6051 - val_loss: 23768.4121 - val_accuracy: 0.6201 - 98ms/epoch - 5ms/step\n",
            "Epoch 130/250\n",
            "18/18 - 0s - loss: 91089.1875 - accuracy: 0.6051 - val_loss: 23839.0078 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 131/250\n",
            "18/18 - 0s - loss: 91131.3125 - accuracy: 0.6060 - val_loss: 23735.6641 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 132/250\n",
            "18/18 - 0s - loss: 91062.6250 - accuracy: 0.6051 - val_loss: 23809.0820 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 133/250\n",
            "18/18 - 0s - loss: 91074.1953 - accuracy: 0.6051 - val_loss: 23811.0625 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 134/250\n",
            "18/18 - 0s - loss: 91095.1328 - accuracy: 0.6051 - val_loss: 23819.0059 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 135/250\n",
            "18/18 - 0s - loss: 91104.0469 - accuracy: 0.6051 - val_loss: 23792.8750 - val_accuracy: 0.6201 - 97ms/epoch - 5ms/step\n",
            "Epoch 136/250\n",
            "18/18 - 0s - loss: 91090.0078 - accuracy: 0.6051 - val_loss: 23741.0996 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 137/250\n",
            "18/18 - 0s - loss: 91076.8438 - accuracy: 0.6060 - val_loss: 23918.2344 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 138/250\n",
            "18/18 - 0s - loss: 91083.8203 - accuracy: 0.6051 - val_loss: 23754.8203 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 139/250\n",
            "18/18 - 0s - loss: 91159.8281 - accuracy: 0.6051 - val_loss: 23826.2090 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 140/250\n",
            "18/18 - 0s - loss: 91076.3203 - accuracy: 0.6051 - val_loss: 23783.3965 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 141/250\n",
            "18/18 - 0s - loss: 91060.5156 - accuracy: 0.6060 - val_loss: 23741.3594 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 142/250\n",
            "18/18 - 0s - loss: 91067.8828 - accuracy: 0.6060 - val_loss: 23752.6934 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 143/250\n",
            "18/18 - 0s - loss: 91066.6172 - accuracy: 0.6051 - val_loss: 23723.9492 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 144/250\n",
            "18/18 - 0s - loss: 91077.2266 - accuracy: 0.6051 - val_loss: 23799.5762 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 145/250\n",
            "18/18 - 0s - loss: 91092.3516 - accuracy: 0.6051 - val_loss: 23921.2480 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 146/250\n",
            "18/18 - 0s - loss: 91095.4453 - accuracy: 0.6051 - val_loss: 23781.5566 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 147/250\n",
            "18/18 - 0s - loss: 91103.8516 - accuracy: 0.6051 - val_loss: 23809.4922 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 148/250\n",
            "18/18 - 0s - loss: 91111.2266 - accuracy: 0.6060 - val_loss: 23845.0293 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 149/250\n",
            "18/18 - 0s - loss: 91099.6953 - accuracy: 0.6051 - val_loss: 23790.3633 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 150/250\n",
            "18/18 - 0s - loss: 91106.7812 - accuracy: 0.6051 - val_loss: 23748.7695 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 151/250\n",
            "18/18 - 0s - loss: 91092.9688 - accuracy: 0.6051 - val_loss: 23804.2441 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 152/250\n",
            "18/18 - 0s - loss: 91074.1797 - accuracy: 0.6060 - val_loss: 23840.2246 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 153/250\n",
            "18/18 - 0s - loss: 91135.5000 - accuracy: 0.6051 - val_loss: 23849.2207 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 154/250\n",
            "18/18 - 0s - loss: 91130.1172 - accuracy: 0.6051 - val_loss: 23750.8652 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 155/250\n",
            "18/18 - 0s - loss: 91079.3828 - accuracy: 0.6051 - val_loss: 23787.3320 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 156/250\n",
            "18/18 - 0s - loss: 91075.9062 - accuracy: 0.6060 - val_loss: 23741.8848 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 157/250\n",
            "18/18 - 0s - loss: 91094.3516 - accuracy: 0.6060 - val_loss: 23798.5117 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 158/250\n",
            "18/18 - 0s - loss: 91066.3594 - accuracy: 0.6051 - val_loss: 23753.0215 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 159/250\n",
            "18/18 - 0s - loss: 91078.6953 - accuracy: 0.6051 - val_loss: 23879.5254 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 160/250\n",
            "18/18 - 0s - loss: 91114.0625 - accuracy: 0.6051 - val_loss: 23783.8516 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 161/250\n",
            "18/18 - 0s - loss: 91089.8750 - accuracy: 0.6060 - val_loss: 23763.9453 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 162/250\n",
            "18/18 - 0s - loss: 91071.4453 - accuracy: 0.6051 - val_loss: 23796.9121 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 163/250\n",
            "18/18 - 0s - loss: 91064.5234 - accuracy: 0.6051 - val_loss: 23817.5312 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 164/250\n",
            "18/18 - 0s - loss: 91271.3359 - accuracy: 0.6060 - val_loss: 24304.0352 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 165/250\n",
            "18/18 - 0s - loss: 91345.7734 - accuracy: 0.6051 - val_loss: 23897.7832 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 166/250\n",
            "18/18 - 0s - loss: 91074.6719 - accuracy: 0.6051 - val_loss: 23791.4980 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 167/250\n",
            "18/18 - 0s - loss: 91087.4531 - accuracy: 0.6051 - val_loss: 23850.0059 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 168/250\n",
            "18/18 - 0s - loss: 91068.0234 - accuracy: 0.6051 - val_loss: 23779.7422 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 169/250\n",
            "18/18 - 0s - loss: 91062.5156 - accuracy: 0.6051 - val_loss: 23783.1250 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 170/250\n",
            "18/18 - 0s - loss: 91053.5859 - accuracy: 0.6051 - val_loss: 23841.5410 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 171/250\n",
            "18/18 - 0s - loss: 91134.7734 - accuracy: 0.6051 - val_loss: 23818.4082 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 172/250\n",
            "18/18 - 0s - loss: 91117.3203 - accuracy: 0.6051 - val_loss: 23815.0371 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 173/250\n",
            "18/18 - 0s - loss: 91050.8359 - accuracy: 0.6051 - val_loss: 23781.9297 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 174/250\n",
            "18/18 - 0s - loss: 91087.1406 - accuracy: 0.6060 - val_loss: 23807.3184 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 175/250\n",
            "18/18 - 0s - loss: 91082.6562 - accuracy: 0.6060 - val_loss: 23804.1191 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 176/250\n",
            "18/18 - 0s - loss: 91053.9297 - accuracy: 0.6051 - val_loss: 23768.6504 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 177/250\n",
            "18/18 - 0s - loss: 91100.1328 - accuracy: 0.6051 - val_loss: 23834.2891 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 178/250\n",
            "18/18 - 0s - loss: 91082.0859 - accuracy: 0.6060 - val_loss: 23789.0723 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 179/250\n",
            "18/18 - 0s - loss: 91051.4453 - accuracy: 0.6051 - val_loss: 23817.2988 - val_accuracy: 0.6201 - 132ms/epoch - 7ms/step\n",
            "Epoch 180/250\n",
            "18/18 - 0s - loss: 91042.0625 - accuracy: 0.6051 - val_loss: 23902.4277 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 181/250\n",
            "18/18 - 0s - loss: 91104.9453 - accuracy: 0.6051 - val_loss: 23838.8301 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 182/250\n",
            "18/18 - 0s - loss: 91089.0078 - accuracy: 0.6051 - val_loss: 23822.4434 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 183/250\n",
            "18/18 - 0s - loss: 91166.9609 - accuracy: 0.5938 - val_loss: 23944.5039 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 184/250\n",
            "18/18 - 0s - loss: 91126.6953 - accuracy: 0.6051 - val_loss: 23839.9746 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 185/250\n",
            "18/18 - 0s - loss: 91100.4297 - accuracy: 0.6060 - val_loss: 23829.0332 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 186/250\n",
            "18/18 - 0s - loss: 91115.0000 - accuracy: 0.6051 - val_loss: 23818.7441 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 187/250\n",
            "18/18 - 0s - loss: 91088.1094 - accuracy: 0.6051 - val_loss: 23813.5625 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 188/250\n",
            "18/18 - 0s - loss: 91085.1641 - accuracy: 0.6051 - val_loss: 23804.5859 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 189/250\n",
            "18/18 - 0s - loss: 91072.5781 - accuracy: 0.6051 - val_loss: 23768.6836 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 190/250\n",
            "18/18 - 0s - loss: 91070.3438 - accuracy: 0.6051 - val_loss: 23821.6406 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 191/250\n",
            "18/18 - 0s - loss: 91044.7344 - accuracy: 0.6051 - val_loss: 23804.0371 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 192/250\n",
            "18/18 - 0s - loss: 91062.6875 - accuracy: 0.6051 - val_loss: 23796.0996 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 193/250\n",
            "18/18 - 0s - loss: 91074.3594 - accuracy: 0.6060 - val_loss: 23980.8301 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 194/250\n",
            "18/18 - 0s - loss: 91127.4531 - accuracy: 0.6051 - val_loss: 23862.4121 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 195/250\n",
            "18/18 - 0s - loss: 91096.4531 - accuracy: 0.6051 - val_loss: 23829.1309 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 196/250\n",
            "18/18 - 0s - loss: 91061.1016 - accuracy: 0.6051 - val_loss: 23810.5684 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 197/250\n",
            "18/18 - 0s - loss: 91055.1172 - accuracy: 0.6060 - val_loss: 23852.3223 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 198/250\n",
            "18/18 - 0s - loss: 91107.2422 - accuracy: 0.6051 - val_loss: 23816.0312 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 199/250\n",
            "18/18 - 0s - loss: 91082.5859 - accuracy: 0.6051 - val_loss: 23869.6699 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 200/250\n",
            "18/18 - 0s - loss: 91085.4766 - accuracy: 0.6041 - val_loss: 24001.9863 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 201/250\n",
            "18/18 - 0s - loss: 91101.0078 - accuracy: 0.6051 - val_loss: 23885.0586 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 202/250\n",
            "18/18 - 0s - loss: 91062.5391 - accuracy: 0.6060 - val_loss: 23834.3281 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 203/250\n",
            "18/18 - 0s - loss: 91068.3516 - accuracy: 0.6051 - val_loss: 23836.6895 - val_accuracy: 0.6201 - 101ms/epoch - 6ms/step\n",
            "Epoch 204/250\n",
            "18/18 - 0s - loss: 91074.3438 - accuracy: 0.6060 - val_loss: 23821.7461 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 205/250\n",
            "18/18 - 0s - loss: 91058.1484 - accuracy: 0.6051 - val_loss: 23869.8750 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 206/250\n",
            "18/18 - 0s - loss: 91140.6094 - accuracy: 0.6060 - val_loss: 23855.6855 - val_accuracy: 0.6201 - 101ms/epoch - 6ms/step\n",
            "Epoch 207/250\n",
            "18/18 - 0s - loss: 91136.2422 - accuracy: 0.6051 - val_loss: 23875.5156 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 208/250\n",
            "18/18 - 0s - loss: 91075.3750 - accuracy: 0.6051 - val_loss: 23843.7734 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 209/250\n",
            "18/18 - 0s - loss: 91150.6484 - accuracy: 0.6051 - val_loss: 23890.8691 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 210/250\n",
            "18/18 - 0s - loss: 91096.0938 - accuracy: 0.6060 - val_loss: 23855.9844 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 211/250\n",
            "18/18 - 0s - loss: 91069.4297 - accuracy: 0.6051 - val_loss: 23853.9219 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 212/250\n",
            "18/18 - 0s - loss: 91055.0078 - accuracy: 0.6051 - val_loss: 23825.8379 - val_accuracy: 0.6201 - 96ms/epoch - 5ms/step\n",
            "Epoch 213/250\n",
            "18/18 - 0s - loss: 91095.3281 - accuracy: 0.6051 - val_loss: 24059.3398 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 214/250\n",
            "18/18 - 0s - loss: 91084.6094 - accuracy: 0.6060 - val_loss: 23880.6543 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 215/250\n",
            "18/18 - 0s - loss: 91076.5078 - accuracy: 0.6060 - val_loss: 23879.8086 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 216/250\n",
            "18/18 - 0s - loss: 91105.8828 - accuracy: 0.6051 - val_loss: 23992.4043 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 217/250\n",
            "18/18 - 0s - loss: 91094.6094 - accuracy: 0.6051 - val_loss: 23894.9570 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 218/250\n",
            "18/18 - 0s - loss: 91085.9922 - accuracy: 0.6060 - val_loss: 23860.0254 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 219/250\n",
            "18/18 - 0s - loss: 91056.5547 - accuracy: 0.6051 - val_loss: 23852.5410 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 220/250\n",
            "18/18 - 0s - loss: 91070.7578 - accuracy: 0.6060 - val_loss: 23846.9219 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 221/250\n",
            "18/18 - 0s - loss: 91088.3672 - accuracy: 0.6060 - val_loss: 23839.0781 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 222/250\n",
            "18/18 - 0s - loss: 91090.7656 - accuracy: 0.6060 - val_loss: 23907.7637 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 223/250\n",
            "18/18 - 0s - loss: 91098.3125 - accuracy: 0.6060 - val_loss: 23852.7422 - val_accuracy: 0.6201 - 97ms/epoch - 5ms/step\n",
            "Epoch 224/250\n",
            "18/18 - 0s - loss: 91110.3125 - accuracy: 0.6051 - val_loss: 23898.8066 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 225/250\n",
            "18/18 - 0s - loss: 91080.2344 - accuracy: 0.6060 - val_loss: 23870.7852 - val_accuracy: 0.6201 - 102ms/epoch - 6ms/step\n",
            "Epoch 226/250\n",
            "18/18 - 0s - loss: 91080.2891 - accuracy: 0.6051 - val_loss: 23884.4941 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 227/250\n",
            "18/18 - 0s - loss: 91099.6953 - accuracy: 0.6060 - val_loss: 23876.3945 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 228/250\n",
            "18/18 - 0s - loss: 91108.8594 - accuracy: 0.6051 - val_loss: 23893.7109 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 229/250\n",
            "18/18 - 0s - loss: 91082.0547 - accuracy: 0.6051 - val_loss: 23890.5918 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 230/250\n",
            "18/18 - 0s - loss: 91075.3984 - accuracy: 0.6060 - val_loss: 23877.8516 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 231/250\n",
            "18/18 - 0s - loss: 91077.6562 - accuracy: 0.6060 - val_loss: 23857.1875 - val_accuracy: 0.6201 - 100ms/epoch - 6ms/step\n",
            "Epoch 232/250\n",
            "18/18 - 0s - loss: 91058.1875 - accuracy: 0.6060 - val_loss: 23873.3398 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 233/250\n",
            "18/18 - 0s - loss: 91049.7734 - accuracy: 0.6051 - val_loss: 23840.6035 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 234/250\n",
            "18/18 - 0s - loss: 91060.1797 - accuracy: 0.6060 - val_loss: 23929.2578 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 235/250\n",
            "18/18 - 0s - loss: 91073.2031 - accuracy: 0.6051 - val_loss: 23942.5781 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 236/250\n",
            "18/18 - 0s - loss: 91054.8984 - accuracy: 0.6060 - val_loss: 23831.1172 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 237/250\n",
            "18/18 - 0s - loss: 91087.4922 - accuracy: 0.6060 - val_loss: 23895.0566 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 238/250\n",
            "18/18 - 0s - loss: 91112.7812 - accuracy: 0.6060 - val_loss: 23862.1914 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 239/250\n",
            "18/18 - 0s - loss: 91077.7500 - accuracy: 0.6060 - val_loss: 24009.5449 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 240/250\n",
            "18/18 - 0s - loss: 91082.2969 - accuracy: 0.6060 - val_loss: 23860.5723 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 241/250\n",
            "18/18 - 0s - loss: 91068.3594 - accuracy: 0.6051 - val_loss: 23834.1367 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 242/250\n",
            "18/18 - 0s - loss: 91036.2266 - accuracy: 0.6060 - val_loss: 23837.9492 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 243/250\n",
            "18/18 - 0s - loss: 91091.4219 - accuracy: 0.6051 - val_loss: 23827.3008 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 244/250\n",
            "18/18 - 0s - loss: 91106.0938 - accuracy: 0.6051 - val_loss: 23858.6816 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 245/250\n",
            "18/18 - 0s - loss: 91142.9766 - accuracy: 0.6051 - val_loss: 23881.2207 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 246/250\n",
            "18/18 - 0s - loss: 91076.4141 - accuracy: 0.6060 - val_loss: 23871.8750 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 247/250\n",
            "18/18 - 0s - loss: 91059.4297 - accuracy: 0.6051 - val_loss: 23843.4277 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 248/250\n",
            "18/18 - 0s - loss: 91034.0391 - accuracy: 0.6051 - val_loss: 23985.6875 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 249/250\n",
            "18/18 - 0s - loss: 91073.6172 - accuracy: 0.6060 - val_loss: 23873.7695 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 250/250\n",
            "18/18 - 0s - loss: 91082.9219 - accuracy: 0.6060 - val_loss: 23908.1367 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "[[  0.3   8.  128.   60.  250.    8.  128. ]]\n",
            "l1 8\n",
            "epochs 250\n",
            "60\n",
            "0.3\n",
            "Epoch 1/250\n",
            "18/18 - 1s - loss: 91893.4297 - accuracy: 0.5075 - val_loss: 24043.3691 - val_accuracy: 0.6201 - 603ms/epoch - 33ms/step\n",
            "Epoch 2/250\n",
            "18/18 - 0s - loss: 91516.5000 - accuracy: 0.6023 - val_loss: 24038.8574 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 3/250\n",
            "18/18 - 0s - loss: 91490.6172 - accuracy: 0.6051 - val_loss: 24018.8008 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 4/250\n",
            "18/18 - 0s - loss: 91498.6328 - accuracy: 0.6051 - val_loss: 24048.7715 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 5/250\n",
            "18/18 - 0s - loss: 91480.4922 - accuracy: 0.6051 - val_loss: 24051.6738 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 6/250\n",
            "18/18 - 0s - loss: 91545.4297 - accuracy: 0.5675 - val_loss: 24024.4980 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 7/250\n",
            "18/18 - 0s - loss: 91527.3672 - accuracy: 0.6051 - val_loss: 24055.7812 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 8/250\n",
            "18/18 - 0s - loss: 91516.2656 - accuracy: 0.6051 - val_loss: 24032.3457 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 9/250\n",
            "18/18 - 0s - loss: 91473.7578 - accuracy: 0.6051 - val_loss: 23989.4609 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 10/250\n",
            "18/18 - 0s - loss: 91457.6016 - accuracy: 0.6051 - val_loss: 24019.6328 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 11/250\n",
            "18/18 - 0s - loss: 91406.2891 - accuracy: 0.6051 - val_loss: 23972.8711 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 12/250\n",
            "18/18 - 0s - loss: 91367.7422 - accuracy: 0.6051 - val_loss: 24001.0332 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 13/250\n",
            "18/18 - 0s - loss: 91375.7578 - accuracy: 0.6051 - val_loss: 23912.7891 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 14/250\n",
            "18/18 - 0s - loss: 91334.2109 - accuracy: 0.6051 - val_loss: 23928.9473 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 15/250\n",
            "18/18 - 0s - loss: 91362.2422 - accuracy: 0.6051 - val_loss: 23923.1797 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 16/250\n",
            "18/18 - 0s - loss: 91326.8828 - accuracy: 0.6051 - val_loss: 23982.4316 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 17/250\n",
            "18/18 - 0s - loss: 91310.1328 - accuracy: 0.6051 - val_loss: 23893.0234 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 18/250\n",
            "18/18 - 0s - loss: 91260.2188 - accuracy: 0.6051 - val_loss: 23864.6836 - val_accuracy: 0.6201 - 100ms/epoch - 6ms/step\n",
            "Epoch 19/250\n",
            "18/18 - 0s - loss: 91237.9219 - accuracy: 0.6051 - val_loss: 23859.2832 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 20/250\n",
            "18/18 - 0s - loss: 91322.8672 - accuracy: 0.6051 - val_loss: 23978.6855 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 21/250\n",
            "18/18 - 0s - loss: 91272.5312 - accuracy: 0.6051 - val_loss: 23901.9766 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 22/250\n",
            "18/18 - 0s - loss: 91194.4531 - accuracy: 0.6051 - val_loss: 23694.6426 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 23/250\n",
            "18/18 - 0s - loss: 91182.7969 - accuracy: 0.6051 - val_loss: 23734.7480 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 24/250\n",
            "18/18 - 0s - loss: 91191.4453 - accuracy: 0.6051 - val_loss: 23691.8184 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 25/250\n",
            "18/18 - 0s - loss: 91222.7578 - accuracy: 0.6051 - val_loss: 23780.7910 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 26/250\n",
            "18/18 - 0s - loss: 91178.5391 - accuracy: 0.6051 - val_loss: 23750.0527 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 27/250\n",
            "18/18 - 0s - loss: 91176.6641 - accuracy: 0.6051 - val_loss: 23744.7090 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 28/250\n",
            "18/18 - 0s - loss: 91188.9219 - accuracy: 0.6051 - val_loss: 23775.3633 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 29/250\n",
            "18/18 - 0s - loss: 91173.4375 - accuracy: 0.6051 - val_loss: 23771.2266 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 30/250\n",
            "18/18 - 0s - loss: 91138.4766 - accuracy: 0.6051 - val_loss: 23792.4219 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 31/250\n",
            "18/18 - 0s - loss: 91133.9766 - accuracy: 0.6051 - val_loss: 23773.7051 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 32/250\n",
            "18/18 - 0s - loss: 91294.7969 - accuracy: 0.6051 - val_loss: 23820.7930 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 33/250\n",
            "18/18 - 0s - loss: 91179.6094 - accuracy: 0.6051 - val_loss: 23884.6523 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 34/250\n",
            "18/18 - 0s - loss: 91196.3516 - accuracy: 0.6051 - val_loss: 23871.4082 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 35/250\n",
            "18/18 - 0s - loss: 91156.5078 - accuracy: 0.6051 - val_loss: 23849.0957 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 36/250\n",
            "18/18 - 0s - loss: 91126.6484 - accuracy: 0.6051 - val_loss: 23859.1484 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 37/250\n",
            "18/18 - 0s - loss: 91153.0703 - accuracy: 0.6051 - val_loss: 23930.8945 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 38/250\n",
            "18/18 - 0s - loss: 91154.6953 - accuracy: 0.6051 - val_loss: 23878.2832 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 39/250\n",
            "18/18 - 0s - loss: 91146.5000 - accuracy: 0.6051 - val_loss: 23864.2344 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 40/250\n",
            "18/18 - 0s - loss: 91110.9688 - accuracy: 0.6051 - val_loss: 23909.9609 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 41/250\n",
            "18/18 - 0s - loss: 91108.4766 - accuracy: 0.6051 - val_loss: 23860.0430 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 42/250\n",
            "18/18 - 0s - loss: 91079.3203 - accuracy: 0.6051 - val_loss: 23975.7070 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 43/250\n",
            "18/18 - 0s - loss: 91097.2109 - accuracy: 0.6051 - val_loss: 23823.5293 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 44/250\n",
            "18/18 - 0s - loss: 91098.9531 - accuracy: 0.6051 - val_loss: 23823.5195 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 45/250\n",
            "18/18 - 0s - loss: 91154.9531 - accuracy: 0.6051 - val_loss: 23882.7363 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 46/250\n",
            "18/18 - 0s - loss: 91217.8516 - accuracy: 0.6051 - val_loss: 23861.3066 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 47/250\n",
            "18/18 - 0s - loss: 91154.6797 - accuracy: 0.6051 - val_loss: 23909.4766 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 48/250\n",
            "18/18 - 0s - loss: 91109.4922 - accuracy: 0.6051 - val_loss: 23917.6816 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 49/250\n",
            "18/18 - 0s - loss: 91132.2500 - accuracy: 0.6051 - val_loss: 23844.0742 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 50/250\n",
            "18/18 - 0s - loss: 91117.8516 - accuracy: 0.6051 - val_loss: 23852.9668 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 51/250\n",
            "18/18 - 0s - loss: 91106.2109 - accuracy: 0.6051 - val_loss: 23877.2441 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 52/250\n",
            "18/18 - 0s - loss: 91123.7969 - accuracy: 0.6051 - val_loss: 23886.3750 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 53/250\n",
            "18/18 - 0s - loss: 91152.3281 - accuracy: 0.6051 - val_loss: 23923.1289 - val_accuracy: 0.6201 - 100ms/epoch - 6ms/step\n",
            "Epoch 54/250\n",
            "18/18 - 0s - loss: 91105.9844 - accuracy: 0.6051 - val_loss: 23912.0195 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 55/250\n",
            "18/18 - 0s - loss: 91094.1484 - accuracy: 0.6051 - val_loss: 23834.7617 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 56/250\n",
            "18/18 - 0s - loss: 91100.2812 - accuracy: 0.6051 - val_loss: 23838.2207 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 57/250\n",
            "18/18 - 0s - loss: 91085.0938 - accuracy: 0.6051 - val_loss: 23890.4688 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 58/250\n",
            "18/18 - 0s - loss: 91068.6875 - accuracy: 0.6051 - val_loss: 23816.8457 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 59/250\n",
            "18/18 - 0s - loss: 91115.4219 - accuracy: 0.6051 - val_loss: 23802.1055 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 60/250\n",
            "18/18 - 0s - loss: 91082.2656 - accuracy: 0.6051 - val_loss: 23844.1270 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 61/250\n",
            "18/18 - 0s - loss: 91094.1016 - accuracy: 0.6051 - val_loss: 23840.3379 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 62/250\n",
            "18/18 - 0s - loss: 91071.4688 - accuracy: 0.6051 - val_loss: 23952.0488 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 63/250\n",
            "18/18 - 0s - loss: 91079.1953 - accuracy: 0.6051 - val_loss: 23811.5000 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 64/250\n",
            "18/18 - 0s - loss: 91056.0859 - accuracy: 0.6051 - val_loss: 23822.5410 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 65/250\n",
            "18/18 - 0s - loss: 91074.1484 - accuracy: 0.6051 - val_loss: 23813.0566 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 66/250\n",
            "18/18 - 0s - loss: 91099.8906 - accuracy: 0.6051 - val_loss: 24114.1094 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 67/250\n",
            "18/18 - 0s - loss: 91132.6562 - accuracy: 0.6051 - val_loss: 23900.4766 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 68/250\n",
            "18/18 - 0s - loss: 91150.7422 - accuracy: 0.6051 - val_loss: 23981.7109 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 69/250\n",
            "18/18 - 0s - loss: 91106.2344 - accuracy: 0.6051 - val_loss: 23844.1270 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 70/250\n",
            "18/18 - 0s - loss: 91092.8906 - accuracy: 0.6051 - val_loss: 23830.7520 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 71/250\n",
            "18/18 - 0s - loss: 91093.0703 - accuracy: 0.6051 - val_loss: 23790.1992 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 72/250\n",
            "18/18 - 0s - loss: 91068.5859 - accuracy: 0.6051 - val_loss: 23869.8477 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 73/250\n",
            "18/18 - 0s - loss: 91071.0859 - accuracy: 0.6051 - val_loss: 23811.6172 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 74/250\n",
            "18/18 - 0s - loss: 91097.9375 - accuracy: 0.6051 - val_loss: 23924.9395 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 75/250\n",
            "18/18 - 0s - loss: 91112.4219 - accuracy: 0.6051 - val_loss: 23838.9883 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 76/250\n",
            "18/18 - 0s - loss: 91089.5625 - accuracy: 0.6051 - val_loss: 23853.2656 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 77/250\n",
            "18/18 - 0s - loss: 91187.3828 - accuracy: 0.6051 - val_loss: 23841.5117 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 78/250\n",
            "18/18 - 0s - loss: 91158.3203 - accuracy: 0.6051 - val_loss: 23982.2109 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 79/250\n",
            "18/18 - 0s - loss: 91105.7734 - accuracy: 0.6051 - val_loss: 23858.4570 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 80/250\n",
            "18/18 - 0s - loss: 91113.2578 - accuracy: 0.6051 - val_loss: 23844.5312 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 81/250\n",
            "18/18 - 0s - loss: 91141.6172 - accuracy: 0.6051 - val_loss: 23880.7031 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 82/250\n",
            "18/18 - 0s - loss: 91120.2422 - accuracy: 0.6051 - val_loss: 23916.9668 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 83/250\n",
            "18/18 - 0s - loss: 91074.1484 - accuracy: 0.6051 - val_loss: 23814.8301 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 84/250\n",
            "18/18 - 0s - loss: 91076.6328 - accuracy: 0.6051 - val_loss: 23816.2988 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 85/250\n",
            "18/18 - 0s - loss: 91074.5312 - accuracy: 0.6051 - val_loss: 23830.8652 - val_accuracy: 0.6201 - 75ms/epoch - 4ms/step\n",
            "Epoch 86/250\n",
            "18/18 - 0s - loss: 91115.0547 - accuracy: 0.6051 - val_loss: 23869.7051 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 87/250\n",
            "18/18 - 0s - loss: 91087.4922 - accuracy: 0.6051 - val_loss: 23857.2363 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 88/250\n",
            "18/18 - 0s - loss: 91075.2188 - accuracy: 0.6051 - val_loss: 23817.1562 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 89/250\n",
            "18/18 - 0s - loss: 91162.3906 - accuracy: 0.6051 - val_loss: 23838.2363 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 90/250\n",
            "18/18 - 0s - loss: 91098.5078 - accuracy: 0.6051 - val_loss: 23873.4668 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 91/250\n",
            "18/18 - 0s - loss: 91049.7422 - accuracy: 0.6051 - val_loss: 23813.8574 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 92/250\n",
            "18/18 - 0s - loss: 91096.4375 - accuracy: 0.6051 - val_loss: 24067.4062 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 93/250\n",
            "18/18 - 0s - loss: 91080.8359 - accuracy: 0.6051 - val_loss: 23819.6992 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 94/250\n",
            "18/18 - 0s - loss: 91092.3281 - accuracy: 0.6051 - val_loss: 23868.7832 - val_accuracy: 0.6201 - 96ms/epoch - 5ms/step\n",
            "Epoch 95/250\n",
            "18/18 - 0s - loss: 91060.7656 - accuracy: 0.6051 - val_loss: 23819.8809 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 96/250\n",
            "18/18 - 0s - loss: 91061.4375 - accuracy: 0.6051 - val_loss: 23799.1680 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 97/250\n",
            "18/18 - 0s - loss: 91076.2109 - accuracy: 0.6051 - val_loss: 23888.2168 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 98/250\n",
            "18/18 - 0s - loss: 91064.3359 - accuracy: 0.6051 - val_loss: 23812.5684 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 99/250\n",
            "18/18 - 0s - loss: 91060.9062 - accuracy: 0.6051 - val_loss: 23798.1660 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 100/250\n",
            "18/18 - 0s - loss: 91051.3203 - accuracy: 0.6051 - val_loss: 23786.1738 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 101/250\n",
            "18/18 - 0s - loss: 91053.7344 - accuracy: 0.6051 - val_loss: 23803.6738 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 102/250\n",
            "18/18 - 0s - loss: 91058.6953 - accuracy: 0.6051 - val_loss: 23785.5957 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 103/250\n",
            "18/18 - 0s - loss: 91053.4297 - accuracy: 0.6051 - val_loss: 23816.1445 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 104/250\n",
            "18/18 - 0s - loss: 91064.2422 - accuracy: 0.6051 - val_loss: 23786.2305 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 105/250\n",
            "18/18 - 0s - loss: 91061.3516 - accuracy: 0.6051 - val_loss: 23836.2773 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 106/250\n",
            "18/18 - 0s - loss: 91128.5781 - accuracy: 0.6051 - val_loss: 23856.6289 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 107/250\n",
            "18/18 - 0s - loss: 91054.9922 - accuracy: 0.6051 - val_loss: 23824.5566 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 108/250\n",
            "18/18 - 0s - loss: 91069.0859 - accuracy: 0.6051 - val_loss: 23838.9766 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 109/250\n",
            "18/18 - 0s - loss: 91087.3906 - accuracy: 0.6051 - val_loss: 23817.6973 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 110/250\n",
            "18/18 - 0s - loss: 91068.2891 - accuracy: 0.6051 - val_loss: 23792.2539 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 111/250\n",
            "18/18 - 0s - loss: 91085.6719 - accuracy: 0.6051 - val_loss: 23923.5586 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 112/250\n",
            "18/18 - 0s - loss: 91135.7188 - accuracy: 0.6051 - val_loss: 23832.6934 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 113/250\n",
            "18/18 - 0s - loss: 91080.5469 - accuracy: 0.6051 - val_loss: 23871.6367 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 114/250\n",
            "18/18 - 0s - loss: 91091.4766 - accuracy: 0.6051 - val_loss: 23864.9297 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 115/250\n",
            "18/18 - 0s - loss: 91043.1016 - accuracy: 0.6051 - val_loss: 23820.3105 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 116/250\n",
            "18/18 - 0s - loss: 91083.9531 - accuracy: 0.6051 - val_loss: 23816.2988 - val_accuracy: 0.6201 - 98ms/epoch - 5ms/step\n",
            "Epoch 117/250\n",
            "18/18 - 0s - loss: 91067.1484 - accuracy: 0.6051 - val_loss: 23929.6504 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 118/250\n",
            "18/18 - 0s - loss: 91088.6328 - accuracy: 0.6051 - val_loss: 23847.3398 - val_accuracy: 0.6201 - 96ms/epoch - 5ms/step\n",
            "Epoch 119/250\n",
            "18/18 - 0s - loss: 91050.2969 - accuracy: 0.6051 - val_loss: 23801.1719 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 120/250\n",
            "18/18 - 0s - loss: 91060.9688 - accuracy: 0.6051 - val_loss: 23787.5977 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 121/250\n",
            "18/18 - 0s - loss: 91068.6250 - accuracy: 0.6051 - val_loss: 23835.2520 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 122/250\n",
            "18/18 - 0s - loss: 91060.7266 - accuracy: 0.6051 - val_loss: 23817.4844 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 123/250\n",
            "18/18 - 0s - loss: 91100.4609 - accuracy: 0.6051 - val_loss: 23836.0742 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 124/250\n",
            "18/18 - 0s - loss: 91106.7578 - accuracy: 0.6051 - val_loss: 23837.5977 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 125/250\n",
            "18/18 - 0s - loss: 91130.6562 - accuracy: 0.6051 - val_loss: 23843.2852 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 126/250\n",
            "18/18 - 0s - loss: 91079.3594 - accuracy: 0.6051 - val_loss: 24034.6230 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 127/250\n",
            "18/18 - 0s - loss: 91120.7656 - accuracy: 0.6051 - val_loss: 23843.7109 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 128/250\n",
            "18/18 - 0s - loss: 91078.3906 - accuracy: 0.6051 - val_loss: 23830.3965 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 129/250\n",
            "18/18 - 0s - loss: 91053.9297 - accuracy: 0.6051 - val_loss: 23821.4805 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 130/250\n",
            "18/18 - 0s - loss: 91118.1094 - accuracy: 0.6051 - val_loss: 23896.0742 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 131/250\n",
            "18/18 - 0s - loss: 91133.1797 - accuracy: 0.6051 - val_loss: 23866.0703 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 132/250\n",
            "18/18 - 0s - loss: 91098.8125 - accuracy: 0.6051 - val_loss: 23847.5234 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 133/250\n",
            "18/18 - 0s - loss: 91107.0391 - accuracy: 0.6051 - val_loss: 23830.9824 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 134/250\n",
            "18/18 - 0s - loss: 91121.7188 - accuracy: 0.6051 - val_loss: 23818.1094 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 135/250\n",
            "18/18 - 0s - loss: 91103.6719 - accuracy: 0.6051 - val_loss: 23878.5586 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 136/250\n",
            "18/18 - 0s - loss: 91068.5078 - accuracy: 0.6051 - val_loss: 23817.8672 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 137/250\n",
            "18/18 - 0s - loss: 91051.8906 - accuracy: 0.6051 - val_loss: 23802.1309 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 138/250\n",
            "18/18 - 0s - loss: 91062.8594 - accuracy: 0.6051 - val_loss: 23803.1797 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 139/250\n",
            "18/18 - 0s - loss: 91059.4375 - accuracy: 0.6051 - val_loss: 23786.3301 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 140/250\n",
            "18/18 - 0s - loss: 91072.6797 - accuracy: 0.6051 - val_loss: 23838.3574 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 141/250\n",
            "18/18 - 0s - loss: 91069.1328 - accuracy: 0.6051 - val_loss: 23812.4941 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 142/250\n",
            "18/18 - 0s - loss: 91028.4609 - accuracy: 0.6051 - val_loss: 23814.0605 - val_accuracy: 0.6201 - 97ms/epoch - 5ms/step\n",
            "Epoch 143/250\n",
            "18/18 - 0s - loss: 91123.8594 - accuracy: 0.6051 - val_loss: 23984.5293 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 144/250\n",
            "18/18 - 0s - loss: 91087.5625 - accuracy: 0.6051 - val_loss: 23814.3652 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 145/250\n",
            "18/18 - 0s - loss: 91082.6797 - accuracy: 0.6051 - val_loss: 23832.8145 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 146/250\n",
            "18/18 - 0s - loss: 91048.8750 - accuracy: 0.6051 - val_loss: 23810.7031 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 147/250\n",
            "18/18 - 0s - loss: 91090.9219 - accuracy: 0.6051 - val_loss: 23890.6699 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 148/250\n",
            "18/18 - 0s - loss: 91094.0625 - accuracy: 0.6051 - val_loss: 23822.5547 - val_accuracy: 0.6201 - 98ms/epoch - 5ms/step\n",
            "Epoch 149/250\n",
            "18/18 - 0s - loss: 91111.5625 - accuracy: 0.6051 - val_loss: 23897.5078 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 150/250\n",
            "18/18 - 0s - loss: 91058.5703 - accuracy: 0.6051 - val_loss: 23823.2930 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 151/250\n",
            "18/18 - 0s - loss: 91057.8125 - accuracy: 0.6051 - val_loss: 23822.7148 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 152/250\n",
            "18/18 - 0s - loss: 91072.9531 - accuracy: 0.6051 - val_loss: 23859.2793 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 153/250\n",
            "18/18 - 0s - loss: 91056.9922 - accuracy: 0.6051 - val_loss: 23848.6621 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 154/250\n",
            "18/18 - 0s - loss: 91036.0156 - accuracy: 0.6051 - val_loss: 23791.3730 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 155/250\n",
            "18/18 - 0s - loss: 91054.5703 - accuracy: 0.6051 - val_loss: 23797.1074 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 156/250\n",
            "18/18 - 0s - loss: 91085.5547 - accuracy: 0.6051 - val_loss: 23790.3535 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 157/250\n",
            "18/18 - 0s - loss: 91079.9531 - accuracy: 0.6051 - val_loss: 23797.3809 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 158/250\n",
            "18/18 - 0s - loss: 91080.4141 - accuracy: 0.6051 - val_loss: 23803.1855 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 159/250\n",
            "18/18 - 0s - loss: 91078.3750 - accuracy: 0.6060 - val_loss: 23809.2480 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 160/250\n",
            "18/18 - 0s - loss: 91048.4922 - accuracy: 0.6069 - val_loss: 23878.0332 - val_accuracy: 0.6201 - 97ms/epoch - 5ms/step\n",
            "Epoch 161/250\n",
            "18/18 - 0s - loss: 91057.5781 - accuracy: 0.6051 - val_loss: 23848.4570 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 162/250\n",
            "18/18 - 0s - loss: 91074.0938 - accuracy: 0.6032 - val_loss: 23801.9512 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 163/250\n",
            "18/18 - 0s - loss: 91064.8828 - accuracy: 0.6051 - val_loss: 23938.8926 - val_accuracy: 0.6157 - 89ms/epoch - 5ms/step\n",
            "Epoch 164/250\n",
            "18/18 - 0s - loss: 91069.0547 - accuracy: 0.6051 - val_loss: 23844.1055 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 165/250\n",
            "18/18 - 0s - loss: 91073.6953 - accuracy: 0.6051 - val_loss: 23789.0684 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 166/250\n",
            "18/18 - 0s - loss: 91036.6016 - accuracy: 0.6060 - val_loss: 23796.6641 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 167/250\n",
            "18/18 - 0s - loss: 91065.5469 - accuracy: 0.6051 - val_loss: 23786.9102 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 168/250\n",
            "18/18 - 0s - loss: 91036.5078 - accuracy: 0.6051 - val_loss: 23825.3359 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 169/250\n",
            "18/18 - 0s - loss: 91043.5391 - accuracy: 0.6060 - val_loss: 23796.1621 - val_accuracy: 0.6201 - 96ms/epoch - 5ms/step\n",
            "Epoch 170/250\n",
            "18/18 - 0s - loss: 91044.9219 - accuracy: 0.6060 - val_loss: 23809.7930 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 171/250\n",
            "18/18 - 0s - loss: 91051.4297 - accuracy: 0.6051 - val_loss: 23825.4883 - val_accuracy: 0.6201 - 95ms/epoch - 5ms/step\n",
            "Epoch 172/250\n",
            "18/18 - 0s - loss: 91066.9062 - accuracy: 0.6051 - val_loss: 23805.5234 - val_accuracy: 0.6201 - 81ms/epoch - 4ms/step\n",
            "Epoch 173/250\n",
            "18/18 - 0s - loss: 91071.5547 - accuracy: 0.6051 - val_loss: 23801.8340 - val_accuracy: 0.6201 - 100ms/epoch - 6ms/step\n",
            "Epoch 174/250\n",
            "18/18 - 0s - loss: 91040.9297 - accuracy: 0.6060 - val_loss: 23810.5352 - val_accuracy: 0.6201 - 97ms/epoch - 5ms/step\n",
            "Epoch 175/250\n",
            "18/18 - 0s - loss: 91046.2969 - accuracy: 0.6051 - val_loss: 23801.6738 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 176/250\n",
            "18/18 - 0s - loss: 91060.3281 - accuracy: 0.6060 - val_loss: 23764.8105 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 177/250\n",
            "18/18 - 0s - loss: 91050.1875 - accuracy: 0.6041 - val_loss: 23779.6230 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 178/250\n",
            "18/18 - 0s - loss: 91044.5156 - accuracy: 0.6051 - val_loss: 23825.0977 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 179/250\n",
            "18/18 - 0s - loss: 91071.5547 - accuracy: 0.6051 - val_loss: 23815.9180 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 180/250\n",
            "18/18 - 0s - loss: 91035.9219 - accuracy: 0.6051 - val_loss: 23823.0508 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 181/250\n",
            "18/18 - 0s - loss: 91114.9297 - accuracy: 0.5769 - val_loss: 23841.5703 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 182/250\n",
            "18/18 - 0s - loss: 91108.4141 - accuracy: 0.6051 - val_loss: 23864.0234 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 183/250\n",
            "18/18 - 0s - loss: 91089.6172 - accuracy: 0.6069 - val_loss: 23841.2988 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 184/250\n",
            "18/18 - 0s - loss: 91044.9297 - accuracy: 0.6051 - val_loss: 23797.2109 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 185/250\n",
            "18/18 - 0s - loss: 91055.0938 - accuracy: 0.6060 - val_loss: 23854.4043 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 186/250\n",
            "18/18 - 0s - loss: 91041.4688 - accuracy: 0.6060 - val_loss: 23768.0020 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 187/250\n",
            "18/18 - 0s - loss: 91055.0000 - accuracy: 0.6051 - val_loss: 23876.1543 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 188/250\n",
            "18/18 - 0s - loss: 91048.1172 - accuracy: 0.6060 - val_loss: 23784.5723 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 189/250\n",
            "18/18 - 0s - loss: 91101.9141 - accuracy: 0.6069 - val_loss: 23796.0977 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 190/250\n",
            "18/18 - 0s - loss: 91080.1797 - accuracy: 0.6060 - val_loss: 23803.2715 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 191/250\n",
            "18/18 - 0s - loss: 91054.4766 - accuracy: 0.6041 - val_loss: 23786.5762 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 192/250\n",
            "18/18 - 0s - loss: 91056.2109 - accuracy: 0.6051 - val_loss: 23784.2480 - val_accuracy: 0.6201 - 93ms/epoch - 5ms/step\n",
            "Epoch 193/250\n",
            "18/18 - 0s - loss: 91074.4297 - accuracy: 0.6041 - val_loss: 23841.7227 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 194/250\n",
            "18/18 - 0s - loss: 91061.8125 - accuracy: 0.6051 - val_loss: 23813.2051 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 195/250\n",
            "18/18 - 0s - loss: 91063.7891 - accuracy: 0.6051 - val_loss: 23818.2480 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 196/250\n",
            "18/18 - 0s - loss: 91060.4141 - accuracy: 0.6060 - val_loss: 23875.4863 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 197/250\n",
            "18/18 - 0s - loss: 91072.1016 - accuracy: 0.6051 - val_loss: 23781.1133 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 198/250\n",
            "18/18 - 0s - loss: 91060.9375 - accuracy: 0.6051 - val_loss: 23785.8340 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 199/250\n",
            "18/18 - 0s - loss: 91040.1797 - accuracy: 0.6051 - val_loss: 23790.0957 - val_accuracy: 0.6201 - 83ms/epoch - 5ms/step\n",
            "Epoch 200/250\n",
            "18/18 - 0s - loss: 91047.1562 - accuracy: 0.6060 - val_loss: 23847.2812 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 201/250\n",
            "18/18 - 0s - loss: 91084.3281 - accuracy: 0.6051 - val_loss: 23822.5488 - val_accuracy: 0.6201 - 92ms/epoch - 5ms/step\n",
            "Epoch 202/250\n",
            "18/18 - 0s - loss: 91057.3359 - accuracy: 0.6041 - val_loss: 23815.9395 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 203/250\n",
            "18/18 - 0s - loss: 91041.0547 - accuracy: 0.6051 - val_loss: 23817.2812 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 204/250\n",
            "18/18 - 0s - loss: 91106.4219 - accuracy: 0.6060 - val_loss: 23831.2891 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 205/250\n",
            "18/18 - 0s - loss: 91068.7734 - accuracy: 0.6051 - val_loss: 23828.0566 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 206/250\n",
            "18/18 - 0s - loss: 91056.3203 - accuracy: 0.6051 - val_loss: 23799.8906 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 207/250\n",
            "18/18 - 0s - loss: 91040.8125 - accuracy: 0.6051 - val_loss: 23866.4746 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 208/250\n",
            "18/18 - 0s - loss: 91101.1875 - accuracy: 0.6069 - val_loss: 23815.2656 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 209/250\n",
            "18/18 - 0s - loss: 91127.7188 - accuracy: 0.6051 - val_loss: 23885.2754 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 210/250\n",
            "18/18 - 0s - loss: 91063.3516 - accuracy: 0.6051 - val_loss: 23818.9082 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 211/250\n",
            "18/18 - 0s - loss: 91086.8281 - accuracy: 0.6060 - val_loss: 23874.5938 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 212/250\n",
            "18/18 - 0s - loss: 91060.6641 - accuracy: 0.6051 - val_loss: 23846.8457 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 213/250\n",
            "18/18 - 0s - loss: 91057.5938 - accuracy: 0.6051 - val_loss: 23783.9512 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 214/250\n",
            "18/18 - 0s - loss: 91061.2891 - accuracy: 0.6060 - val_loss: 23968.0156 - val_accuracy: 0.6026 - 84ms/epoch - 5ms/step\n",
            "Epoch 215/250\n",
            "18/18 - 0s - loss: 91063.3828 - accuracy: 0.6032 - val_loss: 23798.8281 - val_accuracy: 0.6201 - 94ms/epoch - 5ms/step\n",
            "Epoch 216/250\n",
            "18/18 - 0s - loss: 91055.0312 - accuracy: 0.6060 - val_loss: 23845.7578 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 217/250\n",
            "18/18 - 0s - loss: 91068.1562 - accuracy: 0.6079 - val_loss: 23784.0293 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 218/250\n",
            "18/18 - 0s - loss: 91066.8047 - accuracy: 0.6060 - val_loss: 23836.5410 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 219/250\n",
            "18/18 - 0s - loss: 91065.6016 - accuracy: 0.6060 - val_loss: 23790.9121 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 220/250\n",
            "18/18 - 0s - loss: 91055.8828 - accuracy: 0.6051 - val_loss: 23790.7617 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 221/250\n",
            "18/18 - 0s - loss: 91040.7266 - accuracy: 0.6060 - val_loss: 23765.3145 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 222/250\n",
            "18/18 - 0s - loss: 91068.6406 - accuracy: 0.6060 - val_loss: 23813.3262 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 223/250\n",
            "18/18 - 0s - loss: 91031.0625 - accuracy: 0.6051 - val_loss: 23833.2246 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 224/250\n",
            "18/18 - 0s - loss: 91039.1406 - accuracy: 0.6060 - val_loss: 23770.3633 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 225/250\n",
            "18/18 - 0s - loss: 91090.3672 - accuracy: 0.5976 - val_loss: 23886.0547 - val_accuracy: 0.6135 - 77ms/epoch - 4ms/step\n",
            "Epoch 226/250\n",
            "18/18 - 0s - loss: 91092.9844 - accuracy: 0.5779 - val_loss: 23794.0234 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 227/250\n",
            "18/18 - 0s - loss: 91070.7578 - accuracy: 0.6051 - val_loss: 23839.3203 - val_accuracy: 0.6201 - 102ms/epoch - 6ms/step\n",
            "Epoch 228/250\n",
            "18/18 - 0s - loss: 91080.8281 - accuracy: 0.6051 - val_loss: 23842.9473 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 229/250\n",
            "18/18 - 0s - loss: 91054.0469 - accuracy: 0.6051 - val_loss: 23836.6836 - val_accuracy: 0.6201 - 77ms/epoch - 4ms/step\n",
            "Epoch 230/250\n",
            "18/18 - 0s - loss: 91150.8203 - accuracy: 0.5356 - val_loss: 23795.4336 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 231/250\n",
            "18/18 - 0s - loss: 91081.5312 - accuracy: 0.6069 - val_loss: 23864.9277 - val_accuracy: 0.6201 - 91ms/epoch - 5ms/step\n",
            "Epoch 232/250\n",
            "18/18 - 0s - loss: 91109.3438 - accuracy: 0.6051 - val_loss: 23825.6426 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 233/250\n",
            "18/18 - 0s - loss: 91102.4688 - accuracy: 0.6051 - val_loss: 23897.7852 - val_accuracy: 0.6114 - 78ms/epoch - 4ms/step\n",
            "Epoch 234/250\n",
            "18/18 - 0s - loss: 91045.3828 - accuracy: 0.6051 - val_loss: 23787.1484 - val_accuracy: 0.6201 - 88ms/epoch - 5ms/step\n",
            "Epoch 235/250\n",
            "18/18 - 0s - loss: 91088.4609 - accuracy: 0.6060 - val_loss: 23778.2891 - val_accuracy: 0.6201 - 86ms/epoch - 5ms/step\n",
            "Epoch 236/250\n",
            "18/18 - 0s - loss: 91129.0938 - accuracy: 0.6060 - val_loss: 23798.9199 - val_accuracy: 0.6201 - 89ms/epoch - 5ms/step\n",
            "Epoch 237/250\n",
            "18/18 - 0s - loss: 91082.1719 - accuracy: 0.6051 - val_loss: 23823.6348 - val_accuracy: 0.6201 - 81ms/epoch - 5ms/step\n",
            "Epoch 238/250\n",
            "18/18 - 0s - loss: 91095.0469 - accuracy: 0.6060 - val_loss: 23904.4395 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 239/250\n",
            "18/18 - 0s - loss: 91068.6484 - accuracy: 0.6051 - val_loss: 23842.7910 - val_accuracy: 0.6201 - 80ms/epoch - 4ms/step\n",
            "Epoch 240/250\n",
            "18/18 - 0s - loss: 91051.0703 - accuracy: 0.6051 - val_loss: 23836.2754 - val_accuracy: 0.6201 - 90ms/epoch - 5ms/step\n",
            "Epoch 241/250\n",
            "18/18 - 0s - loss: 91073.1094 - accuracy: 0.6051 - val_loss: 23883.2773 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 242/250\n",
            "18/18 - 0s - loss: 91061.9219 - accuracy: 0.6060 - val_loss: 23802.1816 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "Epoch 243/250\n",
            "18/18 - 0s - loss: 91053.2344 - accuracy: 0.6051 - val_loss: 23816.2148 - val_accuracy: 0.6201 - 79ms/epoch - 4ms/step\n",
            "Epoch 244/250\n",
            "18/18 - 0s - loss: 91044.6641 - accuracy: 0.6051 - val_loss: 23829.8066 - val_accuracy: 0.6201 - 84ms/epoch - 5ms/step\n",
            "Epoch 245/250\n",
            "18/18 - 0s - loss: 91035.7578 - accuracy: 0.6051 - val_loss: 23789.3535 - val_accuracy: 0.6201 - 76ms/epoch - 4ms/step\n",
            "Epoch 246/250\n",
            "18/18 - 0s - loss: 91031.8828 - accuracy: 0.6051 - val_loss: 23764.5938 - val_accuracy: 0.6201 - 85ms/epoch - 5ms/step\n",
            "Epoch 247/250\n",
            "18/18 - 0s - loss: 91071.7969 - accuracy: 0.6004 - val_loss: 23831.4492 - val_accuracy: 0.6201 - 87ms/epoch - 5ms/step\n",
            "Epoch 248/250\n",
            "18/18 - 0s - loss: 91051.6406 - accuracy: 0.6051 - val_loss: 23869.6328 - val_accuracy: 0.6201 - 78ms/epoch - 4ms/step\n",
            "Epoch 249/250\n",
            "18/18 - 0s - loss: 91045.6562 - accuracy: 0.6051 - val_loss: 23806.0156 - val_accuracy: 0.6201 - 98ms/epoch - 5ms/step\n",
            "Epoch 250/250\n",
            "18/18 - 0s - loss: 91042.1875 - accuracy: 0.6051 - val_loss: 23768.8398 - val_accuracy: 0.6201 - 82ms/epoch - 5ms/step\n",
            "optimized parameters: [  0.3   8.  128.   60.  250.    8.  128. ]\n",
            "optimized loss: 49269.88671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "def plot_distribution(pd_series):\n",
        "    labels = pd_series.value_counts().index.tolist()\n",
        "    counts = pd_series.value_counts().values.tolist()\n",
        "    \n",
        "    pie_plot = go.Pie(labels=labels, values=counts, hole=.3)\n",
        "    fig = go.Figure(data=[pie_plot])\n",
        "    fig.update_layout(title_text='Distribution for %s' % pd_series.name)\n",
        "    \n",
        "    fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "wgU6WAyiMR_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_distribution(df2['organization_type'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "wejLh0JaM9BL",
        "outputId": "100ca176-ca36-425e-aa44-22c0d534c109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"0c140937-c33a-4085-8800-c6bb4e29999a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0c140937-c33a-4085-8800-c6bb4e29999a\")) {                    Plotly.newPlot(                        \"0c140937-c33a-4085-8800-c6bb4e29999a\",                        [{\"hole\":0.3,\"labels\":[1,2,3,5,4],\"values\":[1500,458,234,59,24],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution for organization_type\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0c140937-c33a-4085-8800-c6bb4e29999a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.histogram(df2, x=\"total_scope_1\", nbins=20)\n",
        "fig.update_layout(title_text='Age distribution')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "l9udvxHYNHg8",
        "outputId": "91468ff7-0cc6-4458-e4d5-45417492d4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8fe2cbe9-457c-45cc-a336-4ce24a56d552\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8fe2cbe9-457c-45cc-a336-4ce24a56d552\")) {                    Plotly.newPlot(                        \"8fe2cbe9-457c-45cc-a336-4ce24a56d552\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"total_scope_1=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"nbinsx\":20,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[6017.0,824.0,19811.0,17802.0,4132.0,2284.0,717.0,882.0,2775.0,2261.0,41799.0,18858.0,11164.0,548.0,18915.0,737.0,360.0,0.0,12115.0,6395.0,1831.0,2141.0,5039.0,5968.0,557.0,2628.0,18038.0,11.0,23219.0,3279.0,11868.0,350.0,1862.0,2000.0,20100.0,8024.0,41373.0,56979.0,7003.0,6296.0,614.0,14747.0,274.0,62521.0,2963.0,19469.0,2287.0,10481.0,28300.0,26837.0,28536.0,1948.0,1229.0,2547.0,663.0,78.0,2588.0,253.0,405.0,22443.0,719000.0,119452.0,6776.0,4149496.0,3285.0,1689.0,3328.0,1569.0,1374.0,6720.0,10234177.0,29362.0,167510.0,22388.0,27843.0,2639.0,5660.0,13426.0,13349.0,10725.0,478.0,10645.0,52074.0,1767.0,656.0,16054.0,1267.0,852527.0,1670.0,1637.0,34841.0,2066.0,320.0,2594.0,871.0,472.0,578.0,5150.0,39252.0,7889.0,1549.0,2657.0,2353.0,2710.0,4361.0,209520.0,681.0,9231.0,263.0,49576.0,509.0,975.0,44455.0,5708.0,4593.0,360.0,0.0,25722.0,3480.0,0.0,56.0,9085.0,2779.0,11150.0,851.0,4772.0,2424.0,220.0,1272.0,1863.0,1103.0,12424.0,44.0,2346.0,1244.0,9527.0,248957.0,2188.0,3535.0,1213.0,74.0,25271.0,2013.0,3223.0,4010.0,12686.0,198016.0,3985.0,158357.0,10612.0,6956.0,1612.0,53682.0,13321.0,1824.0,4775.0,2763.0,1724.0,904.0,226384.0,1190.0,42395.0,6583.0,1072.0,525.0,3802.0,12566.0,1319.0,83696.0,2561.0,104.0,1293.0,1730.0,733.0,74.0,2039.0,1829.0,27823.0,1465.0,1724.0,30.0,8158.0,251.0,646.0,3083.0,6184.0,1366.0,4238.0,296.0,887.0,1940.0,1178.0,45555.0,543.0,8093.0,74472.0,0.0,2611.0,829.0,4111.0,22289.0,3414.0,27.0,1243.0,2550.0,4195.0,259.0,1948.0,791.0,16540.0,0.0,2029.0,4708613.0,1261.0,4527.0,4882.0,14315.0,348.0,7799.0,1829.0,66685.0,7548.0,1243.0,5193.0,3568.0,6812.0,409.0,8378.0,3449.0,4561.0,4117.0,30719.0,8112.0,7278.0,231.0,5055.0,4142.0,384.0,26153.0,499.0,15530.0,17.0,1962.0,1150.0,6267.0,2014.0,1180.0,1318.0,9.0,1880.0,1109.0,186.0,3812.0,4450.0,9649.0,1758.0,174981.0,1924.0,8134.0,31111.0,2018.0,10063.0,13591.0,3675.0,12452.0,1155.0,1146.0,117312.0,279.0,492.0,85834.0,2655.0,12151.0,1536.0,7431.0,3456.0,2537.0,831.0,295.0,9876.0,13205.0,15969.0,1071.0,848.0,11747.0,5993.0,19396.0,1451.0,1824.0,1215120.0,125286.0,3309.0,587.0,130476.0,45.0,967.0,60154.0,27503.0,1291.0,4364999.0,137295.0,3940.0,4513.0,2114.0,1112.0,2020.0,2494.0,8484.0,6430.0,21880.0,498.0,558.0,567.0,1343.0,2643.0,27795.0,1733.0,2171.0,6266.0,264.0,2221.0,16054.0,3819.0,5409.0,37.0,5578.0,8940.0,517.0,1355.0,20300.0,56437.0,131138.0,1695191.0,3873.0,3420.0,616.0,1383055.0,968.0,1443.0,17950.0,4924.0,1103.0,4593.0,15.0,4817.0,855.0,1148.0,20569.0,2146.0,85592.0,7280.0,12269.0,10270.0,2386.0,13377.0,12461.0,17430.0,0.0,28042.0,8338.0,144502.0,2977.0,71256.0,1886.0,1244.0,21383.0,45468.0,5097.0,5984.0,805.0,7954.0,1518.0,93.0,421.0,13763.0,3695.0,21794.0,8546.0,1561.0,65.0,196.0,10405.0,1948.0,381.0,12390.0,11597.0,16416.0,3794.0,469478.0,16.0,6242.0,297.0,6700.0,8439.0,35230.0,4902.0,7050.0,240.0,308.0,6965.0,959.0,34752.0,154.0,2702.0,2711.0,1912816.0,51165.0,2229.0,38322.0,1064.0,19413.0,1655.0,20.0,29546.0,62.0,4926.0,5438.0,4200.0,119.0,4799.0,1955.0,1450.0,613.0,3106.0,4715.0,1472.0,814.0,59497.0,23067.0,947.0,3394.0,28134.0,9872.0,11447.0,5133.0,3380.0,792120.0,17046.0,412060.0,298.0,634.0,3276.0,275.0,2617.0,11023.0,14764.0,4208.0,1140.0,5662.0,19139.0,1504.0,2016.0,1688.0,1960.0,183.0,6363.0,3088.0,1780.0,4202.0,10358.0,2870.0,1394.0,598.0,457333.0,16286.0,2707.0,1037.0,769.0,26538.0,994.0,1212.0,55906.0,2665.0,2297.0,1260.0,7552.0,280854.0,3345.0,4606.0,18725.0,28555.0,4165.0,208.0,879.0,51965.0,2256.0,2267.0,5648.0,1450.0,4309.0,5897.0,1069.0,261.0,1116.0,115335.0,87791.0,458.0,135369.0,17698.0,589.0,4186.0,1355.0,1945.0,1664.0,416.0,34748.0,4625.0,3327.0,52220.0,2842.0,42610.0,8015.0,1080.0,13793.0,42002.0,246.0,556.0,96.0,2412.0,2040.0,10532.0,9306.0,2328.0,1161.0,104387.0,11374.0,1424.0,10298.0,780.0,18250.0,1209.0,2600.0,90.0,685.0,2381.0,181.0,1465.0,623.0,1245.0,1999.0,2223.0,835832.0,6288.0,13385.0,22695.0,860.0,272.0,14091.0,4659.0,7327.0,81.0,36786.0,362.0,30969.0,2176.0,1914.0,2792.0,88145.0,8403.0,20121.0,1703.0,1545.0,2632.0,6486.0,1410.0,16444.0,8596.0,490.0,1859.0,691.0,5836.0,1872.0,1148.0,899242.0,1590.0,19463.0,7534.0,3813.0,6384.0,129703.0,25687.0,124.0,3617.0,1826.0,4192.0,1139.0,37583.0,2439.0,3828.0,4426.0,954.0,966.0,6878.0,2528.0,53656.0,1560.0,9048.0,3170.0,6527.0,3508.0,1585.0,447685.0,106259.0,4843.0,43024.0,2150.0,1729.0,1405654.0,89289.0,519.0,470.0,4393.0,42031.0,4376.0,1885.0,2575.0,7753.0,277.0,61.0,1289.0,2289.0,88.0,2000.0,1914.0,287.0,11617.0,5227.0,2336.0,580.0,4997.0,293.0,1245.0,939.0,4692.0,6715.0,757.0,22966.0,1617.0,736.0,2174.0,6186.0,49.0,1554.0,0.0,1968.0,606.0,68600.0,5980.0,869717.0,13837.0,444.0,9082.0,391.0,426.0,1538.0,2197.0,2285.0,1538.0,10801.0,36634.0,347.0,540.0,1249.0,32413.0,6778.0,502.0,117.0,17150.0,213.0,7683.0,4650.0,21396.0,1646.0,3390.0,6336.0,1113.0,2748.0,313.0,89.0,391.0,6687.0,230.0,469.0,1260.0,751.0,14722.0,2391.0,1661.0,13547.0,16874.0,364.0,12519.0,3781.0,391.0,18869.0,1886.0,158.0,323.0,3556.0,3444.0,1158.0,83213.0,187.0,13480.0,343.0,4228.0,2182.0,510.0,2219.0,400.0,1370.0,31.0,42345.0,554.0,4805.0,5275.0,2669.0,9557.0,4524.0,558.0,830.0,2071.0,1058.0,1818.0,9152.0,2236.0,2776.0,0.0,1032.0,558.0,17058.0,6224.0,2974.0,14673.0,3774.0,1136.0,953.0,2293.0,3806.0,3665.0,11980.0,2044.0,17889.0,8603.0,15052.0,11233.0,25510.0,6516.0,48532.0,1454.0,9075.0,428.0,1235.0,29940.0,1905.0,1298.0,12386.0,93.0,6356.0,7075.0,263.0,777.0,279.0,1289498.0,2924.0,7557.0,651.0,1397.0,15780.0,189.0,19107.0,410.0,48914.0,139.0,2367.0,16722.0,1905.0,7605.0,453.0,3269.0,3346.0,454.0,2483.0,1737.0,2.0,3324.0,55089.0,1749.0,38331.0,44.0,830.0,76.0,1334.0,943.0,6996.0,4235.0,114.0,1330.0,1803.0,2905.0,572.0,0.0,1104.0,0.0,1127.0,1927.0,3275.0,2231.0,8445.0,0.0,639.0,704.0,916.0,562.0,79.0,1492.0,986.0,1065.0,5020.0,1522.0,1844.0,1055.0,23294.0,3279.0,4617.0,1475.0,635.0,2318.0,2798.0,7124.0,8835.0,5205.0,626.0,4138.0,1449.0,461.0,1398.0,17471.0,4792.0,399.0,2988.0,1100.0,1730.0,8867.0,1914.0,14431.0,6295.0,379.0,4969.0,195.0,4921.0,983.0,865.0,2844.0,1076.0,1433.0,162.0,1072865.0,8915.0,1504.0,15280.0,4571.0,1727.0,2620.0,494.0,2635.0,109.0,2188.0,1663.0,1123.0,192789.0,675.0,545.0,2729.0,129.0,1067.0,142.0,484.0,4703.0,83.0,4911.0,3724.0,139.0,17299.0,630.0,14794.0,22445.0,4407.0,600.0,320.0,579.0,1252.0,21601.0,19057.0,15676.0,12304.0,1375.0,2386.0,0.0,6751.0,5568.0,2751.0,1203.0,793.0,3452.0,623.0,22899.0,2103.0,331.0,2378.0,4715.0,1471.0,696.0,305.0,40556.0,0.0,53815.0,1320.0,27559.0,128.0,1311.0,6282.0,5402.0,4232.0,4417.0,20830.0,339.0,24271.0,55.0,478.0,4355.0,254.0,2893.0,4844.0,0.0,1480.0,1113.0,1375.0,159.0,1061.0,274.0,1220.0,2055.0,5119.0,450.0,2379.0,1665.0,2043.0,914.0,1614.0,546.0,6830.0,2245.0,45464.0,4364.0,12714.0,1311.0,310710.0,2474.0,2670.0,2080.0,6385.0,320.0,14712.0,3613.0,3545.0,8276.0,1827.0,964.0,179.0,321.0,2351.0,90419.0,2613.0,2690.0,21806.0,9979.0,23.0,17198.0,12308.0,2432.0,4205.0,439.0,178.0,261.0,348.0,2618.0,1478.0,8900.0,77235.0,48179.0,37.0,1877.0,4875.0,986.0,15478.0,789.0,100.0,725.0,1204.0,2303.0,12016.0,18158.0,965.0,34.0,1273.0,2265.0,2420.0,439.0,4982.0,2796.0,2090.0,5639.0,1441.0,887.0,2477.0,18120.0,446.0,250.0,870.0,1063.0,89342.0,1475.0,746.0,345.0,259.0,281.0,1212.0,798.0,18521.0,695.0,3596.0,1644.0,3997.0,4246.0,1316.0,211.0,15351.0,10.0,266.0,95652.0,134.0,726.0,941.0,26482.0,1016.0,1111.0,1030.0,993.0,14873.0,1570.0,472.0,3416.0,5012.0,529.0,458.0,64.0,8360.0,154.0,4.0,387.0,3001.0,13668.0,768979.0,543.0,1550.0,51.0,2821.0,7302.0,80225.0,2342.0,2035.0,300.0,2071.0,7473.0,3032.0,472.0,7496.0,530.0,5460.0,1074.0,97569.0,659122.0,1791.0,395.0,2586.0,1506.0,464.0,5197.0,807.0,1800.0,147566.0,2280.0,45290.0,3090.0,2145.0,167570.0,3168.0,2432.0,2427.0,882.0,10116.0,2015.0,40.0,19224.0,3494.0,21712.0,776.0,1509.0,19634.0,9033.0,2900.0,70977.0,88534.0,18043.0,11666.0,306.0,0.0,10586.0,4201.0,1284.0,426.0,10332.0,9404.0,2658.0,108.0,6098.0,48085.0,319.0,68290.0,969.0,1713.0,1492.0,17507.0,3222.0,362.0,4201.0,2773.0,855.0,2639.0,5066.0,16405.0,1289.0,281.0,644.0,258199.0,4914.0,469.0,173.0,1919.0,1663.0,118.0,50439.0,3.0,6980.0,5837.0,806.0,14689.0,13191.0,11576.0,9042.0,2697.0,14858.0,1897.0,273792.0,24117.0,272.0,596.0,284.0,394.0,265.0,643.0,96.0,1266.0,14429.0,1746.0,3992.0,476.0,436.0,12948.0,180219.0,1.0,1631.0,10.0,11046.0,560.0,14.0,2491.0,50142.0,1184.0,2859.0,2578.0,1502.0,6182.0,13455.0,705.0,645.0,669.0,934.0,1047.0,814.0,32568.0,6285.0,5.0,591.0,69498.0,30872.0,904.0,676.0,1027.0,4137.0,3918.0,4521.0,2043.0,3147.0,2043.0,395.0,8236.0,3771.0,493054.0,1793.0,7030.0,22871.0,45.0,8259.0,51.0,49493.0,9696.0,3581.0,309.0,1002.0,735.0,1922.0,45537.0,593.0,156.0,1079.0,289.0,9416.0,195.0,6300.0,630.0,189.0,21711.0,7422.0,1142.0,530.0,10050.0,3641.0,2739.0,5042.0,404.0,1160.0,55.0,333.0,12380.0,8520.0,19781.0,36175.0,33772.0,9835.0,3584.0,6969.0,1975.0,67561.0,1094.0,144598.0,12686.0,1090.0,341.0,1373.0,32857.0,10124.0,51231.0,377.0,830.0,406.0,334.0,3438.0,7746.0,203.0,550.0,1285.0,5747.0,1453.0,152.0,33385.0,185.0,1895.0,295.0,20102.0,24538.0,22002.0,320.0,5474.0,1593.0,13.0,2559.0,16170.0,2793.0,55.0,50.0,1386.0,4307.0,1203.0,6063.0,2118.0,5.0,267.0,8124.0,19.0,252.0,25.0,29451.0,9133.0,1808.0,665.0,5672.0,5941.0,862.0,2514.0,2052.0,493.0,915.0,3137.0,105874.0,79.0,4046.0,68.0,550.0,30385.0,618.0,841.0,1673.0,1013.0,3125.0,593.0,1258.0,13997.0,2012.0,339.0,784282.0,27.0,42343.0,3556.0,189.0,312.0,966.0,284253.0,301920.0,1216.0,4189.0,1143.0,9256.0,1744050.0,857.0,3205.0,64639.0,9897.0,2281.0,638.0,22438.0,899.0,872270.0,962918.0,4104.0,729500.0,3812.0,1944.0,952.0,6671.0,523.0,634.0,357900.0,525.0,520.0,7302.0,79392.0,734.0,3086.0,1415.0,780.0,3710.0,3557.0,50678.0,420.0,1528.0,491.0,415.0,5.0,66810.0,3692.0,7426.0,3607.0,3897.0,1495.0,1268.0,9722.0,1002.0,4446.0,7854.0,441.0,219.0,555.0,109.0,2034.0,3169.0,7850.0,987.0,2132.0,10190.0,2334.0,4240.0,650.0,5073.0,3339.0,2046.0,205.0,2298.0,6530.0,9302.0,5941.0,820.0,289.0,9481.0,1381.0,3747.0,44.0,11485.0,5926.0,772.0,614.0,5396.0,502.0,1011.0,1914.0,1475.0,3407.0,1282.0,21.0,20485.0,3816.0,669.0,240.0,297.0,468.0,6014.0,220.0,51985.0,277.0,97.0,657.0,823.0,4123.0,4329.0,1539.0,885.0,725.0,10977.0,245.0,2368.0,5330.0,358.0,9490.0,3.0,29148.0,21390.0,198.0,1204.0,479.0,3864.0,1265.0,514.0,1847.0,6996.0,2718.0,600.0,112.0,13142.0,540.0,3816.0,11593.0,10059.0,3942.0,771.0,774.0,2574.0,3972.0,1688.0,2246.0,7644.0,430.0,114.0,267.0,5572.0,89.0,1180.0,37814.0,4008.0,3026.0,2977.0,13370.0,902.0,5049.0,1930.0,6049.0,25445.0,1542.0,2908.0,1696.0,3260.0,2472.0,14165855.0,5180.0,16467.0,3068359.0,127830.0,4144128.0,318929.0,3540.0,3137.0,3549951.0,5185.0,3657.0,2373.0,297.0,4337.0,2386.0,4574.0,4271.0,4558.0,287.0,49189.0,213.0,144903.0,1387.0,6092.0,609.0,3344.0,491.0,1236.0,3789.0,27073.0,1611.0,620.0,32417.0,765423.0,1336.0,4011.0,211221.0,1316.0,14024.0,2303.0,1444566.0,1207.0,11823.0,13384.0,14692.0,2401.0,4387.0,3352.0,234060.0,998.0,1005.0,2230.0,2063.0,4703.0,1378.0,24347.0,1365.0,201003.0,1846.0,1371.0,148.0,10984.0,163.0,506.0,79493.0,12492.0,10804.0,3213.0,152.0,1178.0,34408.0,35699735.0,9206.0,35754.0,7160.0,1256.0,24012.0,78868.0,2229.0,21852.0,6055.0,291.0,2071.0,75361.0,83.0,296.0,2067.0,52166.0,1716.0,528.0,306.0,23998.0,3234.0,1546.0,6472.0,28537996.0,91.0,1322.0,9655.0,13686.0,3456.0,1307.0,10361.0,1365.0,445.0,533.0,5493.0,2189.0,18554.0,1479.0,12490.0,5338.0,855.0,2219.0,4227.0,9.0,7076.0,145.0,881.0,7886.0,992.0,31862.0,204.0,33014.0,389.0,13539.0,39696.0,1529.0,14141.0,3272.0,2467.0,249.0,50230.0,3815.0,8500.0,4109.0,2388.0,5554.0,291.0,205.0,525467.0,11381.0,2565.0,1587.0,7197.0,10419.0,26789.0,55417.0,232.0,3163.0,3145.0,1080.0,6134.0,39.0,340.0,3174.0,16246.0,1442.0,41399.0,548.0,7561.0,3438828.0,642.0,8354.0,364.0,2731.0,56.0,1541.0,1126.0,139367.0,1415.0,3533.0,1433.0,30.0,41.0,2226.0,4333.0,10678.0,190.0,266.0,1058.0,265.0,10301.0,3800.0,1619.0,919.0,195.0,7183.0,282.0,11186.0,431.0,3616.0,2108.0,6258.0,39274.0,1905.0,5449.0,927.0,1271.0,6519.0,2175.0,12167.0,680.0,6815.0,970.0,986.0,1022.0,69915.0,177340.0,177.0,360904.0,616.0,9717.0,1358.0,3835.0,844.0,848.0,2532.0,2054.0,12813.0,2004.0,389.0,1248.0,287.0,539.0,499.0,2740.0,8729.0,107184.0,4012.0,475.0,739.0,5619.0,2795.0,44.0,429.0,1723.0,392.0,30.0,1312.0,1569.0,3404.0,444.0,813.0,2084.0,611.0,924.0,3305.0,3653.0,5658.0,9500.0,969.0,9171.0,172.0,1358.0,843.0,11558.0,1154.0,818.0,214.0,729342.0,657.0,34889.0,155.0,46676.0,9473.0,21142.0,16691.0,22351.0,12949.0,824.0,1600.0,68798.0,1.0,40704.0,1073.0,21458.0,464.0,711.0,220.0,3173.0,46492.0,30994.0,2410.0,1912.0,6006.0,10.0,2839.0,7347.0,2111.0,138566.0,6568.0,4670.0,39057.0,3902.0,1380473.0,13936.0,16170.0,8176.0,1245.0,2426.0,98646.0,6680.0,886.0,5914.0,298.0,6028.0,302.0,392.0,2136.0,11699.0,65567.0,838.0,50027.0,1529.0,287.0,137111.0,1505.0,440.0,10209.0,870.0,296171.0,6550.0,2555.0,11311.0,881.0,2823.0,1350.0,4498.0,3400.0,8949.0,59563.0,1949.0,10204.0,951.0,2431.0,971.0,6938.0,13464.0,2561.0,4361.0,22974.0,6433.0,1675.0,235.0,2552.0,13056.0,1456.0,3885.0,255.0,17000.0,1555.0,7972.0,2079.0,807.0,8815.0,9199.0,6846.0,5099.0,2644.0,2240.0,3398.0,3970.0,3780.0,3454.0,3263.0,4526.0,13408.0,3661.0,2873.0,8005.0,736.0,89.0,115.0,427.0,69280.0,1704.0,2832.0,1159.0,30.0,3118.0,25322.0,682.0,2222.0,2476.0,12922.0,1406.0,307.0,199.0,461031.0,936.0,994.0,14.0,152.0,458.0,9393.0,2881.0,4728.0,3571.0,52348.0,1286.0,2493.0,23873.0,10470.0,3191.0,3094.0,698476.0,377.0,237.0,7527.0,2711.0,6515.0,3574.0,230.0,2418.0,9696.0,1001.0,5131.0,503.0,3730.0,438.0,6433.0,814.0,3068.0,5338.0,5774.0,3917.0,483.0,54.0,6578.0,722.0,190.0,1909.0,447.0,59.0,1573.0,1287.0,29957.0,1532.0,1398.0,3165.0,580711.0,1.0,1123.0,3507.0,797.0,2212.0,463.0,5755.0,7344.0,3959.0,7645.0,219.0,2991.0,25068.0,103.0,12355.0,994.0,772.0,13334.0,43.0,2572.0,473.0,22325.0,885.0,994.0,825.0,748.0,1300.0,1547.0,1459.0,24.0,842.0,4583.0,5050.0,1307.0,269.0,1392.0,2133.0,119.0,2346.0,1156.0,2374.0,531113.0,12330.0,2410000.0,13337.0,1424000.0,1585.0,74843.0,359.0,31531.0,3465.0,580.0,147.0,123.0,704.0,17990.0,473.0,2426.0,486.0,1377.0,1360.0,453.0,25.0,1408.0,89.0,1890.0,2294.0,11413.0,383.0,6874.0,3339.0,211.0,495.0,48728.0,7397.0,2002.0,593.0,2484.0,5158.0,434.0,2405.0,2512.0,703.0,10550.0,74.0,778.0,535.0,4735.0,270.0,7091.0,1317.0,1782.0,80097.0,78263.0,10811.0,855.0,238.0,14203.0,7807.0,5.0,17681.0,4029.0,181635.0,1672.0,713.0,54466.0,295.0,346.0,25828.0,1939.0,1532.0,2500.0,2070.0,5841.0,776.0,756.0,5931.0,1536.0,4091.0,2631.0,14458.0,2925.0,1706.0,7363.0,2632.0,14025.0,1431.0,1024.0,136.0,61.0,11314.0,5892.0,21992.0,712.0,1257.0,5772.0,6931.0,788.0,7123.0,347.0,1927.0,6802.0,10750.0,7017.0,236.0,5.0,778.0,6232.0,2642.0,16349.0,923.0,14458.0,4905.0,6017.0,220.0,1797.0,575.0,3070.0,1506.0,750.0,5439.0,8866.0,2730.0,4006.0,3284.0,1177.0,9556.0,1644.0,1183.0,1854.0,1031.0,39.0,79404.0,55003.0,1949.0,934.0,2113.0,129.0,10.0,56058.0,2322.0,2281.0,463.0,1155.0,25225.0,1805.0,8036.0,6151.0,5279.0,2688.0,2403.0,1371.0,54221.0,1639.0,985.0,909.0,45.0,22434.0,1516.0,2910.0,379.0,16315.0,727729.0,19919.0,3072.0,5121574.0,192.0,3921.0,7633.0,3371.0,21112.0,219.0,10339.0,5264.0,1233.0,539.0,8817.0,6085.0,1441.0,29184.0,8430.0,2646.0,17947.0,496.0,47617.0,2211.0,10552.0,2874.0,13159.0,245.0,9902.0,2402.0,269.0,2818.0,174.0,692.0,6053.0,2910.0,10484.0,1177.0,184.0,4508.0,574.0,1969.0,91.0,0.0,12556.0,4368.0,3443.0,1450.0,154.0,2150.0,960.0,4602.0,2376.0,0.0,11602.0,4581.0,464056.0,1125.0,1273.0,361.0,86481.0,725.0,787.0,5691.0,789.0,1883.0,91.0,2113.0,12242.0,2320.0,40.0,2149.0,2603.0,0.0,2977.0,587.0,6734.0,146.0,777.0,0.0,3303.0,37361.0,431.0,354.0,276.0,17158.0,127140.0,7574.0,3066.0,82.0,8813.0,52.0,36620.0,0.0,698.0,16239.0,759.0,3890.0,4079.0,995.0,965.0,1676.0,3429.0,14975.0,2625.0,140.0,1777.0,8872.0,1713.0,249.0,294.0,813.0,3330.0,12647.0,15851.0,24596.0,439.0,1141.0],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"total_scope_1\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\",\"title\":{\"text\":\"Age distribution\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8fe2cbe9-457c-45cc-a336-4ce24a56d552');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}